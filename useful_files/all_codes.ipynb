{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56deecfd-cb54-469a-ab53-58b2052d0e6d",
      "metadata": {
        "id": "56deecfd-cb54-469a-ab53-58b2052d0e6d",
        "outputId": "16b3a467-fc8b-4fe4-ec07-bb6b23c84a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdflib in /opt/conda/lib/python3.12/site-packages (7.1.3)\n",
            "Requirement already satisfied: openai in /opt/conda/lib/python3.12/site-packages (0.28.0)\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
            "Requirement already satisfied: pyparsing<4,>=2.1.0 in /opt/conda/lib/python3.12/site-packages (from rdflib) (3.2.0)\n",
            "Requirement already satisfied: requests>=2.20 in /opt/conda/lib/python3.12/site-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from openai) (4.67.0)\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from openai) (3.11.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->openai) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->openai) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests>=2.20->openai) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->openai) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->openai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->openai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->openai) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->openai) (1.17.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install rdflib openai pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c90137c2-19ac-41f3-bf15-470d46eee32f",
      "metadata": {
        "id": "c90137c2-19ac-41f3-bf15-470d46eee32f",
        "outputId": "4b329ecd-8f78-4d49-8cee-d5c31db6e2ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /opt/conda/lib/python3.12/site-packages (1.0.1)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90131767-c28e-4b22-9479-7e8ce7ae5c89",
      "metadata": {
        "id": "90131767-c28e-4b22-9479-7e8ce7ae5c89"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import openai\n",
        "from rdflib import Graph, Namespace, RDF, RDFS, OWL\n",
        "from llama_cpp import Llama\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import re\n",
        "from rdflib import URIRef\n",
        "\n",
        "import sys\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.embeddings import GPT4AllEmbeddings\n",
        "from langchain_community.llms import LlamaCpp\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnablePick\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain import hub\n",
        "from langchain_core.prompts import PromptTemplate"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "529a5bff-f983-4b57-80c5-7ca0cd14f47b",
      "metadata": {
        "id": "529a5bff-f983-4b57-80c5-7ca0cd14f47b"
      },
      "source": [
        "load_dotenv('openai-key.txt')\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6ea47bc-8ffc-436c-bf34-01b56fb584c5",
      "metadata": {
        "id": "d6ea47bc-8ffc-436c-bf34-01b56fb584c5"
      },
      "source": [
        "# Extract Classes and properties from TTL file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b630d1e-0c26-4a12-9ef6-3b5a8de88327",
      "metadata": {
        "id": "3b630d1e-0c26-4a12-9ef6-3b5a8de88327",
        "outputId": "d92c9647-29ca-4842-d05c-5583e77ccdf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N691b142952c54cc588be93e1e44833fa (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 395,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g = Graph()\n",
        "g.parse(\"only_events.ttl\", format=\"turtle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c868154-2b50-4198-abe6-fd293a146734",
      "metadata": {
        "id": "9c868154-2b50-4198-abe6-fd293a146734"
      },
      "outputs": [],
      "source": [
        "classes = set() #use set because no duplicates allowed and order does not matter\n",
        "properties = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "733b6e79-e69e-4234-b240-f1cd9e3089e7",
      "metadata": {
        "id": "733b6e79-e69e-4234-b240-f1cd9e3089e7"
      },
      "outputs": [],
      "source": [
        "for s in g.subjects(RDF.type, OWL.Class):\n",
        "    label = g.value(s, RDFS.label)\n",
        "    classes.add((str(s), str(label) if label else s.split(\"/\")[-1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59fcb69f-d083-4859-8cc8-0e8053ee0295",
      "metadata": {
        "id": "59fcb69f-d083-4859-8cc8-0e8053ee0295",
        "outputId": "4c66c3d4-cce6-4bb9-da46-d2ae4c89ae89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://example.org/Event\n",
            "http://example.org/Calendar\n",
            "http://example.org/Location\n",
            "http://example.org/EventCategory\n",
            "http://example.org/State\n"
          ]
        }
      ],
      "source": [
        "for s in g.subjects(RDF.type, OWL.Class):\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1206eaa3-ce27-48d6-97a4-4bcf27bc19dd",
      "metadata": {
        "id": "1206eaa3-ce27-48d6-97a4-4bcf27bc19dd",
        "outputId": "bc38d2b2-de84-42b4-d6e9-cbd3307d9b4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{('http://example.org/Calendar', 'Calendar'),\n",
              " ('http://example.org/Event', 'Event'),\n",
              " ('http://example.org/EventCategory', 'Event Category'),\n",
              " ('http://example.org/Location', 'Location'),\n",
              " ('http://example.org/State', 'State')}"
            ]
          },
          "execution_count": 399,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a89a242-97b6-47ae-a576-246ce04abdf2",
      "metadata": {
        "id": "7a89a242-97b6-47ae-a576-246ce04abdf2"
      },
      "outputs": [],
      "source": [
        "for s in g.subjects(RDF.type, OWL.ObjectProperty):\n",
        "    domain = g.value(s, RDFS.domain)\n",
        "    range_ = g.value(s, RDFS.range)\n",
        "    label = g.value(s, RDFS.label)\n",
        "    properties[str(s)] = {\n",
        "        \"type\":\"ObjectProperty\",\n",
        "        \"label\":str(label) if label else s.split(\"/\")[-1],\n",
        "        \"domain\":str(domain),\n",
        "        \"range\":str(range_)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "906123d3-6756-49b9-84e6-e20be362cdb5",
      "metadata": {
        "id": "906123d3-6756-49b9-84e6-e20be362cdb5",
        "outputId": "90d14e13-1acb-44b4-84ee-a578f23ea36c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://example.org/eventat\n",
            "http://example.org/eventon\n",
            "http://example.org/eventstate\n",
            "http://example.org/hasCategory\n"
          ]
        }
      ],
      "source": [
        "for s in g.subjects(RDF.type, OWL.ObjectProperty):\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d67c9e6b-bb99-461c-a5c4-cc13b4586d7b",
      "metadata": {
        "id": "d67c9e6b-bb99-461c-a5c4-cc13b4586d7b",
        "outputId": "f0d1ff68-0573-4b5e-b640-791807c945f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'http://example.org/eventat': {'type': 'ObjectProperty',\n",
              "  'label': 'Event At',\n",
              "  'domain': 'http://example.org/Location',\n",
              "  'range': 'http://example.org/Event'},\n",
              " 'http://example.org/eventon': {'type': 'ObjectProperty',\n",
              "  'label': 'Event On',\n",
              "  'domain': 'http://example.org/Calendar',\n",
              "  'range': 'http://example.org/Event'},\n",
              " 'http://example.org/eventstate': {'type': 'ObjectProperty',\n",
              "  'label': 'Event State',\n",
              "  'domain': 'http://example.org/Event',\n",
              "  'range': 'http://example.org/State'},\n",
              " 'http://example.org/hasCategory': {'type': 'ObjectProperty',\n",
              "  'label': 'Has Category',\n",
              "  'domain': 'http://example.org/EventCategory',\n",
              "  'range': 'http://example.org/Event'}}"
            ]
          },
          "execution_count": 402,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e83f7ba-9df9-4e6f-abe0-00a9d6734a7c",
      "metadata": {
        "id": "7e83f7ba-9df9-4e6f-abe0-00a9d6734a7c"
      },
      "outputs": [],
      "source": [
        "for s in g.subjects(RDF.type, OWL.DatatypeProperty):\n",
        "    domain = g.value(s, RDFS.domain)\n",
        "    range_ = g.value(s, RDFS.range)\n",
        "    label = g.value(s, RDFS.label)\n",
        "    properties[str(s)] = {\n",
        "        \"type\":\"DatatypeProperty\",\n",
        "        \"label\":str(label) if label else s.split(\"/\")[-1],\n",
        "        \"domain\":str(domain),\n",
        "        \"range\":str(range_)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30456e78-819d-448a-af7f-28bdc93a53a1",
      "metadata": {
        "id": "30456e78-819d-448a-af7f-28bdc93a53a1",
        "outputId": "93ea70a1-bbff-4737-dfcf-5aa2bd107830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://example.org/eventcatclassid\n",
            "http://example.org/eventcatname_it\n",
            "http://example.org/eventclassid\n",
            "http://example.org/eventdescr_it\n",
            "http://example.org/eventimage_url\n",
            "http://example.org/eventname_it\n",
            "http://example.org/calendarclassid\n",
            "http://example.org/day\n",
            "http://example.org/end_time\n",
            "http://example.org/start_time\n",
            "http://example.org/locationclassid\n",
            "http://example.org/address\n",
            "http://example.org/statecode\n",
            "http://example.org/statename\n"
          ]
        }
      ],
      "source": [
        "for s in g.subjects(RDF.type, OWL.DatatypeProperty):\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61e248c3-ee71-46ac-826e-071ed9b0e022",
      "metadata": {
        "id": "61e248c3-ee71-46ac-826e-071ed9b0e022",
        "outputId": "9c00045c-f13a-4cd4-8f22-0382ba0c36d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'http://example.org/eventat': {'type': 'ObjectProperty',\n",
              "  'label': 'Event At',\n",
              "  'domain': 'http://example.org/Location',\n",
              "  'range': 'http://example.org/Event'},\n",
              " 'http://example.org/eventon': {'type': 'ObjectProperty',\n",
              "  'label': 'Event On',\n",
              "  'domain': 'http://example.org/Calendar',\n",
              "  'range': 'http://example.org/Event'},\n",
              " 'http://example.org/eventstate': {'type': 'ObjectProperty',\n",
              "  'label': 'Event State',\n",
              "  'domain': 'http://example.org/Event',\n",
              "  'range': 'http://example.org/State'},\n",
              " 'http://example.org/hasCategory': {'type': 'ObjectProperty',\n",
              "  'label': 'Has Category',\n",
              "  'domain': 'http://example.org/EventCategory',\n",
              "  'range': 'http://example.org/Event'},\n",
              " 'http://example.org/eventcatclassid': {'type': 'DatatypeProperty',\n",
              "  'label': 'Eventcat Classid',\n",
              "  'domain': 'http://example.org/EventCategory',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/eventcatname_it': {'type': 'DatatypeProperty',\n",
              "  'label': 'Eventcat Name',\n",
              "  'domain': 'http://example.org/EventCategory',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/eventclassid': {'type': 'DatatypeProperty',\n",
              "  'label': 'Event Class ID',\n",
              "  'domain': 'http://example.org/Event',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/eventdescr_it': {'type': 'DatatypeProperty',\n",
              "  'label': 'Event Description (IT)',\n",
              "  'domain': 'http://example.org/Event',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/eventimage_url': {'type': 'DatatypeProperty',\n",
              "  'label': 'Event Image URL',\n",
              "  'domain': 'http://example.org/Event',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/eventname_it': {'type': 'DatatypeProperty',\n",
              "  'label': 'Event Name',\n",
              "  'domain': 'http://example.org/Event',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/calendarclassid': {'type': 'DatatypeProperty',\n",
              "  'label': 'Calendar Class ID',\n",
              "  'domain': 'http://example.org/Calendar',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/day': {'type': 'DatatypeProperty',\n",
              "  'label': 'day',\n",
              "  'domain': 'http://example.org/Calendar',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#date'},\n",
              " 'http://example.org/end_time': {'type': 'DatatypeProperty',\n",
              "  'label': 'EndTime',\n",
              "  'domain': 'http://example.org/Calendar',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/start_time': {'type': 'DatatypeProperty',\n",
              "  'label': 'StartTime',\n",
              "  'domain': 'http://example.org/Calendar',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/locationclassid': {'type': 'DatatypeProperty',\n",
              "  'label': 'Location Class ID',\n",
              "  'domain': 'http://example.org/Location',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/address': {'type': 'DatatypeProperty',\n",
              "  'label': 'Address',\n",
              "  'domain': 'http://example.org/Location',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/statecode': {'type': 'DatatypeProperty',\n",
              "  'label': 'State code',\n",
              "  'domain': 'http://example.org/State',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'},\n",
              " 'http://example.org/statename': {'type': 'DatatypeProperty',\n",
              "  'label': 'State name',\n",
              "  'domain': 'http://example.org/State',\n",
              "  'range': 'http://www.w3.org/2001/XMLSchema#string'}}"
            ]
          },
          "execution_count": 405,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "properties"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a905cbb7-876b-4c90-95c2-a530a5a101f2",
      "metadata": {
        "id": "a905cbb7-876b-4c90-95c2-a530a5a101f2"
      },
      "source": [
        "# Create one document per class and property"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f446a89b-931f-4d4a-960a-818b31e6a6e5",
      "metadata": {
        "id": "f446a89b-931f-4d4a-960a-818b31e6a6e5"
      },
      "outputs": [],
      "source": [
        "docs = []\n",
        "\n",
        "for uri, label in classes:\n",
        "    docs.append(f\"Class: {label} URI: {uri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3926ea3-5871-4b53-9b6a-3fa9a8fa515d",
      "metadata": {
        "id": "f3926ea3-5871-4b53-9b6a-3fa9a8fa515d",
        "outputId": "b5ca4701-21e7-41ec-f7ef-3829023d09d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Class: Event Category URI: http://example.org/EventCategory',\n",
              " 'Class: Location URI: http://example.org/Location',\n",
              " 'Class: State URI: http://example.org/State',\n",
              " 'Class: Event URI: http://example.org/Event',\n",
              " 'Class: Calendar URI: http://example.org/Calendar']"
            ]
          },
          "execution_count": 407,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "515b2cb8-a9ae-4a7d-b760-060256b05d14",
      "metadata": {
        "id": "515b2cb8-a9ae-4a7d-b760-060256b05d14"
      },
      "outputs": [],
      "source": [
        "for uri, prop in properties.items():\n",
        "    docs.append(f\"Property: {prop['label']} URI: {uri} Type: {prop['type']} Domain: {prop['domain']} Range: {prop['range']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad4f770a-a4cf-4b1c-a8f5-60d231716288",
      "metadata": {
        "scrolled": true,
        "id": "ad4f770a-a4cf-4b1c-a8f5-60d231716288",
        "outputId": "486209de-9fa3-42e2-94a9-6a767e1ea1f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Class: Event Category URI: http://example.org/EventCategory',\n",
              " 'Class: Location URI: http://example.org/Location',\n",
              " 'Class: State URI: http://example.org/State',\n",
              " 'Class: Event URI: http://example.org/Event',\n",
              " 'Class: Calendar URI: http://example.org/Calendar',\n",
              " 'Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event',\n",
              " 'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event',\n",
              " 'Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State',\n",
              " 'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event',\n",
              " 'Property: Eventcat Classid URI: http://example.org/eventcatclassid Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Eventcat Name URI: http://example.org/eventcatname_it Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Event Description (IT) URI: http://example.org/eventdescr_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Event Image URL URI: http://example.org/eventimage_url Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Event Name URI: http://example.org/eventname_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Calendar Class ID URI: http://example.org/calendarclassid Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: day URI: http://example.org/day Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#date',\n",
              " 'Property: EndTime URI: http://example.org/end_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Location Class ID URI: http://example.org/locationclassid Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Address URI: http://example.org/address Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: State code URI: http://example.org/statecode Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string']"
            ]
          },
          "execution_count": 409,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d0b9cf1-2bce-4280-b810-f4b0453e676a",
      "metadata": {
        "id": "3d0b9cf1-2bce-4280-b810-f4b0453e676a"
      },
      "source": [
        "# Ask LLM if class/property is relevant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b1d761e-bf65-4ef5-956d-76e6e0ad2364",
      "metadata": {
        "id": "4b1d761e-bf65-4ef5-956d-76e6e0ad2364",
        "outputId": "86432587-6304-4d14-9553-6847f762b82a"
      },
      "outputs": [
        {
          "ename": "RateLimitError",
          "evalue": "You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[74], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[1;32m      6\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou are a SPARQL expert. Given the user question: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Is the following class/property relevant? \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Answer only YES or NO.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 8\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4o\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     answer \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYES\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m answer:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[0;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[1;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m     )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/openai/api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[1;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[1;32m    767\u001b[0m     )\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[0;31mRateLimitError\u001b[0m: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors."
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happen on 2015-12-12?\"\n",
        "\n",
        "relevant_docs = []\n",
        "\n",
        "for doc in docs:\n",
        "    prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\" Is the following class/property relevant? {doc} Answer only YES or NO.\"\"\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0,\n",
        "        api_key=api_key\n",
        "    )\n",
        "\n",
        "    answer = response[\"choices\"][0][\"message\"][\"content\"].strip().upper()\n",
        "    if \"YES\" in answer:\n",
        "        relevant_docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89e4e47d-6a35-4db6-a8fd-a4cc740b097b",
      "metadata": {
        "id": "89e4e47d-6a35-4db6-a8fd-a4cc740b097b",
        "outputId": "f198541b-ae46-43e8-cd07-a387a383e8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-cpp-python in /opt/conda/lib/python3.12/site-packages (0.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /opt/conda/lib/python3.12/site-packages (from llama-cpp-python) (1.26.4)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /opt/conda/lib/python3.12/site-packages (from llama-cpp-python) (5.6.3)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /opt/conda/lib/python3.12/site-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a502dbc5-c6f4-4ddb-8203-59a4366b60f8",
      "metadata": {
        "id": "a502dbc5-c6f4-4ddb-8203-59a4366b60f8",
        "outputId": "e665f9a5-1b89-44f7-88f4-2e3a85c1b827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q8_0.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 6.67 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOG token        = 2 '</s>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  6828.64 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '7'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "llm = Llama(\n",
        "    model_path=\"llama-2-7b-chat.Q8_0.gguf\",\n",
        "    n_ctx=2048\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2699a9a5-fd95-4be6-94e2-5470ffd9e2e7",
      "metadata": {
        "id": "2699a9a5-fd95-4be6-94e2-5470ffd9e2e7",
        "outputId": "3c2b148c-2605-4e74-8d5d-2cd94bc864d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 61 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    61 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14732.92 ms /    76 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37725.87 ms /    65 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   36387.94 ms /    65 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6412.06 ms /    23 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4896.34 ms /    23 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 42 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    42 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7549.30 ms /    49 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9929.08 ms /    51 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25793.87 ms /    71 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10362.68 ms /    51 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38966.30 ms /   106 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8651.75 ms /    62 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38789.88 ms /   102 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39093.13 ms /   106 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4340.68 ms /    56 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     4 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5991.08 ms /    57 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39213.50 ms /   103 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6461.68 ms /    55 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37759.55 ms /   102 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37465.81 ms /   102 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38476.31 ms /   103 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38346.27 ms /    99 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6569.24 ms /    57 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    5324.57 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17491.46 ms /    72 tokens\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happen on 2015-12-12?\"\n",
        "relevant_docs = []\n",
        "\n",
        "for doc in docs:\n",
        "    prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\" Is the following class/property relevant? {doc} Answer only YES or NO.\"\"\"\n",
        "\n",
        "    response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "    answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "    if \"YES\" in answer:\n",
        "        relevant_docs.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a6cc04-7fa5-438c-aa39-e25b894afb7b",
      "metadata": {
        "id": "a8a6cc04-7fa5-438c-aa39-e25b894afb7b",
        "outputId": "a46b00b0-fae6-469f-8558-cb148f80c2b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Class: Calendar URI: http://example.org/Calendar',\n",
              " 'Class: Event URI: http://example.org/Event',\n",
              " 'Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State',\n",
              " 'Property: EndTime URI: http://example.org/end_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Location Class ID URI: http://example.org/locationclassid Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string']"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relevant_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb4a468-5bf2-43c3-99ef-b00b433b7ca0",
      "metadata": {
        "id": "1eb4a468-5bf2-43c3-99ef-b00b433b7ca0"
      },
      "source": [
        "Properties are not capturing well! But write in a function below and try other questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f25cace1-b18d-4b73-b1d9-307ab36addd3",
      "metadata": {
        "id": "f25cace1-b18d-4b73-b1d9-307ab36addd3"
      },
      "outputs": [],
      "source": [
        "question_doc_evaluations = []\n",
        "\n",
        "def get_relevant_docs(question, docs, llm):\n",
        "    relevant_docs = []\n",
        "\n",
        "    for doc in docs:\n",
        "        prompt = (\n",
        "            f'You are a SPARQL expert. Given the user question: \"{question}\" '\n",
        "            f'Is the following class/property relevant?\\n\\n{doc}\\n\\n'\n",
        "            \"Answer only YES or NO.\"\n",
        "        )\n",
        "\n",
        "        response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "\n",
        "        if isinstance(response, dict) and 'choices' in response:\n",
        "            answer = response['choices'][0]['text'].strip().upper()\n",
        "        else:\n",
        "            answer = str(response).strip().upper()\n",
        "\n",
        "        question_doc_evaluations.append({\n",
        "            \"question\": question,\n",
        "            \"document\": doc,\n",
        "            \"answer\": answer\n",
        "        })\n",
        "\n",
        "        if \"YES\" in answer:\n",
        "            relevant_docs.append(doc)\n",
        "\n",
        "    return relevant_docs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f395d8-7bd8-4dfa-8ee3-10f55f85f31d",
      "metadata": {
        "id": "d8f395d8-7bd8-4dfa-8ee3-10f55f85f31d",
        "outputId": "9f849e6b-bb2c-416d-d7ce-ae3ace7ec024"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 4 prefix-match hit, remaining 62 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    62 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   23928.70 ms /    85 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39887.39 ms /    67 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    1362.11 ms /    19 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    1288.25 ms /    19 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 20 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    20 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    1145.25 ms /    21 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 44 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    44 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2621.72 ms /    45 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8370.20 ms /    48 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2648.60 ms /    42 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 43 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    43 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24036.93 ms /    70 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 59 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    59 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10621.46 ms /    68 tokens\n",
            "Llama.generate: 50 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42769.72 ms /   106 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17765.50 ms /    73 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 59 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    59 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3432.02 ms /    60 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3265.61 ms /    57 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21391.25 ms /    78 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3103.94 ms /    57 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2954.04 ms /    53 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14221.39 ms /    68 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    40 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   36119.90 ms /    95 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12360.34 ms /    68 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14189.76 ms /    66 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14401.04 ms /    68 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14529.61 ms /    68 tokens\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happen on 2015-12-12?\"\n",
        "\n",
        "relevant_docs = get_relevant_docs(question_1, docs, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad0ce0f-028b-494f-b142-96cfeccaa360",
      "metadata": {
        "id": "3ad0ce0f-028b-494f-b142-96cfeccaa360",
        "outputId": "813e6552-7f53-4e76-f291-0bde89e85645"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Class: Location URI: http://example.org/Location',\n",
              " 'Class: Calendar URI: http://example.org/Calendar',\n",
              " 'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event',\n",
              " 'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event',\n",
              " 'Property: Eventcat Name URI: http://example.org/eventcatname_it Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: Event Name URI: http://example.org/eventname_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: EndTime URI: http://example.org/end_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              " 'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string']"
            ]
          },
          "execution_count": 628,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relevant_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0366c388-c862-4bd0-a225-c26eeaa19f6a",
      "metadata": {
        "scrolled": true,
        "id": "0366c388-c862-4bd0-a225-c26eeaa19f6a",
        "outputId": "49b8cac9-0c90-4e89-924f-31c6dac58954"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Class: Location URI: http://example.org/Location',\n",
              "  'answer': 'IF YOU ANSWER YES, PROVIDE THE RELEVANT CLASS/PROPERTY. IF YOU ANSWER NO, PLEASE EXPLAIN WHY.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Class: Calendar URI: http://example.org/Calendar',\n",
              "  'answer': 'IF YES, PLEASE EXPLAIN HOW.\\n\\nNO, THE CLASS CALENDAR IS NOT RELEVANT TO ANSWER THE USER QUESTION BECAUSE THE USER ASKED FOR EVENTS THAT HAPPENED ON A SPECIFIC DATE (2015-12-12) BUT THE CLASS CALENDAR'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Class: Event URI: http://example.org/Event',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Class: State URI: http://example.org/State',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Class: Event Category URI: http://example.org/EventCategory',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event',\n",
              "  'answer': 'IF YES, PLEASE EXPLAIN WHY.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event',\n",
              "  'answer': 'IF YES, PROVIDE A BRIEF EXPLANATION OF WHY THE PROPERTY IS RELEVANT. OTHERWISE, PROVIDE A BRIEF EXPLANATION OF WHY IT IS NOT RELEVANT.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Eventcat Classid URI: http://example.org/eventcatclassid Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'PLEASE LET ME KNOW YOUR ANSWER.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Eventcat Name URI: http://example.org/eventcatname_it Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'EXPLAIN YOUR ANSWER.\\n\\nANSWER: YES, THE PROPERTY \"EVENTCAT NAME\" IS RELEVANT FOR ANSWERING THE USER QUESTION. THE USER IS ASKING FOR THE NAMES OF EVENTS THAT HAPPENED ON A SPECIFIC DATE, AND THE \"EVENTCAT NAME\" PROPERTY'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'IF YOU WANT TO PROVIDE ADDITIONAL INFORMATION OR CLARIFICATION, PLEASE DO SO IN THE COMMENTS.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Event Description (IT) URI: http://example.org/eventdescr_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Event Image URL URI: http://example.org/eventimage_url Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Event Name URI: http://example.org/eventname_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'IF YES, PLEASE PROVIDE A BRIEF EXPLANATION OF WHY THE PROPERTY IS RELEVANT. IF NO, PLEASE EXPLAIN WHY NOT.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Calendar Class ID URI: http://example.org/calendarclassid Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: day URI: http://example.org/day Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#date',\n",
              "  'answer': ''},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: EndTime URI: http://example.org/end_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'IF YES, PLEASE EXPLAIN HOW IT IS RELEVANT TO THE QUESTION.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'PLEASE SELECT ONE OF THE FOLLOWING OPTIONS:\\n\\nNO, THIS PROPERTY IS NOT RELEVANT TO ANSWERING THE QUESTION.\\nYES, THIS PROPERTY IS RELEVANT AND CAN BE USED TO ANSWER THE QUESTION.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Location Class ID URI: http://example.org/locationclassid Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'IF YOU NEED MORE INFORMATION OR CLARIFICATION, PLEASE ASK!'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: Address URI: http://example.org/address Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'PLEASE LET ME KNOW IF YOU NEED ANY FURTHER CLARIFICATION.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: State code URI: http://example.org/statecode Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'PLEASE LET ME KNOW IF YOU NEED ANY FURTHER CLARIFICATION.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'document': 'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "  'answer': 'PLEASE LET ME KNOW IF YOU NEED ANY FURTHER CLARIFICATION.'}]"
            ]
          },
          "execution_count": 629,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_doc_evaluations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "663bdcb5-46b3-4d10-8f30-b19673753d29",
      "metadata": {
        "id": "663bdcb5-46b3-4d10-8f30-b19673753d29"
      },
      "source": [
        "#### Seperate the docs to classes and properties and check first with classes then properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4122803e-c578-42a3-be1f-8096fbeb35df",
      "metadata": {
        "id": "4122803e-c578-42a3-be1f-8096fbeb35df"
      },
      "outputs": [],
      "source": [
        "classes_only = []\n",
        "properties_only = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d36a79b3-202c-4969-994e-7903da9df07d",
      "metadata": {
        "id": "d36a79b3-202c-4969-994e-7903da9df07d"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "        if doc.startswith('Class'):\n",
        "            classes_only.append(doc)\n",
        "        elif doc.startswith('Property'):\n",
        "            properties_only.append(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "967dd7a1-e0c2-43ec-be4b-8d9f1cfd6acd",
      "metadata": {
        "id": "967dd7a1-e0c2-43ec-be4b-8d9f1cfd6acd",
        "outputId": "2c5e4699-54a3-4049-ac99-e662e7332231"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Class: Event Category URI: http://example.org/EventCategory',\n",
              " 'Class: Location URI: http://example.org/Location',\n",
              " 'Class: State URI: http://example.org/State',\n",
              " 'Class: Event URI: http://example.org/Event',\n",
              " 'Class: Calendar URI: http://example.org/Calendar']"
            ]
          },
          "execution_count": 412,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classes_only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9414ebd-7dcf-4498-912a-c54b3f990a9a",
      "metadata": {
        "id": "e9414ebd-7dcf-4498-912a-c54b3f990a9a"
      },
      "outputs": [],
      "source": [
        "relevant_classes = []\n",
        "questions_responses = []\n",
        "\n",
        "def ask_relevant_classes(question, docs, llm):\n",
        "\n",
        "    relevant_classes = []\n",
        "\n",
        "    for doc in docs:\n",
        "            prompt = f\"\"\"Generate a SPARQL query that matches the provided document from RDF schema. : \"{question}\" Is the following class relevant? {doc} Answer only YES or NO.\"\"\"\n",
        "            response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "\n",
        "            #answer = response.strip().upper()\n",
        "            answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "            if \"YES\" in answer:\n",
        "               relevant_classes.append(doc)\n",
        "\n",
        "    questions_responses.append({\"question\": question,\"response\": relevant_classes})\n",
        "\n",
        "    return relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b030c1cd-8fe9-456d-b8bc-c356c16c4380",
      "metadata": {
        "id": "b030c1cd-8fe9-456d-b8bc-c356c16c4380",
        "outputId": "678a6228-a546-43e5-e5a3-bc936353ae43"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 66 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    66 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41398.28 ms /   115 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2825.13 ms /    18 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37146.59 ms /    65 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39315.20 ms /    65 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2669.49 ms /    18 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['Class: Event URI: http://example.org/Event']\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_1, classes_only, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\") #mistakenly rerun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "711333d5-da77-4476-a322-b6e8f7c6d8df",
      "metadata": {
        "id": "711333d5-da77-4476-a322-b6e8f7c6d8df",
        "outputId": "d4c4ac57-07e6-44c6-9067-ad27730d317c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38712.54 ms /    88 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37477.87 ms /    65 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25333.32 ms /    49 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37570.71 ms /    65 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    47 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   35294.58 ms /    63 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['Class: Location URI: http://example.org/Location', 'Class: Event URI: http://example.org/Event']\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_2, classes_only, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b8ec731-b564-4b42-a150-67a4a4e5a12c",
      "metadata": {
        "id": "0b8ec731-b564-4b42-a150-67a4a4e5a12c",
        "outputId": "a1333d81-15b1-45a7-c997-458f22a7ad6b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 42 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    42 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     8 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9471.36 ms /    50 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12233.13 ms /    29 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5555.92 ms /    21 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     4 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4633.57 ms /    20 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   44615.42 ms /    67 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['Class: Event URI: http://example.org/Event', 'Class: State URI: http://example.org/State', 'Class: Event Category URI: http://example.org/EventCategory']\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_3, classes_only, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f85ea7-a91b-414d-9405-a0c78aa8d0cf",
      "metadata": {
        "id": "e7f85ea7-a91b-414d-9405-a0c78aa8d0cf",
        "outputId": "942d13ba-b8d3-4053-bbbc-875dec3cff74"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     4 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6324.92 ms /    41 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6414.78 ms /    22 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    42 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41311.12 ms /    58 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   46998.22 ms /    65 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13630.66 ms /    31 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['Class: Location URI: http://example.org/Location', 'Class: Calendar URI: http://example.org/Calendar', 'Class: State URI: http://example.org/State']\n"
          ]
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30? \"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_4, classes_only, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aec950cf-4235-4a10-a2fd-08c073374e4c",
      "metadata": {
        "id": "aec950cf-4235-4a10-a2fd-08c073374e4c",
        "outputId": "4fdf04a6-deb6-42e6-c616-901d7b8180ac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 15 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   47137.13 ms /    83 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12041.00 ms /    28 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   46075.61 ms /    65 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20616.94 ms /    37 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   28821.52 ms /    48 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['Class: Calendar URI: http://example.org/Calendar', 'Class: State URI: http://example.org/State']\n"
          ]
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_5, classes_only, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7235fe5-2f0e-4384-8374-3172ad57d68c",
      "metadata": {
        "id": "f7235fe5-2f0e-4384-8374-3172ad57d68c",
        "outputId": "4120e363-bb2a-4b52-f1ad-81b92bcdf2d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': ['Class: Location URI: http://example.org/Location']},\n",
              " {'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': ['Class: Calendar URI: http://example.org/Calendar',\n",
              "   'Class: Event URI: http://example.org/Event',\n",
              "   'Class: State URI: http://example.org/State',\n",
              "   'Class: Event Category URI: http://example.org/EventCategory']},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': ['Class: Event URI: http://example.org/Event',\n",
              "   'Class: Event Category URI: http://example.org/EventCategory']},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12',\n",
              "  'response': ['Class: Event URI: http://example.org/Event',\n",
              "   'Class: State URI: http://example.org/State',\n",
              "   'Class: Event Category URI: http://example.org/EventCategory']},\n",
              " {'question': 'What are the events scheduled to start at 11.30? ',\n",
              "  'response': ['Class: Location URI: http://example.org/Location',\n",
              "   'Class: Calendar URI: http://example.org/Calendar',\n",
              "   'Class: State URI: http://example.org/State']},\n",
              " {'question': 'Can you give the event names and their status?',\n",
              "  'response': ['Class: Calendar URI: http://example.org/Calendar',\n",
              "   'Class: State URI: http://example.org/State']}]"
            ]
          },
          "execution_count": 431,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7b597bc-0f71-4970-adb1-47c07843b7d0",
      "metadata": {
        "id": "f7b597bc-0f71-4970-adb1-47c07843b7d0"
      },
      "outputs": [],
      "source": [
        "relevant_properties = {}\n",
        "questions_responses_prop = []\n",
        "\n",
        "def ask_relevant_properties(question, relevant_classes, docs, llm):\n",
        "\n",
        "    class_to_properties = {}\n",
        "\n",
        "    for cls in relevant_classes:\n",
        "        class_name = cls.split('/')[1].strip()\n",
        "\n",
        "        relevant_props = []\n",
        "\n",
        "        for doc in docs:\n",
        "                prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\" Is the following property relevant for class {class_name}? {doc} Answer only YES or NO.\"\"\"\n",
        "                response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "                answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "                if \"YES\" in answer:\n",
        "                    relevant_props.append(doc)\n",
        "\n",
        "        class_to_properties[class_name] = relevant_props\n",
        "\n",
        "    questions_responses_prop.append({\"question\": question,\"relevant_classes\": relevant_classes,\"response\": relevant_props})\n",
        "\n",
        "    return class_to_properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f386694a-ad22-4fbc-88d9-c5fc74900164",
      "metadata": {
        "id": "f386694a-ad22-4fbc-88d9-c5fc74900164"
      },
      "outputs": [],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_1, classes_only, llm)\n",
        "#print(f\"Relevant classes: {relevant_classes}\")\n",
        "class_properties = ask_relevant_properties(question_1, relevant_classes, properties_only, llm)\n",
        "#print(f\"Relevant properties: {class_properties}\")   #took more thank one hour, so stopped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd5861b6-d167-42c0-8fab-a652dd75a0bf",
      "metadata": {
        "id": "dd5861b6-d167-42c0-8fab-a652dd75a0bf"
      },
      "outputs": [],
      "source": [
        "relevant_properties = {}\n",
        "questions_responses_prop = []\n",
        "\n",
        "def ask_relevant_properties(question, relevant_classes, docs, llm):\n",
        "\n",
        "    class_to_properties = {}\n",
        "\n",
        "    for cls in relevant_classes:\n",
        "        class_name = cls.split('/')[1].strip()\n",
        "\n",
        "        relevant_props = []\n",
        "\n",
        "        for doc in docs:\n",
        "                prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\" Is the following property relevant for class {class_name}? {doc} Answer only YES or NO.\"\"\"\n",
        "                response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "                answer = response.strip().upper()\n",
        "\n",
        "                if \"YES\" in answer:\n",
        "                    relevant_props.append(doc)\n",
        "\n",
        "        class_to_properties[class_name] = relevant_props\n",
        "\n",
        "    questions_responses_prop.append({\"question\": question,\"response\": relevant_props})\n",
        "\n",
        "    return class_to_properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb08af72-0051-4b65-8c81-592734a7413e",
      "metadata": {
        "id": "bb08af72-0051-4b65-8c81-592734a7413e",
        "outputId": "cfbddc50-d8cf-411b-af26-df45a0e1a20c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42467.91 ms /    65 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42837.26 ms /    65 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41626.12 ms /    65 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 16 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    16 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   28025.47 ms /    49 tokens\n",
            "Llama.generate: 49 prefix-match hit, remaining 18 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    18 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42731.73 ms /    67 tokens\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_1, classes_only, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e66bbdd-7d5f-449d-86d0-5ba2d77cf7c8",
      "metadata": {
        "id": "1e66bbdd-7d5f-449d-86d0-5ba2d77cf7c8",
        "outputId": "4a64c616-81d7-4f47-a680-3e16a9aa8287"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Class: Calendar URI: http://example.org/Calendar']"
            ]
          },
          "execution_count": 938,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e0de66-a375-4b51-96e2-66c9a1024b64",
      "metadata": {
        "id": "08e0de66-a375-4b51-96e2-66c9a1024b64",
        "outputId": "f1a171a8-3e42-4e43-baf6-02a69dc167f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 85 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    85 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11175.13 ms /    91 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   49050.14 ms /    88 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    46 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   46149.05 ms /    85 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25172.68 ms /    65 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12471.02 ms /    67 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8674.02 ms /    60 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30628.79 ms /    82 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   29843.52 ms /    84 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15889.07 ms /    67 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   45535.33 ms /    97 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   49143.72 ms /   103 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   35095.44 ms /    84 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6468.73 ms /    56 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11798.20 ms /    62 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12284.07 ms /    64 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15227.20 ms /    63 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13236.69 ms /    63 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13094.19 ms /    62 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'': ['Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State', 'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event', 'Property: Eventcat Name URI: http://example.org/eventcatname_it Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Description (IT) URI: http://example.org/eventdescr_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Name URI: http://example.org/eventname_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: day URI: http://example.org/day Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#date']}\n"
          ]
        }
      ],
      "source": [
        "class_properties = ask_relevant_properties(question_1, relevant_classes, properties_only, llm)\n",
        "print(f\"Relevant properties: {class_properties}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7aabfd0-9b5a-4c6e-94bd-d80087c718c4",
      "metadata": {
        "id": "b7aabfd0-9b5a-4c6e-94bd-d80087c718c4",
        "outputId": "d8cde0b3-5e15-4287-eba4-3bf7492bdd06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 85 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    50 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39706.04 ms /    51 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41688.37 ms /    88 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42525.77 ms /    88 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43040.21 ms /    90 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3339.44 ms /    58 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7530.27 ms /    60 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43382.71 ms /   102 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   45388.71 ms /   106 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12493.59 ms /    65 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5063.89 ms /    55 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   23145.81 ms /    78 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27772.74 ms /    80 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15006.12 ms /    68 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10813.14 ms /    62 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43319.66 ms /   103 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43248.23 ms /    99 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5740.91 ms /    55 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43837.81 ms /   101 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 40 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    40 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21173.69 ms /    62 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16653.18 ms /    56 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42975.35 ms /    88 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43003.39 ms /    90 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3235.75 ms /    58 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10908.59 ms /    64 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43797.77 ms /   102 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11741.53 ms /    67 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4880.09 ms /    56 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    39 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   34946.95 ms /    92 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3329.97 ms /    55 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42464.44 ms /    99 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43758.54 ms /   102 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    48 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43244.44 ms /   101 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4856.43 ms /    56 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43095.53 ms /    99 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   28450.06 ms /    83 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43019.71 ms /   101 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'': ['Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event', 'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event', 'Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State', 'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event', 'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Name URI: http://example.org/eventname_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string', 'Property: State code URI: http://example.org/statecode Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string', 'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string']}\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "class_properties = ask_relevant_properties(question_1, relevant_classes, properties_only, llm)\n",
        "print(f\"Relevant properties: {class_properties}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d031676-171c-45bb-b72d-020d9109b5d6",
      "metadata": {
        "id": "5d031676-171c-45bb-b72d-020d9109b5d6",
        "outputId": "93566094-907b-45e4-f332-80f706119bf4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 19 prefix-match hit, remaining 63 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    63 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43204.96 ms /   112 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41622.62 ms /    88 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41150.18 ms /    88 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42190.67 ms /    90 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42416.06 ms /   106 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41714.57 ms /   104 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41554.28 ms /   102 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3152.73 ms /    58 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41184.66 ms /   103 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3234.80 ms /    54 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37845.40 ms /    99 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42315.24 ms /    99 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24554.59 ms /    80 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41368.99 ms /   102 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20696.21 ms /    76 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40980.73 ms /    99 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40828.32 ms /   101 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41878.02 ms /   101 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 40 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    40 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41338.81 ms /    89 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7221.76 ms /    45 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4243.80 ms /    41 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     8 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9182.78 ms /    49 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43081.76 ms /   106 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42542.77 ms /   104 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41388.41 ms /   102 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42124.90 ms /   106 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41704.41 ms /   103 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40372.70 ms /   102 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42371.89 ms /   103 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42817.06 ms /    99 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42413.73 ms /   102 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42322.61 ms /   102 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41292.87 ms /   103 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24441.41 ms /    77 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   28077.62 ms /    84 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40856.46 ms /   101 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'': ['Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event', 'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event', 'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event', 'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Description (IT) URI: http://example.org/eventdescr_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Image URL URI: http://example.org/eventimage_url Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Location Class ID URI: http://example.org/locationclassid Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Address URI: http://example.org/address Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string', 'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string']}\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "class_properties = ask_relevant_properties(question_2, relevant_classes, properties_only, llm)\n",
        "print(f\"Relevant properties: {class_properties}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3b91358-6772-4611-a433-22407ffef096",
      "metadata": {
        "id": "d3b91358-6772-4611-a433-22407ffef096",
        "outputId": "fb016dec-4b05-4bb9-8611-5d2209e3b736"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 68 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    68 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   45578.92 ms /   117 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43571.71 ms /    88 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6272.39 ms /    44 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42710.12 ms /    90 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30141.71 ms /    90 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15935.18 ms /    70 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42374.69 ms /   102 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   44253.81 ms /   106 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43422.96 ms /   103 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43313.15 ms /   102 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18802.74 ms /    73 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43464.68 ms /    99 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43313.06 ms /   102 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43220.13 ms /   102 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   28431.85 ms /    85 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   28852.11 ms /    83 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8248.30 ms /    59 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42781.80 ms /   101 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 40 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    40 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4021.54 ms /    42 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    36 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   31703.97 ms /    75 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42386.67 ms /    88 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43050.69 ms /    90 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6018.21 ms /    60 tokens\n",
            "Llama.generate: 48 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43901.34 ms /   104 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41963.74 ms /   102 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43422.30 ms /   106 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41934.03 ms /   103 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43431.27 ms /   102 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11986.31 ms /    65 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   44019.07 ms /    99 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4578.75 ms /    55 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    43 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39054.66 ms /    96 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42794.97 ms /   103 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42466.71 ms /    99 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43020.92 ms /   101 tokens\n",
            "Llama.generate: 47 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   43492.66 ms /   101 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'': ['Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event', 'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event', 'Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State', 'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event', 'Property: Eventcat Name URI: http://example.org/eventcatname_it Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Description (IT) URI: http://example.org/eventdescr_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Event Image URL URI: http://example.org/eventimage_url Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string', 'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string', 'Property: Location Class ID URI: http://example.org/locationclassid Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string', 'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string']}\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12\"\n",
        "\n",
        "class_properties = ask_relevant_properties(question_3, relevant_classes, properties_only, llm)\n",
        "print(f\"Relevant properties: {class_properties}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c082d1ed-370f-4e14-a600-9176f0dbbe0a",
      "metadata": {
        "scrolled": true,
        "id": "c082d1ed-370f-4e14-a600-9176f0dbbe0a",
        "outputId": "9eae9daf-fd20-4503-c56c-842dca95a21b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': ['Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event',\n",
              "   'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event',\n",
              "   'Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State',\n",
              "   'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event',\n",
              "   'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Event Name URI: http://example.org/eventname_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: State code URI: http://example.org/statecode Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string']},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': ['Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event',\n",
              "   'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event',\n",
              "   'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event',\n",
              "   'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Event Description (IT) URI: http://example.org/eventdescr_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Event Image URL URI: http://example.org/eventimage_url Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Location Class ID URI: http://example.org/locationclassid Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Address URI: http://example.org/address Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string']},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12',\n",
              "  'response': ['Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event',\n",
              "   'Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event',\n",
              "   'Property: Event State URI: http://example.org/eventstate Type: ObjectProperty Domain: http://example.org/Event Range: http://example.org/State',\n",
              "   'Property: Has Category URI: http://example.org/hasCategory Type: ObjectProperty Domain: http://example.org/EventCategory Range: http://example.org/Event',\n",
              "   'Property: Eventcat Name URI: http://example.org/eventcatname_it Type: DatatypeProperty Domain: http://example.org/EventCategory Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Event Class ID URI: http://example.org/eventclassid Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Event Description (IT) URI: http://example.org/eventdescr_it Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Event Image URL URI: http://example.org/eventimage_url Type: DatatypeProperty Domain: http://example.org/Event Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: StartTime URI: http://example.org/start_time Type: DatatypeProperty Domain: http://example.org/Calendar Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: Location Class ID URI: http://example.org/locationclassid Type: DatatypeProperty Domain: http://example.org/Location Range: http://www.w3.org/2001/XMLSchema#string',\n",
              "   'Property: State name URI: http://example.org/statename Type: DatatypeProperty Domain: http://example.org/State Range: http://www.w3.org/2001/XMLSchema#string']}]"
            ]
          },
          "execution_count": 440,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses_prop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d208e5d2-0357-47ec-a1f9-81addbe2cbd7",
      "metadata": {
        "id": "d208e5d2-0357-47ec-a1f9-81addbe2cbd7"
      },
      "source": [
        "### Try using RAG below"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2654f577-2e7c-4488-8483-371ea041bb1d",
      "metadata": {
        "id": "2654f577-2e7c-4488-8483-371ea041bb1d"
      },
      "source": [
        "First retrieve the relevant classes and properties using RAG retriever and then pass them to LLM using a loop and ask whether each class/property is relevant or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e4784e8-beff-4c95-87b1-73f9b61af561",
      "metadata": {
        "id": "0e4784e8-beff-4c95-87b1-73f9b61af561"
      },
      "outputs": [],
      "source": [
        "model_name = \"all-MiniLM-L6-v2.gguf2.f16.gguf\"\n",
        "gpt4all_kwargs = {\"allow_download\": \"True\"}\n",
        "embeddings = GPT4AllEmbeddings(model_name=model_name, gpt4all_kwargs=gpt4all_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d2a04a-e6fa-44f3-81f0-280156fb58ed",
      "metadata": {
        "id": "f2d2a04a-e6fa-44f3-81f0-280156fb58ed"
      },
      "outputs": [],
      "source": [
        "vectorstore = Chroma.from_texts(texts=docs, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eae15c9b-5b61-4d92-8cfe-6532913e0b12",
      "metadata": {
        "id": "eae15c9b-5b61-4d92-8cfe-6532913e0b12",
        "outputId": "f2847b46-05aa-4351-a60f-2f903916fdc8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q8_0.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 6.67 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOG token        = 2 '</s>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  6828.64 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '7'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "llm = LlamaCpp(\n",
        "    model_path=\"llama-2-7b-chat.Q8_0.gguf\",\n",
        "    n_gpu_layers=-1,\n",
        "    n_batch=512,\n",
        "    n_ctx=2048,\n",
        "    f16_kv=True,\n",
        "    verbose=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d74aaacb-10c9-40c4-be8e-c9cb03c97b79",
      "metadata": {
        "id": "d74aaacb-10c9-40c4-be8e-c9cb03c97b79"
      },
      "outputs": [],
      "source": [
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf6ed5d0-2868-4129-a3e8-181434604176",
      "metadata": {
        "id": "bf6ed5d0-2868-4129-a3e8-181434604176"
      },
      "outputs": [],
      "source": [
        "question = \"What are the names of the events that happen on 2015-12-12?\"\n",
        "retrieved_docs = retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "624f66a5-8e57-4b3c-9d9c-dda9caa9d93c",
      "metadata": {
        "id": "624f66a5-8e57-4b3c-9d9c-dda9caa9d93c",
        "outputId": "ed54e19f-3408-43a2-c06d-007309bbf243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='e002b501-7672-41e4-bb47-745cf2cfd7c9', metadata={}, page_content='Class: Event URI: http://example.org/Event'),\n",
              " Document(id='a4dd52df-23c6-417b-9124-5aeb5ce200be', metadata={}, page_content='Property: Event On URI: http://example.org/eventon Type: ObjectProperty Domain: http://example.org/Calendar Range: http://example.org/Event'),\n",
              " Document(id='05d233bd-a7da-403e-afb8-9c012f43e9f6', metadata={}, page_content='Class: Event Category URI: http://example.org/EventCategory'),\n",
              " Document(id='190c9272-2a41-465f-844c-fd524b1fa198', metadata={}, page_content='Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event')]"
            ]
          },
          "execution_count": 421,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieved_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0f739ab-711e-470e-ab3e-bb1fed7b1635",
      "metadata": {
        "id": "b0f739ab-711e-470e-ab3e-bb1fed7b1635"
      },
      "source": [
        "### Retrieval is not working well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf74dd57-bcb6-44de-86cf-eeb169b44748",
      "metadata": {
        "id": "cf74dd57-bcb6-44de-86cf-eeb169b44748"
      },
      "outputs": [],
      "source": [
        "yes_docs = []\n",
        "no_docs = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eeb933d-9289-49ab-9553-3d7f6f45280d",
      "metadata": {
        "id": "7eeb933d-9289-49ab-9553-3d7f6f45280d",
        "outputId": "3680abab-1db4-476c-d540-747579921548"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    80 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16500.62 ms /    95 tokens\n",
            "Llama.generate: 57 prefix-match hit, remaining 47 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    47 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27775.38 ms /    80 tokens\n",
            "Llama.generate: 57 prefix-match hit, remaining 25 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    25 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12115.55 ms /    38 tokens\n",
            "Llama.generate: 57 prefix-match hit, remaining 47 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    47 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4539.90 ms /    49 tokens\n"
          ]
        }
      ],
      "source": [
        "for i, doc in enumerate(retrieved_docs):\n",
        "    custom_prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\",\n",
        "is the following class/property relevant?\n",
        "\n",
        "### Class/Property:\n",
        "{doc.page_content}\n",
        "\n",
        "### Answer (only YES or NO):\"\"\"\n",
        "\n",
        "    response = llm.invoke(custom_prompt)\n",
        "    decision = response.strip().upper()\n",
        "\n",
        "    result = {\n",
        "        \"index\": i + 1,\n",
        "        \"doc\": doc.page_content.strip(),\n",
        "        \"response\": decision\n",
        "    }\n",
        "\n",
        "    if \"YES\" in decision:\n",
        "        yes_docs.append(result)\n",
        "    else:\n",
        "        no_docs.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e56c57b3-41fe-447e-869d-2949ae3d6973",
      "metadata": {
        "id": "e56c57b3-41fe-447e-869d-2949ae3d6973",
        "outputId": "59cdd287-4be5-4d4f-8aa3-f9623dc66632"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'index': 4,\n",
              "  'doc': 'Property: Event At URI: http://example.org/eventat Type: ObjectProperty Domain: http://example.org/Location Range: http://example.org/Event',\n",
              "  'response': 'YES'}]"
            ]
          },
          "execution_count": 424,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yes_docs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953c85d1-4246-4781-838e-1653819f5276",
      "metadata": {
        "id": "953c85d1-4246-4781-838e-1653819f5276"
      },
      "source": [
        "##### Since this does not work well, just follow the langchain pipeline without the loop checking one by one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01050ba0-11d7-407c-9554-f31012f34aaf",
      "metadata": {
        "id": "01050ba0-11d7-407c-9554-f31012f34aaf",
        "outputId": "dba980ee-0b16-4ea7-ddeb-e3ee22ee882f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 181 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   181 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   32851.37 ms /   211 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant Classes and Properties:\n",
            "Event, EventOn, 2015-12-12\n",
            "EventCategory, EventAt, http://example.org/Calendar\n"
          ]
        }
      ],
      "source": [
        "rag_prompt = PromptTemplate.from_template(\n",
        "    \"Given RDF schema below, extract only the relevant classes and properties that match the following question.\\n\"\n",
        "    \"### RDF Schema:\\n\"\n",
        "    \"{context}\\n\\n\"\n",
        "    \"### Question:\\n\"\n",
        "    \"{question}\\n\\n\"\n",
        "    \"### Answer (List only the relevant classes and properties, separated by commas):\\n\"\n",
        ")\n",
        "\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "qa_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | rag_prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "question = \"What are the names of the events that happen on 2015-12-12?\"\n",
        "response = qa_chain.invoke(question)\n",
        "\n",
        "print(\"Relevant Classes and Properties:\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d21977a-2996-4d73-93fb-6ab7943ca236",
      "metadata": {
        "id": "3d21977a-2996-4d73-93fb-6ab7943ca236"
      },
      "source": [
        "Not working well!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c73bae2-fa75-4449-9f30-c8d474879d49",
      "metadata": {
        "id": "6c73bae2-fa75-4449-9f30-c8d474879d49"
      },
      "source": [
        "### Try Graph Traversal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36eb20e4-b491-4f34-bfa3-0c8a14236f8d",
      "metadata": {
        "id": "36eb20e4-b491-4f34-bfa3-0c8a14236f8d",
        "outputId": "3fbc2101-a160-4521-a7cb-2920e93a8573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Graph identifier=N2597b14458d14adba490849834cf5d88 (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "execution_count": 426,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ttl_graph = Graph()\n",
        "ttl_graph.parse(\"only_events.ttl\", format=\"turtle\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76387ce3-a221-4464-be6a-8e7ec15a261f",
      "metadata": {
        "id": "76387ce3-a221-4464-be6a-8e7ec15a261f"
      },
      "outputs": [],
      "source": [
        "G = nx.MultiDiGraph()  #a multi edge directed graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7ee3c6b-bdb0-483f-a155-e999b6faf071",
      "metadata": {
        "id": "d7ee3c6b-bdb0-483f-a155-e999b6faf071"
      },
      "outputs": [],
      "source": [
        "for s in ttl_graph.subjects(RDF.type, OWL.Class):\n",
        "    label = ttl_graph.value(s, RDFS.label)\n",
        "    G.add_node(str(s), type=\"Class\", label=str(label) if label else s.split(\"/\")[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "febbbd0b-2c8c-42f5-afa3-b87b59d2007d",
      "metadata": {
        "id": "febbbd0b-2c8c-42f5-afa3-b87b59d2007d"
      },
      "outputs": [],
      "source": [
        "for s in ttl_graph.subjects(RDF.type, OWL.ObjectProperty):\n",
        "    domain = ttl_graph.value(s, RDFS.domain)\n",
        "    range_ = ttl_graph.value(s, RDFS.range)\n",
        "    label = ttl_graph.value(s, RDFS.label)\n",
        "    prop_label = str(label) if label else s.split(\"/\")[-1]\n",
        "    if domain and range_:\n",
        "        G.add_edge(str(domain), str(range_), type=\"ObjectProperty\", label=prop_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67aafe85-be2e-4197-aeaa-d461c29871be",
      "metadata": {
        "id": "67aafe85-be2e-4197-aeaa-d461c29871be"
      },
      "outputs": [],
      "source": [
        "for s in ttl_graph.subjects(RDF.type, OWL.DatatypeProperty):\n",
        "    domain = ttl_graph.value(s, RDFS.domain)\n",
        "    range_ = ttl_graph.value(s, RDFS.range)\n",
        "    label = ttl_graph.value(s, RDFS.label)\n",
        "    prop_label = str(label) if label else s.split(\"/\")[-1]\n",
        "    if domain:\n",
        "        G.add_edge(str(domain), str(range_) if range_ else \"Literal\", type=\"DatatypeProperty\", label=prop_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a55882b-3d3f-4ac7-8c8f-c2bc469dbf93",
      "metadata": {
        "id": "0a55882b-3d3f-4ac7-8c8f-c2bc469dbf93",
        "outputId": "60d2ccef-1f9d-47f8-a409-fe3daca21960"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "http://example.org/eventcatclassid\n",
            "http://example.org/eventcatname_it\n",
            "http://example.org/eventclassid\n",
            "http://example.org/eventdescr_it\n",
            "http://example.org/eventimage_url\n",
            "http://example.org/eventname_it\n",
            "http://example.org/calendarclassid\n",
            "http://example.org/day\n",
            "http://example.org/end_time\n",
            "http://example.org/start_time\n",
            "http://example.org/locationclassid\n",
            "http://example.org/address\n",
            "http://example.org/statecode\n",
            "http://example.org/statename\n"
          ]
        }
      ],
      "source": [
        "for s in ttl_graph.subjects(RDF.type, OWL.DatatypeProperty):\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d901d26c-81a8-4210-9406-19cf3abd89c0",
      "metadata": {
        "id": "d901d26c-81a8-4210-9406-19cf3abd89c0"
      },
      "outputs": [],
      "source": [
        "combined_labels = defaultdict(list)\n",
        "for u, v, k, d in G.edges(data=True, keys=True):\n",
        "    combined_labels[(u, v)].append(d['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0b950b7-ee11-44d5-a715-74c20b4894ca",
      "metadata": {
        "id": "f0b950b7-ee11-44d5-a715-74c20b4894ca",
        "outputId": "c82d44df-284c-4e54-8ef7-bcecb5c77867"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pos = nx.circular_layout(G)\n",
        "edge_labels = {k: \"\\n\".join(v) for k, v in combined_labels.items()}\n",
        "node_labels = {n: d.get('label', n.split(\"/\")[-1]) for n, d in G.nodes(data=True)}\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "nx.draw(G, pos, with_labels=True, labels=node_labels, node_size=2000, node_color='skyblue', font_size=10, arrows=True)\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "plt.title(\"RDF Schema as Graph\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dce525b4-710b-44a6-8222-709fe3f0b67f",
      "metadata": {
        "id": "dce525b4-710b-44a6-8222-709fe3f0b67f",
        "outputId": "5731bb5e-1fb0-4aea-aecf-6698433bd08b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NodeView(('http://example.org/Event', 'http://example.org/Calendar', 'http://example.org/Location', 'http://example.org/EventCategory', 'http://example.org/State', 'http://www.w3.org/2001/XMLSchema#string', 'http://www.w3.org/2001/XMLSchema#date'))"
            ]
          },
          "execution_count": 450,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "G.nodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f361f490-5c4e-4776-8af5-bd5a7ad4ceea",
      "metadata": {
        "id": "f361f490-5c4e-4776-8af5-bd5a7ad4ceea"
      },
      "outputs": [],
      "source": [
        "question = \"What are the names of the events happen on 2015-12-12?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "323fe5aa-49e8-4db4-b010-15a684d68af6",
      "metadata": {
        "id": "323fe5aa-49e8-4db4-b010-15a684d68af6"
      },
      "outputs": [],
      "source": [
        "class_nodes = [n for n in G.nodes() if not n.startswith(\"http://www.w3.org/2001/XMLSchema#\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02d12364-fde6-49ab-9a8f-03b2bcd0628a",
      "metadata": {
        "id": "02d12364-fde6-49ab-9a8f-03b2bcd0628a",
        "outputId": "16b709b4-08a1-48df-eb17-7bea5acbed21"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['http://example.org/Event',\n",
              " 'http://example.org/Calendar',\n",
              " 'http://example.org/Location',\n",
              " 'http://example.org/EventCategory',\n",
              " 'http://example.org/State']"
            ]
          },
          "execution_count": 453,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6a6a4cf-fb9c-4d12-aa44-2cb9db6a47b8",
      "metadata": {
        "id": "c6a6a4cf-fb9c-4d12-aa44-2cb9db6a47b8"
      },
      "outputs": [],
      "source": [
        "prompt = (\n",
        "    \"You are a semantic web expert.\\n\"\n",
        "    \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "    + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "    \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "    f\"'{question}'\\n\\n\"\n",
        "    \"List only the relevant classes\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a374118d-2bca-4d11-b8fb-b898bb307bac",
      "metadata": {
        "id": "a374118d-2bca-4d11-b8fb-b898bb307bac",
        "outputId": "cb796c8e-b10f-4887-80a4-85d5e4aa4def"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 81 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16250.19 ms /    18 tokens\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt, max_tokens=150, temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a8cb05-4b57-43ed-a96b-004dbb181892",
      "metadata": {
        "id": "93a8cb05-4b57-43ed-a96b-004dbb181892",
        "outputId": "429f16f2-e0d1-4ae8-d2cf-d1aa0a6df54c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'.\\n\\nNote: The RDF data is in Turtle format.'"
            ]
          },
          "execution_count": 443,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd4efe23-624c-4bb7-8c29-295328e59c84",
      "metadata": {
        "id": "dd4efe23-624c-4bb7-8c29-295328e59c84"
      },
      "source": [
        "#### Answer is correct! Next try to optimize the prompt to avoid much explaination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c64a2c-d993-4cb2-84f1-638bc9d72903",
      "metadata": {
        "id": "85c64a2c-d993-4cb2-84f1-638bc9d72903"
      },
      "outputs": [],
      "source": [
        "prompt = (\n",
        "    \"You are a semantic web expert.\\n\"\n",
        "    \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "    + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "    \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "    f\"'{question}'\\n\\n\"\n",
        "    \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb6a5843-7d21-49be-a426-97bdb1fe5982",
      "metadata": {
        "id": "cb6a5843-7d21-49be-a426-97bdb1fe5982",
        "outputId": "f701a085-ff13-4292-958a-0e8f56c26e09"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 58 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9377.36 ms /    53 tokens\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt, max_tokens=150, temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c14c82e2-d4f8-4c1d-a9a5-b24b90e7812e",
      "metadata": {
        "id": "c14c82e2-d4f8-4c1d-a9a5-b24b90e7812e",
        "outputId": "25693df5-5b3e-42de-eedf-acb8644fc6d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nAnswer: Event, Calendar'"
            ]
          },
          "execution_count": 293,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a36f36c0-7322-4078-8cbd-212b44e26fbe",
      "metadata": {
        "id": "a36f36c0-7322-4078-8cbd-212b44e26fbe"
      },
      "outputs": [],
      "source": [
        "question = \"What are the names and addresses of the events belong to 'Kids' category?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1fa099-8018-4ccd-b3b8-b023cc603898",
      "metadata": {
        "id": "7b1fa099-8018-4ccd-b3b8-b023cc603898"
      },
      "outputs": [],
      "source": [
        "prompt = (\n",
        "    \"You are a semantic web expert.\\n\"\n",
        "    \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "    + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "    \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "    f\"'{question}'\\n\\n\"\n",
        "    \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c3769ff-6891-45c5-94b4-2da174b08dde",
      "metadata": {
        "id": "4c3769ff-6891-45c5-94b4-2da174b08dde",
        "outputId": "927806cd-6bd1-48a8-dc51-f12413ef417b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 58 prefix-match hit, remaining 42 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    42 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13451.58 ms /    54 tokens\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt, max_tokens=150, temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e213ac4-6b78-4c4a-bd90-a7cbe9ddd31b",
      "metadata": {
        "id": "4e213ac4-6b78-4c4a-bd90-a7cbe9ddd31b",
        "outputId": "818e9ada-c8e8-479e-a7b9-3ed517952f0f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n\\nPlease answer this question as a semantic web expert.'"
            ]
          },
          "execution_count": 460,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37840db5-ea1c-4c84-b56a-afc82ca41673",
      "metadata": {
        "id": "37840db5-ea1c-4c84-b56a-afc82ca41673"
      },
      "source": [
        "#### Performs quite well! Write a function to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414ee578-8add-4671-ba77-380c178a33f0",
      "metadata": {
        "id": "414ee578-8add-4671-ba77-380c178a33f0"
      },
      "outputs": [],
      "source": [
        "questions_responses = []\n",
        "\n",
        "def ask_question(question, G, llm):\n",
        "\n",
        "    class_nodes = [n for n in G.nodes() if not n.startswith(\"http://www.w3.org/2001/XMLSchema#\")]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a semantic web expert.\\n\"\n",
        "        \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "        + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "        \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    relevant_classes = response.strip()\n",
        "\n",
        "    questions_responses.append({\n",
        "        \"question\": question,\n",
        "        \"response\": relevant_classes\n",
        "    })\n",
        "\n",
        "    return relevant_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c471a8-37ab-4688-bb31-3dacc44a33aa",
      "metadata": {
        "scrolled": true,
        "id": "66c471a8-37ab-4688-bb31-3dacc44a33aa",
        "outputId": "2c523ff6-2da8-4b07-d351-ff6fbe3e035f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 103 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     8 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6894.88 ms /     9 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Answer: Event, Calendar'"
            ]
          },
          "execution_count": 347,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happen on 2015-12-12?\"\n",
        "ask_question(question_1, G, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "505d2494-393f-4343-9963-c02d17077ab2",
      "metadata": {
        "id": "505d2494-393f-4343-9963-c02d17077ab2",
        "outputId": "dfca7fdb-6ee5-488d-d6bf-1ded5652d4a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 99 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9441.08 ms /    13 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Answer: Event, Calendar, EventCategory.'"
            ]
          },
          "execution_count": 352,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "ask_question(question_2, G, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68bbe159-e47e-4f5e-a6bc-3a5b1dae5081",
      "metadata": {
        "id": "68bbe159-e47e-4f5e-a6bc-3a5b1dae5081",
        "outputId": "9baa67ed-3a3c-4767-c80f-e45770177304"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 57 prefix-match hit, remaining 47 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    47 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11449.81 ms /    56 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Answer: Event, Calendar, Location'"
            ]
          },
          "execution_count": 354,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12 \"\n",
        "ask_question(question_3, G, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fa6f569-73d5-471f-962c-d26cb9f6e11a",
      "metadata": {
        "id": "0fa6f569-73d5-471f-962c-d26cb9f6e11a",
        "outputId": "ef6d1da7-8101-46c7-8e3b-ff6541180ca4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 98 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    54 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41936.82 ms /    55 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"For example, if the answer is:\\n'Event, Calendar'\\nthen the given query is looking for information about events that are scheduled to start at 11.30am, and the relevant classes are 'Event' and 'Calendar'.\""
            ]
          },
          "execution_count": 357,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30? \"\n",
        "ask_question(question_4, G, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a29e7046-3f0e-4e37-b986-d2573e42937f",
      "metadata": {
        "id": "a29e7046-3f0e-4e37-b986-d2573e42937f",
        "outputId": "0fe17d7b-6848-49b2-ebfc-39daad1016e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 93 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7831.34 ms /    12 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Class names: Event, Calendar, State'"
            ]
          },
          "execution_count": 368,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status? \"\n",
        "ask_question(question_5, G, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd34d2b6-fd9a-4f46-96fc-dd5f764edb39",
      "metadata": {
        "id": "fd34d2b6-fd9a-4f46-96fc-dd5f764edb39",
        "outputId": "24b5c321-6c39-400b-a6eb-37917b4fefa1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'response': 'Please let me know if you need more information or clarification.'},\n",
              " {'question': 'What are the names of the events happen on 2015-12-12?',\n",
              "  'response': 'Answer: Event, Calendar'},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': 'Note: The RDF schema may include other classes as well, but these are the ones that are relevant for this specific query.'},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': ''},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': 'Answer: Event, Calendar, EventCategory.'},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12 ',\n",
              "  'response': 'Answer: Event, Calendar, Location'},\n",
              " {'question': 'What are the events scheduled to start at 11.30? ',\n",
              "  'response': ''},\n",
              " {'question': 'What are the events scheduled to start at 11.30? ',\n",
              "  'response': \"For example, if the answer is:\\n'Event, Calendar'\\nthen the given query is looking for information about events that are scheduled to start at 11.30am, and the relevant classes are 'Event' and 'Calendar'.\"},\n",
              " {'question': 'Can you give the events and their status details? ',\n",
              "  'response': \"Note: 'Event' is already mentioned in the question, so it does not need to be included in the answer.\"},\n",
              " {'question': 'Can you give the events and their status details? ',\n",
              "  'response': ''},\n",
              " {'question': 'Can you give the events and their status details? ',\n",
              "  'response': '(Note: You can assume that the given RDF schema is complete and consistent, and that all relevant information has been provided for each class)'},\n",
              " {'question': 'Can you give the events and their status details? ',\n",
              "  'response': ''},\n",
              " {'question': 'Can you give the events and their status details? ',\n",
              "  'response': \"For example, if the question was about an event called 'Conference', the answer would be:\\n'Event, Calendar, State'\"},\n",
              " {'question': 'Can you give the event names and their status? ',\n",
              "  'response': \"Example: If the answer is 'Event, Calendar', then you would write: 'Event, Calendar'.\"},\n",
              " {'question': 'Can you give the event names and their status? ',\n",
              "  'response': ''},\n",
              " {'question': 'Can you give the event names and their status? ',\n",
              "  'response': ''},\n",
              " {'question': 'Can you give the event names and their status? ',\n",
              "  'response': 'Class names: Event, Calendar, State'}]"
            ]
          },
          "execution_count": 369,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a30909-c4cf-43cf-8e66-7d830fec18bb",
      "metadata": {
        "id": "91a30909-c4cf-43cf-8e66-7d830fec18bb"
      },
      "outputs": [],
      "source": [
        "#Extract edges from G and save into property list\n",
        "def extract_all_properties(G):\n",
        "    property_lines = []\n",
        "\n",
        "    for u, v, k, d in G.edges(data=True, keys=True):\n",
        "        line = f\"- {d['label']} (from {u.split('/')[-1]} to {v.split('/')[-1]})\"\n",
        "        property_lines.append(line)\n",
        "\n",
        "    return property_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330a5d29-4c9a-4be5-bf65-a6452e8e0c78",
      "metadata": {
        "id": "330a5d29-4c9a-4be5-bf65-a6452e8e0c78"
      },
      "outputs": [],
      "source": [
        "questions_answers = []\n",
        "\n",
        "def ask_relevant_properties(question, relevant_classes, G, llm):\n",
        "    property_lines = extract_all_properties(G)\n",
        "\n",
        "    print(property_lines)\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a semantic web expert.\\n\"\n",
        "        \"The following RDF classes have been identified as relevant to the question:\\n\"\n",
        "        + \", \".join(c.split('/')[-1] for c in relevant_classes) + \"\\n\\n\"\n",
        "        \"Here are all properties (edges) in the RDF graph:\\n\"\n",
        "        + \"\\n\".join(property_lines) +\n",
        "        \"\\n\\nWhich of these properties are relevant for answering the question:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        \"List the property names only, separated by commas. Do not include any explanation or extra text.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #print(response)\n",
        "\n",
        "    relevant_properties = response.strip()\n",
        "\n",
        "    questions_answers.append({\n",
        "        \"question\": question,\n",
        "        \"relevant_classes\": relevant_classes,\n",
        "        \"relevant_properties\": relevant_properties\n",
        "    })\n",
        "\n",
        "    return relevant_properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbf9e520-9a3a-4129-aff7-e162830e4d73",
      "metadata": {
        "id": "bbf9e520-9a3a-4129-aff7-e162830e4d73",
        "outputId": "7784d3bc-d42e-4557-b984-db191d17fa5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['- Event State (from Event to State)', '- Event Class ID (from Event to XMLSchema#string)', '- Event Description (IT) (from Event to XMLSchema#string)', '- Event Image URL (from Event to XMLSchema#string)', '- Event Name (from Event to XMLSchema#string)', '- Event On (from Calendar to Event)', '- Calendar Class ID (from Calendar to XMLSchema#string)', '- EndTime (from Calendar to XMLSchema#string)', '- StartTime (from Calendar to XMLSchema#string)', '- day (from Calendar to XMLSchema#date)', '- Event At (from Location to Event)', '- Location Class ID (from Location to XMLSchema#string)', '- Address (from Location to XMLSchema#string)', '- Has Category (from EventCategory to Event)', '- Eventcat Classid (from EventCategory to XMLSchema#string)', '- Eventcat Name (from EventCategory to XMLSchema#string)', '- State code (from State to XMLSchema#string)', '- State name (from State to XMLSchema#string)']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 326 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   326 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19039.68 ms /   327 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: \n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes_for_prop = ['http://example.org/Event', 'http://example.org/Calendar' ]\n",
        "relevant_properties = ask_relevant_properties(question, relevant_classes_for_prop, G, llm)\n",
        "print(\"Relevant properties:\", relevant_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "575f8544-df67-4406-aeb5-af1b7f6d83bc",
      "metadata": {
        "id": "575f8544-df67-4406-aeb5-af1b7f6d83bc",
        "outputId": "5bbb3873-3720-496b-c7b6-5858b8c88b4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'relevant_classes': ['http://example.org/Event',\n",
              "   'http://example.org/Calendar'],\n",
              "  'relevant_properties': ''}]"
            ]
          },
          "execution_count": 465,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_answers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cc21375-7d7c-4920-aa20-3ac828991ec1",
      "metadata": {
        "id": "7cc21375-7d7c-4920-aa20-3ac828991ec1"
      },
      "source": [
        "#### Put all together without manually givin the classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ef3a00-be6b-4292-a479-82d54e8b903b",
      "metadata": {
        "id": "65ef3a00-be6b-4292-a479-82d54e8b903b"
      },
      "outputs": [],
      "source": [
        "def get_class_uri_map(G):\n",
        "    return {n.split('/')[-1]: n for n in G.nodes() if not n.startswith(\"http://www.w3.org/2001/XMLSchema#\")}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2481e2cb-2146-4ac6-9e19-48cb09176bed",
      "metadata": {
        "id": "2481e2cb-2146-4ac6-9e19-48cb09176bed",
        "outputId": "69b6a3d5-2b32-4344-cca8-309ae735ec44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 85 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    85 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12525.43 ms /    94 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 321 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['- Event State (from Event to State)', '- Event Class ID (from Event to XMLSchema#string)', '- Event Description (IT) (from Event to XMLSchema#string)', '- Event Image URL (from Event to XMLSchema#string)', '- Event Name (from Event to XMLSchema#string)', '- Event On (from Calendar to Event)', '- Calendar Class ID (from Calendar to XMLSchema#string)', '- EndTime (from Calendar to XMLSchema#string)', '- StartTime (from Calendar to XMLSchema#string)', '- day (from Calendar to XMLSchema#date)', '- Event At (from Location to Event)', '- Location Class ID (from Location to XMLSchema#string)', '- Address (from Location to XMLSchema#string)', '- Has Category (from EventCategory to Event)', '- Eventcat Classid (from EventCategory to XMLSchema#string)', '- Eventcat Name (from EventCategory to XMLSchema#string)', '- State code (from State to XMLSchema#string)', '- State name (from State to XMLSchema#string)']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   321 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17536.35 ms /   322 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: \n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "question_3 = \"What are the locations of the events happen on 2015-12-12 \"\n",
        "question_4 = \"What are the events scheduled to start at 11.30? \"\n",
        "question_5 = \"Can you give the event names and their status? \"\n",
        "\n",
        "# Ask LLM for relevant classes\n",
        "class_string = ask_question(question_5, G, llm)\n",
        "#print(f\"class_string: {class_string}\")\n",
        "\n",
        "# Map those to URIs\n",
        "class_uri_map = get_class_uri_map(G)\n",
        "class_names = [name.strip() for name in class_string.split(\",\")]\n",
        "relevant_class_uris = [class_uri_map[name] for name in class_names if name in class_uri_map]\n",
        "#print(f\"relevant_class_uris: {relevant_class_uris}\")\n",
        "\n",
        "# Ask for relevant properties\n",
        "relevant_properties = ask_relevant_properties(question_5, relevant_class_uris, G, llm)\n",
        "\n",
        "print(\"Relevant properties:\", relevant_properties)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02600f6d-578d-447d-99b4-182673dff6b2",
      "metadata": {
        "id": "02600f6d-578d-447d-99b4-182673dff6b2",
        "outputId": "b6e4cf27-f133-4d58-dd55-03b0a446c615"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'relevant_classes': [],\n",
              "  'relevant_properties': 'Event State, Event Name, StartTime, EndTime, Day'},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'relevant_classes': [],\n",
              "  'relevant_properties': 'Answer: Event At, Eventcat Classid, Eventcat Name, State code, State name'},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12 ',\n",
              "  'relevant_classes': ['http://example.org/Calendar'],\n",
              "  'relevant_properties': 'Please provide a list of property names, without any extra information or explanation.'},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12 ',\n",
              "  'relevant_classes': [],\n",
              "  'relevant_properties': 'Please respond with the list of relevant property names only.'},\n",
              " {'question': 'What are the events scheduled to start at 11.30? ',\n",
              "  'relevant_classes': [],\n",
              "  'relevant_properties': ''}]"
            ]
          },
          "execution_count": 564,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_answers"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "895d3f95-99c5-4d1f-a6bb-1a1d94ac1f28",
      "metadata": {
        "id": "895d3f95-99c5-4d1f-a6bb-1a1d94ac1f28"
      },
      "source": [
        "## Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c6b96f3-d567-446a-9482-1617bf4a7690",
      "metadata": {
        "id": "9c6b96f3-d567-446a-9482-1617bf4a7690"
      },
      "outputs": [],
      "source": [
        "questions_responses = []\n",
        "\n",
        "def ask_question(question, G, llm):\n",
        "\n",
        "    class_nodes = [n for n in G.nodes() if not n.startswith(\"http://www.w3.org/2001/XMLSchema#\")]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a semantic web expert.\\n\"\n",
        "        \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "        + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "        \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    relevant_classes = response['choices'][0]['text'].strip()\n",
        "\n",
        "    questions_responses.append({\n",
        "        \"question\": question,\n",
        "        \"response\": relevant_classes\n",
        "    })\n",
        "\n",
        "    return relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d33978ec-dfdc-4cd1-aab9-ed46fa2bb9e1",
      "metadata": {
        "id": "d33978ec-dfdc-4cd1-aab9-ed46fa2bb9e1"
      },
      "outputs": [],
      "source": [
        "#Extract edges from G and save into property list\n",
        "def extract_all_properties(G):\n",
        "    property_lines = []\n",
        "\n",
        "    for u, v, k, d in G.edges(data=True, keys=True):\n",
        "        line = f\"- {d['label']} (from {u.split('/')[-1]} to {v.split('/')[-1]})\"\n",
        "        property_lines.append(line)\n",
        "\n",
        "    return property_lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a619a45a-cd5f-4f8d-a88f-82b655a905ca",
      "metadata": {
        "id": "a619a45a-cd5f-4f8d-a88f-82b655a905ca"
      },
      "outputs": [],
      "source": [
        "questions_answers = []\n",
        "\n",
        "def ask_relevant_properties(question, relevant_classes, G, llm):\n",
        "    property_lines = extract_all_properties(G)\n",
        "\n",
        "    print(property_lines)\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a semantic web expert.\\n\"\n",
        "        \"The following RDF classes have been identified as relevant to the question:\\n\"\n",
        "        + \", \".join(relevant_classes) + \"\\n\\n\"\n",
        "        \"Here are all properties (edges) in the RDF graph:\\n\"\n",
        "        + \"\\n\".join(property_lines) +\n",
        "        \"\\n\\nWhich of these properties are relevant for answering the question:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        \"List the property names only, separated by commas. Do not include any explanation or extra text.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #print(response)\n",
        "\n",
        "    relevant_properties = response['choices'][0]['text'].strip()\n",
        "\n",
        "    questions_answers.append({\n",
        "        \"question\": question,\n",
        "        \"relevant_classes\": relevant_classes,\n",
        "        \"relevant_properties\": relevant_properties\n",
        "    })\n",
        "\n",
        "    return relevant_properties\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62c88ca-7630-4880-95fc-05c6a43f225d",
      "metadata": {
        "id": "a62c88ca-7630-4880-95fc-05c6a43f225d"
      },
      "outputs": [],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "question_3 = \"What are the locations of the events happen on 2015-12-12 \"\n",
        "question_4 = \"What are the events scheduled to start at 11.30? \"\n",
        "question_5 = \"Can you give the event names and their status? \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b73e272-3f58-4225-a21b-cbc774802e25",
      "metadata": {
        "id": "3b73e272-3f58-4225-a21b-cbc774802e25",
        "outputId": "28478636-1312-40e9-8ea9-f6dff3ccff8f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 91 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    91 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13285.57 ms /    98 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 325 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['- Event State (from Event to State)', '- Event Class ID (from Event to XMLSchema#string)', '- Event Description (IT) (from Event to XMLSchema#string)', '- Event Image URL (from Event to XMLSchema#string)', '- Event Name (from Event to XMLSchema#string)', '- Event On (from Calendar to Event)', '- Calendar Class ID (from Calendar to XMLSchema#string)', '- EndTime (from Calendar to XMLSchema#string)', '- StartTime (from Calendar to XMLSchema#string)', '- day (from Calendar to XMLSchema#date)', '- Event At (from Location to Event)', '- Location Class ID (from Location to XMLSchema#string)', '- Address (from Location to XMLSchema#string)', '- Has Category (from EventCategory to Event)', '- Eventcat Classid (from EventCategory to XMLSchema#string)', '- Eventcat Name (from EventCategory to XMLSchema#string)', '- State code (from State to XMLSchema#string)', '- State name (from State to XMLSchema#string)']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   325 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27591.49 ms /   337 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: Event Name, Event On, Event At, Has Category\n"
          ]
        }
      ],
      "source": [
        "class_string = ask_question(question_1, G, llm)\n",
        "class_names = [name.strip() for name in class_string.split(\",\")]\n",
        "relevant_properties = ask_relevant_properties(question_1, class_names, G, llm)\n",
        "\n",
        "print(\"Relevant properties:\", relevant_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b4d736fe-2b76-4e5e-b939-8b4c2c450912",
      "metadata": {
        "id": "b4d736fe-2b76-4e5e-b939-8b4c2c450912",
        "outputId": "60bf930a-eba4-4789-ef09-d730437eaa96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 95 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    95 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13295.80 ms /   106 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 332 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['- Event State (from Event to State)', '- Event Class ID (from Event to XMLSchema#string)', '- Event Description (IT) (from Event to XMLSchema#string)', '- Event Image URL (from Event to XMLSchema#string)', '- Event Name (from Event to XMLSchema#string)', '- Event On (from Calendar to Event)', '- Calendar Class ID (from Calendar to XMLSchema#string)', '- EndTime (from Calendar to XMLSchema#string)', '- StartTime (from Calendar to XMLSchema#string)', '- day (from Calendar to XMLSchema#date)', '- Event At (from Location to Event)', '- Location Class ID (from Location to XMLSchema#string)', '- Address (from Location to XMLSchema#string)', '- Has Category (from EventCategory to Event)', '- Eventcat Classid (from EventCategory to XMLSchema#string)', '- Eventcat Name (from EventCategory to XMLSchema#string)', '- State code (from State to XMLSchema#string)', '- State name (from State to XMLSchema#string)']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   332 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18179.86 ms /   333 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: \n"
          ]
        }
      ],
      "source": [
        "class_string = ask_question(question_2, G, llm)\n",
        "class_names = [name.strip() for name in class_string.split(\",\")]\n",
        "relevant_properties = ask_relevant_properties(question_2, class_names, G, llm)\n",
        "\n",
        "print(\"Relevant properties:\", relevant_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "721a6c7d-0cff-4cea-900a-8967a5f6b8b0",
      "metadata": {
        "id": "721a6c7d-0cff-4cea-900a-8967a5f6b8b0",
        "outputId": "0d2f3494-af70-4d4e-beb3-66e53786366a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 9 prefix-match hit, remaining 85 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    85 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5075.51 ms /    86 tokens\n",
            "Llama.generate: 9 prefix-match hit, remaining 313 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['- Event State (from Event to State)', '- Event Class ID (from Event to XMLSchema#string)', '- Event Description (IT) (from Event to XMLSchema#string)', '- Event Image URL (from Event to XMLSchema#string)', '- Event Name (from Event to XMLSchema#string)', '- Event On (from Calendar to Event)', '- Calendar Class ID (from Calendar to XMLSchema#string)', '- EndTime (from Calendar to XMLSchema#string)', '- StartTime (from Calendar to XMLSchema#string)', '- day (from Calendar to XMLSchema#date)', '- Event At (from Location to Event)', '- Location Class ID (from Location to XMLSchema#string)', '- Address (from Location to XMLSchema#string)', '- Has Category (from EventCategory to Event)', '- Eventcat Classid (from EventCategory to XMLSchema#string)', '- Eventcat Name (from EventCategory to XMLSchema#string)', '- State code (from State to XMLSchema#string)', '- State name (from State to XMLSchema#string)']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   313 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   23462.86 ms /   319 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: Event Name, Event State\n"
          ]
        }
      ],
      "source": [
        "class_string = ask_question(question_3, G, llm)\n",
        "class_names = [name.strip() for name in class_string.split(\",\")]\n",
        "relevant_properties = ask_relevant_properties(question_3, class_names, G, llm)\n",
        "\n",
        "print(\"Relevant properties:\", relevant_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640e7217-505e-41b2-be18-c77494061655",
      "metadata": {
        "id": "640e7217-505e-41b2-be18-c77494061655",
        "outputId": "f5d9b9cd-7007-4253-b2fc-0a1d909fa870"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 98 prefix-match hit, remaining 1 prompt tokens to eval\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[724], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_string \u001b[38;5;241m=\u001b[39m \u001b[43mask_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m class_names \u001b[38;5;241m=\u001b[39m [name\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m class_string\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      3\u001b[0m relevant_properties \u001b[38;5;241m=\u001b[39m ask_relevant_properties(question_4, class_names, G, llm)\n",
            "Cell \u001b[0;32mIn[720], line 16\u001b[0m, in \u001b[0;36mask_question\u001b[0;34m(question, G, llm)\u001b[0m\n\u001b[1;32m      5\u001b[0m class_nodes \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://www.w3.org/2001/XMLSchema#\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a semantic web expert.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven the following classes in an RDF schema:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m relevant_classes \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     20\u001b[0m questions_responses\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: relevant_classes\n\u001b[1;32m     23\u001b[0m })\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1900\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1838\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1863\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[CreateCompletionResponse, Iterator[CreateCompletionStreamResponse]]:\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m \n\u001b[1;32m   1866\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;124;03m        Response object containing the generated text.\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1833\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     chunks: Iterator[CreateCompletionStreamResponse] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[0;32m-> 1833\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1318\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1316\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1317\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1318\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:910\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    912\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    913\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    914\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    929\u001b[0m         )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:643\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    639\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    641\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    642\u001b[0m )\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/_internals.py:300\u001b[0m, in \u001b[0;36mLlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: LlamaBatch):\n\u001b[0;32m--> 300\u001b[0m     return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class_string = ask_question(question_4, G, llm)\n",
        "class_names = [name.strip() for name in class_string.split(\",\")]\n",
        "relevant_properties = ask_relevant_properties(question_4, class_names, G, llm)\n",
        "\n",
        "print(\"Relevant properties:\", relevant_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7370c535-8db1-47e9-933b-e1ccb1417fce",
      "metadata": {
        "id": "7370c535-8db1-47e9-933b-e1ccb1417fce"
      },
      "outputs": [],
      "source": [
        "class_string = ask_question(question_5, G, llm)\n",
        "class_names = [name.strip() for name in class_string.split(\",\")]\n",
        "relevant_properties = ask_relevant_properties(question_5, class_names, G, llm)\n",
        "\n",
        "print(\"Relevant properties:\", relevant_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f172d26a-ef2c-4ace-bfdb-f1d594553484",
      "metadata": {
        "id": "f172d26a-ef2c-4ace-bfdb-f1d594553484",
        "outputId": "f86cb5f9-c492-4782-d953-ad5d05d8b66d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'relevant_classes': ['Event', 'Calendar', 'EventCategory'],\n",
              "  'relevant_properties': 'Event Name, Event On, Event At, Has Category'},\n",
              " {'question': 'Can you give the event names and their status? ',\n",
              "  'relevant_classes': [\"For example:\\n'What are the names of the events happening on 2015-12-12?'\\nrelevant class names: Event\",\n",
              "   'Calendar',\n",
              "   'Location'],\n",
              "  'relevant_properties': 'Event Name, Event State'},\n",
              " {'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'relevant_classes': ['Please help me understand which classes are relevant for this task.'],\n",
              "  'relevant_properties': 'Event State, Event Class ID, Event Description, Event Image URL, Event Name, Event On, StartTime, EndTime, day, Event At'},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12 ',\n",
              "  'relevant_classes': ['For example:  Event', 'Calendar', 'Location'],\n",
              "  'relevant_properties': ''},\n",
              " {'question': 'Can you give the event names and their status? ',\n",
              "  'relevant_classes': [''],\n",
              "  'relevant_properties': 'Event Name, Event State'}]"
            ]
          },
          "execution_count": 625,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4daf521d-d01e-4062-b09d-de0b1bae835b",
      "metadata": {
        "id": "4daf521d-d01e-4062-b09d-de0b1bae835b"
      },
      "outputs": [],
      "source": [
        "question = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "relevant_classes = [\n",
        "    \"http://example.org/ontology/Event\",\n",
        "    \"http://example.org/ontology/Calendar\",\n",
        "    \"http://example.org/ontology/EventCategory\"\n",
        "]\n",
        "relevant_properties = [\n",
        "    \"http://example.org/ontology/eventName\",\n",
        "    \"http://example.org/ontology/eventOn\",\n",
        "    \"http://example.org/ontology/eventAt\",\n",
        "    \"http://example.org/ontology/hasCategory\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3a300aa-ee60-425b-9e74-e8b9edccf121",
      "metadata": {
        "id": "a3a300aa-ee60-425b-9e74-e8b9edccf121"
      },
      "outputs": [],
      "source": [
        "prompt = f\"\"\"\n",
        "You are a semantic web and SPARQL expert.\n",
        "\n",
        "I have an RDF schema with the following relevant classes:\n",
        "{relevant_classes}\n",
        "\n",
        "And the following relevant properties:\n",
        "{relevant_properties}\n",
        "\n",
        "Now, write a SPARQL query that answers the question:\n",
        "\"{question}\"\n",
        "\n",
        "Use full URIs in the query. Use standard SPARQL syntax and assume the data uses these exact URIs. The query should return the event name and address only for events in the 'Kids' category.\n",
        "Do not include explanations or comments. Output only the SPARQL query.\n",
        "###SPARQL query\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67a674a3-fbf0-4b9f-ac22-1153caaccab1",
      "metadata": {
        "id": "67a674a3-fbf0-4b9f-ac22-1153caaccab1",
        "outputId": "a00fab24-6975-4e48-ac74-fb8812056831"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 163 prefix-match hit, remaining 72 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    72 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   29139.02 ms /    97 tokens\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt, max_tokens=50, temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c9f2afa-64de-4f3e-8317-764b96c43e31",
      "metadata": {
        "id": "7c9f2afa-64de-4f3e-8317-764b96c43e31",
        "outputId": "b3e494f6-4989-4baa-fc11-c0d0503a58ab"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'cmpl-34517c00-463d-4f68-ae23-7c0bf55b2b97',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1744324025,\n",
              " 'model': 'llama-2-7b-chat.Q8_0.gguf',\n",
              " 'choices': [{'text': '---\\n\\n\\nNote: This is a sample query, you will need to modify it to fit your specific use case.',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'stop'}],\n",
              " 'usage': {'prompt_tokens': 235, 'completion_tokens': 25, 'total_tokens': 260}}"
            ]
          },
          "execution_count": 890,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b9a50bb-4e0b-44ed-92d6-8aafb11f6dce",
      "metadata": {
        "id": "9b9a50bb-4e0b-44ed-92d6-8aafb11f6dce"
      },
      "source": [
        "#### Here manually creating a method to extract properties and feed to LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7bd5563-5401-465a-b070-72ccdc9a5d07",
      "metadata": {
        "id": "e7bd5563-5401-465a-b070-72ccdc9a5d07"
      },
      "outputs": [],
      "source": [
        "questions_responses = []\n",
        "\n",
        "def ask_question(question, G, llm):\n",
        "\n",
        "    class_nodes = [n for n in G.nodes() if not n.startswith(\"http://www.w3.org/2001/XMLSchema#\")]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a semantic web expert.\\n\"\n",
        "        \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "        + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "        \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    response_text = response['choices'][0]['text'].strip()\n",
        "    relevant_classes = [cls.strip() for cls in response_text.split(\",\") if cls.strip()]\n",
        "\n",
        "    questions_responses.append({\n",
        "        \"question\": question,\n",
        "        \"response\": relevant_classes\n",
        "    })\n",
        "\n",
        "    return relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e04e6e5-47c0-42eb-9e27-c4fc35a53c21",
      "metadata": {
        "id": "5e04e6e5-47c0-42eb-9e27-c4fc35a53c21",
        "outputId": "d2fc22b7-26d1-412d-c379-00607df5797a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 103 prompt tokens to eval\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[731], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhat are the names of the events happening on 2015-12-12?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m relevant_classes \u001b[38;5;241m=\u001b[39m \u001b[43mask_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(relevant_classes) \u001b[38;5;66;03m# takes a lot of time\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[730], line 16\u001b[0m, in \u001b[0;36mask_question\u001b[0;34m(question, G, llm)\u001b[0m\n\u001b[1;32m      5\u001b[0m class_nodes \u001b[38;5;241m=\u001b[39m [n \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m G\u001b[38;5;241m.\u001b[39mnodes() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp://www.w3.org/2001/XMLSchema#\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are a semantic web expert.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGiven the following classes in an RDF schema:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     14\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m response_text \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m     19\u001b[0m relevant_classes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response_text\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1900\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1838\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1863\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[CreateCompletionResponse, Iterator[CreateCompletionStreamResponse]]:\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m \n\u001b[1;32m   1866\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;124;03m        Response object containing the generated text.\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1833\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     chunks: Iterator[CreateCompletionStreamResponse] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[0;32m-> 1833\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1318\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1316\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1317\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1318\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:910\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    912\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    913\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    914\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    929\u001b[0m         )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:643\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    639\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    641\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    642\u001b[0m )\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/_internals.py:300\u001b[0m, in \u001b[0;36mLlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: LlamaBatch):\n\u001b[0;32m--> 300\u001b[0m     return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "relevant_classes = ask_question(question, G, llm)\n",
        "print(relevant_classes) # takes a lot of time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd446f53-2c53-493a-a0f2-02e68c2a4588",
      "metadata": {
        "id": "cd446f53-2c53-493a-a0f2-02e68c2a4588"
      },
      "outputs": [],
      "source": [
        "def extract_properties_for_class(G, class_uri):\n",
        "    props = []\n",
        "    for u,v,d in G.edges(data=True):\n",
        "        if u == class_uri or v == class_uri:\n",
        "            direction = \"->\" if u == class_uri else \"<-\"\n",
        "            props.append({\n",
        "                \"domain\": u,\n",
        "                \"range\": v,\n",
        "                \"type\": d[\"type\"],\n",
        "                \"label\": d[\"label\"],\n",
        "                \"direction\": direction\n",
        "            })\n",
        "    return props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb56cd65-d72a-4ee5-a24b-10cfa1fb23f7",
      "metadata": {
        "id": "eb56cd65-d72a-4ee5-a24b-10cfa1fb23f7"
      },
      "outputs": [],
      "source": [
        "def ask_relevant_properties(question, class_name, properties, llm):\n",
        "    if not properties:\n",
        "        return []\n",
        "\n",
        "    props_description = \"\\n\".join(f\"Property: {p['label']} | Type: {p['type']} | Domain: {p['domain'].split('/')[-1]} | Range: {p['range'].split('/')[-1]}\"\n",
        "        for p in properties)\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are a semantic web expert.\\n\"\n",
        "        f\"Given the following properties related to the class '{class_name}':\\n\\n\"\n",
        "        f\"{props_description}\\n\\n\"\n",
        "        f\"Which of these properties are relevant for answering the question:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        f\"List only the relevant property labels, separated by commas, without explanation.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "    return [prop.strip() for prop in response.strip().split(',') if prop.strip()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3eb4eb2b-0c6a-4d78-af8c-677b5c00cff8",
      "metadata": {
        "id": "3eb4eb2b-0c6a-4d78-af8c-677b5c00cff8",
        "outputId": "6f1510d1-d595-4220-9df3-0a94107c0fd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 4 prefix-match hit, remaining 238 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   238 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   32935.31 ms /   258 tokens\n",
            "Llama.generate: 19 prefix-match hit, remaining 163 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties for class 'Event': ['Event State', 'Event Class ID', 'Event Name', 'Event On', 'Event At', 'Has Category']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    8167.94 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   163 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   22564.81 ms /   180 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties for class 'Calendar': ['Event On | Calendar Class ID | EndTime | StartTime | day']\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ['http://example.org/Event', 'http://example.org/Calendar' ]\n",
        "\n",
        "for cls_uri in relevant_classes:\n",
        "    cls_name = cls_uri.split(\"/\")[-1]\n",
        "    props = extract_properties_for_class(G, cls_uri)\n",
        "    relevant_props = ask_relevant_properties(question, cls_name, props, llm)\n",
        "    print(f\"Relevant properties for class '{cls_name}': {relevant_props}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f28a3b-caeb-4e78-bf6f-836d35d1306d",
      "metadata": {
        "id": "32f28a3b-caeb-4e78-bf6f-836d35d1306d"
      },
      "outputs": [],
      "source": [
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "relevant_classes = ask_question(question, G, llm)\n",
        "\n",
        "for cls_name in relevant_classes:\n",
        "    #cls_name = cls_uri.split(\"/\")[-1]\n",
        "    props = extract_properties_for_class(G, cls_name)\n",
        "    relevant_props = ask_relevant_properties(question, cls_name, props, llm)\n",
        "    print(f\"Relevant properties for class '{cls_name}': {relevant_props}\")#takes a lot of time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aff4a68a-e728-4adc-97ed-9007157608df",
      "metadata": {
        "id": "aff4a68a-e728-4adc-97ed-9007157608df"
      },
      "source": [
        "### Try DDT algorithm for edge traversal"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85504630-36d3-476e-9114-2a0433d42cfd",
      "metadata": {
        "id": "85504630-36d3-476e-9114-2a0433d42cfd"
      },
      "source": [
        "since relevant class selection works well with Graph approach, use DDT algorithm to extract edges and feed into LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d51c6ff-4fba-4086-9030-bf3cbc34ea77",
      "metadata": {
        "id": "4d51c6ff-4fba-4086-9030-bf3cbc34ea77"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/Location\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1399c92c-3e24-469a-84d1-e4601de2cd66",
      "metadata": {
        "id": "1399c92c-3e24-469a-84d1-e4601de2cd66"
      },
      "outputs": [],
      "source": [
        "def dtt_traverse(graph, start_class, max_depth=2):\n",
        "    from collections import deque\n",
        "    visited = set()\n",
        "    queue = deque([(start_class, 0)])\n",
        "    collected_properties = []\n",
        "\n",
        "    while queue:\n",
        "        current_node, depth = queue.popleft()\n",
        "        if depth > max_depth or current_node in visited:\n",
        "            continue\n",
        "        visited.add(current_node)\n",
        "\n",
        "        for _, neighbor, key, data in graph.out_edges(current_node, keys=True, data=True):\n",
        "            property_info = {\n",
        "                \"from\": current_node,\n",
        "                \"to\": neighbor,\n",
        "                \"label\": data.get(\"label\", \"\"),\n",
        "                \"type\": data.get(\"type\", \"\"),\n",
        "            }\n",
        "            collected_properties.append(property_info)\n",
        "            queue.append((neighbor, depth + 1))\n",
        "\n",
        "    return collected_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5da4bb4e-c4b3-4acc-9344-bd4a1c3805e4",
      "metadata": {
        "id": "5da4bb4e-c4b3-4acc-9344-bd4a1c3805e4"
      },
      "outputs": [],
      "source": [
        "all_collected_props = []\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    all_collected_props.extend(props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "742f754a-cd76-4c3f-a5c3-cca86bfbfbed",
      "metadata": {
        "scrolled": true,
        "id": "742f754a-cd76-4c3f-a5c3-cca86bfbfbed",
        "outputId": "a9d64004-68f3-4dfb-c780-4279dfaf5eeb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'from': 'http://example.org/Location',\n",
              "  'to': 'http://example.org/Event',\n",
              "  'label': 'Event At',\n",
              "  'type': 'ObjectProperty'},\n",
              " {'from': 'http://example.org/Location',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Location Class ID',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Location',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Address',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://example.org/State',\n",
              "  'label': 'Event State',\n",
              "  'type': 'ObjectProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Class ID',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Description (IT)',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Image URL',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Name',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State code',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State name',\n",
              "  'type': 'DatatypeProperty'}]"
            ]
          },
          "execution_count": 825,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1efbff9e-c968-4630-85aa-9dc2b5c77225",
      "metadata": {
        "id": "1efbff9e-c968-4630-85aa-9dc2b5c77225",
        "outputId": "b8589607-3f57-4c1d-dfbc-cd8f59d985ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'from': 'http://example.org/Event',\n",
              "  'to': 'http://example.org/State',\n",
              "  'label': 'Event State',\n",
              "  'type': 'ObjectProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Class ID',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Description (IT)',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Image URL',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Name',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State code',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State name',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Calendar',\n",
              "  'to': 'http://example.org/Event',\n",
              "  'label': 'Event On',\n",
              "  'type': 'ObjectProperty'},\n",
              " {'from': 'http://example.org/Calendar',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Calendar Class ID',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Calendar',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'EndTime',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Calendar',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'StartTime',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Calendar',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#date',\n",
              "  'label': 'day',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://example.org/State',\n",
              "  'label': 'Event State',\n",
              "  'type': 'ObjectProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Class ID',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Description (IT)',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Image URL',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Name',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State code',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State name',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Location',\n",
              "  'to': 'http://example.org/Event',\n",
              "  'label': 'Event At',\n",
              "  'type': 'ObjectProperty'},\n",
              " {'from': 'http://example.org/Location',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Location Class ID',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Location',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Address',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://example.org/State',\n",
              "  'label': 'Event State',\n",
              "  'type': 'ObjectProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Class ID',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Description (IT)',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Image URL',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/Event',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'Event Name',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State code',\n",
              "  'type': 'DatatypeProperty'},\n",
              " {'from': 'http://example.org/State',\n",
              "  'to': 'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'label': 'State name',\n",
              "  'type': 'DatatypeProperty'}]"
            ]
          },
          "execution_count": 826,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_collected_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "558d762a-4053-4c1d-825a-e23a0d9c5252",
      "metadata": {
        "id": "558d762a-4053-4c1d-825a-e23a0d9c5252"
      },
      "outputs": [],
      "source": [
        "def prepare_property_prompt(question, class_uri, props):\n",
        "    class_label = class_uri.split(\"/\")[-1]\n",
        "    prop_lines = \"\\n\".join(\n",
        "        f\"Property: {p['label']} | Type: {p['type']} | To: {p['to'].split('/')[-1]}\"\n",
        "        for p in props\n",
        "    )\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are a semantic web expert.\\n\"\n",
        "        f\"The following properties are related to the class '{class_label}':\\n\\n\"\n",
        "        f\"{prop_lines}\\n\\n\"\n",
        "        f\"Which of these properties are relevant for answering the question:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        f\"List only the property labels, separated by commas, without explanation.\"\n",
        "    )\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a4c1ce-7070-4377-a090-8030c8402567",
      "metadata": {
        "id": "e0a4c1ce-7070-4377-a090-8030c8402567",
        "outputId": "804486af-61d9-42db-d479-f93fcefc366b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 200 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  723396.57 ms /    21 tokens\n",
            "Llama.generate: 18 prefix-match hit, remaining 269 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: Event | Relevant Properties: {'id': 'cmpl-97572094-00db-40a8-80dd-06c0ea1c6a6a', 'object': 'text_completion', 'created': 1744275173, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\nAnswer:\\nState, Event Name, Event Image URL, State code, State name', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 201, 'completion_tokens': 19, 'total_tokens': 220}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   269 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    42 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time = 1480558.77 ms /   311 tokens\n",
            "Llama.generate: 18 prefix-match hit, remaining 233 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: Calendar | Relevant Properties: {'id': 'cmpl-0be4841d-1d82-495c-91ba-da2b38ab2381', 'object': 'text_completion', 'created': 1744275897, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\nEvent On\\nCalendar Class ID\\nEndTime\\nStartTime\\nday\\nEvent State\\nEvent Class ID\\nEvent Description (IT)\\nEvent Image URL\\nEvent Name\\nState code\\nState name', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 287, 'completion_tokens': 42, 'total_tokens': 329}}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   233 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  442981.15 ms /   245 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: Location | Relevant Properties: {'id': 'cmpl-04ae66da-417b-4518-833b-8ee241641734', 'object': 'text_completion', 'created': 1744277377, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 251, 'completion_tokens': 12, 'total_tokens': 263}}\n"
          ]
        }
      ],
      "source": [
        "question_ = \"'What are the locations of the events happen on 2015-12-12\"\n",
        "\n",
        "for cls_uri in relevant_classes:\n",
        "    props = dtt_traverse(G, cls_uri)\n",
        "    if not props:\n",
        "        continue\n",
        "\n",
        "    prompt = prepare_property_prompt(question_, cls_uri, props)\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #relevant_props = [p.strip() for p in response['choices'][0]['message']['content'].split(\",\") if p.strip()]\n",
        "    print(f\"Class: {cls_uri.split('/')[-1]} | Relevant Properties: {response}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28f2e911-6815-4a83-9eac-e648f864f4a8",
      "metadata": {
        "id": "28f2e911-6815-4a83-9eac-e648f864f4a8"
      },
      "source": [
        "#### Provide the extracted relevant classes to the traversal function and try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93a94ec9-f8a5-40c2-a2d5-7b2725ccbdef",
      "metadata": {
        "id": "93a94ec9-f8a5-40c2-a2d5-7b2725ccbdef"
      },
      "outputs": [],
      "source": [
        "def dtt_traverse(graph, start_class, max_depth=2):\n",
        "    from collections import deque\n",
        "    visited = set()\n",
        "    queue = deque([(start_class, 0)])\n",
        "    collected_properties = []\n",
        "\n",
        "    while queue:\n",
        "        current_node, depth = queue.popleft()\n",
        "        if depth > max_depth or current_node in visited:\n",
        "            continue\n",
        "        visited.add(current_node)\n",
        "\n",
        "        for _, neighbor, key, data in graph.out_edges(current_node, keys=True, data=True):\n",
        "            property_info = {\n",
        "                \"from\": current_node,\n",
        "                \"to\": neighbor,\n",
        "                \"label\": data.get(\"label\", \"\"),\n",
        "                \"type\": data.get(\"type\", \"\"),\n",
        "            }\n",
        "            collected_properties.append(property_info)\n",
        "            queue.append((neighbor, depth + 1))\n",
        "\n",
        "    return collected_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "279b7578-926a-4231-88cf-324e2521256b",
      "metadata": {
        "id": "279b7578-926a-4231-88cf-324e2521256b"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/Location\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbcc4998-7e0c-4b15-b965-60c6f630627e",
      "metadata": {
        "id": "bbcc4998-7e0c-4b15-b965-60c6f630627e"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fead4c7-8a02-43e1-8fc8-b9e1602b2a9c",
      "metadata": {
        "id": "9fead4c7-8a02-43e1-8fc8-b9e1602b2a9c",
        "outputId": "978f2eac-7dcc-44a7-e402-2b60bd52ce8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Description (IT)',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Location',\n",
              "  'http://example.org/Event',\n",
              "  'Event At',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://example.org/State',\n",
              "  'Event State',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Image URL',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Calendar Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'StartTime',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Location',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Location Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State code',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://example.org/Event',\n",
              "  'Event On',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Location',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Address',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#date',\n",
              "  'day',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'EndTime',\n",
              "  'DatatypeProperty')]"
            ]
          },
          "execution_count": 857,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_collected_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcbb3c9b-2146-452a-8fd3-620fcfe2199d",
      "metadata": {
        "id": "dcbb3c9b-2146-452a-8fd3-620fcfe2199d"
      },
      "outputs": [],
      "source": [
        "def prepare_property_prompt(question, relevant_classes, all_collected_props):\n",
        "\n",
        "    all_collected_props_dict = [\n",
        "        {\"label\": prop[2], \"type\": prop[3], \"from\": prop[0], \"to\": prop[1]}\n",
        "        for prop in all_collected_props\n",
        "    ]\n",
        "\n",
        "    prop_lines = \"\\n\".join(\n",
        "        f\"Property: {p['label']} | Type: {p['type']} | From: {p['from']} | To: {p['to']}\"\n",
        "        for p in all_collected_props_dict\n",
        "    )\n",
        "\n",
        "    prompt = (\n",
        "        f\"You are a semantic web expert.\\n\"\n",
        "        f\"The following properties are related to the classes: {', '.join(relevant_classes)}:\\n\\n\"\n",
        "        f\"{prop_lines}\\n\\n\"\n",
        "        f\"Which of these properties are relevant for answering the question:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        f\"List only the property labels, separated by commas, without explanation.\"\n",
        "    )\n",
        "\n",
        "    return prompt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7682e458-81ff-4e52-bb95-688e0dced4d5",
      "metadata": {
        "id": "7682e458-81ff-4e52-bb95-688e0dced4d5",
        "outputId": "b16e6e3c-b5ac-4b50-e56c-4c6b21c586ce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 4 prefix-match hit, remaining 691 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   692 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   70833.99 ms /   723 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar', 'http://example.org/Location'] | Relevant Properties: {'id': 'cmpl-b8750b09-c59d-4754-a2a4-40626dabfc37', 'object': 'text_completion', 'created': 1744321379, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\nEvent Description, Event At, Event State, Event Image URL, Event On, Event Class ID, Event Name, Address, day, EndTime.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 695, 'completion_tokens': 31, 'total_tokens': 726}}\n"
          ]
        }
      ],
      "source": [
        "question_ = \"'What are the locations of the events happen on 2015-12-12\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf1ce687-7b0c-4e55-82a8-f13c68dc6023",
      "metadata": {
        "id": "cf1ce687-7b0c-4e55-82a8-f13c68dc6023"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ad5384-eb2b-46aa-939b-e2ca4d6dcb7e",
      "metadata": {
        "id": "66ad5384-eb2b-46aa-939b-e2ca4d6dcb7e"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e12837c-14a1-465c-9e15-604076cc1736",
      "metadata": {
        "id": "2e12837c-14a1-465c-9e15-604076cc1736",
        "outputId": "7cfad025-ce4c-4a1a-9346-a4d603b95a25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Description (IT)',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://example.org/State',\n",
              "  'Event State',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Image URL',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Calendar Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'StartTime',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State code',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://example.org/Event',\n",
              "  'Event On',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#date',\n",
              "  'day',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'EndTime',\n",
              "  'DatatypeProperty')]"
            ]
          },
          "execution_count": 866,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_collected_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e64c69a-f12d-414c-b681-802d8919006a",
      "metadata": {
        "id": "3e64c69a-f12d-414c-b681-802d8919006a",
        "outputId": "0bf69f7c-2057-4d5a-bc9f-337f4fce9fa5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 33 prefix-match hit, remaining 540 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /  1052 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   56332.98 ms /  1084 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar'] | Relevant Properties: {'id': 'cmpl-49d9df69-43d2-4617-a37e-de059aea40ae', 'object': 'text_completion', 'created': 1744322048, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\nEvent Description, Event State, Event Image URL, StartTime, EndTime, State code, Event On, Event Class ID, Event Name, day.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 573, 'completion_tokens': 32, 'total_tokens': 605}}\n"
          ]
        }
      ],
      "source": [
        "question_ = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b5d338f-926c-441c-866c-cb8238b30247",
      "metadata": {
        "id": "7b5d338f-926c-441c-866c-cb8238b30247"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/EventCategory\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79980a71-4cb5-4020-bd9a-6b6e79423f05",
      "metadata": {
        "id": "79980a71-4cb5-4020-bd9a-6b6e79423f05"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a9dfe5c-88eb-4d02-aa5b-7093a3f4dc40",
      "metadata": {
        "id": "2a9dfe5c-88eb-4d02-aa5b-7093a3f4dc40",
        "outputId": "0d59bcbc-a6b0-493a-b2d4-b7ab764ff013"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Description (IT)',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/EventCategory',\n",
              "  'http://example.org/Event',\n",
              "  'Has Category',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://example.org/State',\n",
              "  'Event State',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Image URL',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Calendar Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'StartTime',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State code',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/EventCategory',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Eventcat Name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/EventCategory',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Eventcat Classid',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://example.org/Event',\n",
              "  'Event On',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#date',\n",
              "  'day',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'EndTime',\n",
              "  'DatatypeProperty')]"
            ]
          },
          "execution_count": 870,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_collected_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7744fe8a-b49a-4e47-bed7-ea1d6920e1ca",
      "metadata": {
        "id": "7744fe8a-b49a-4e47-bed7-ea1d6920e1ca",
        "outputId": "b0efa2af-ddca-4132-c50b-050fb27a48ad"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 33 prefix-match hit, remaining 665 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   665 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   73762.39 ms /   703 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar', 'http://example.org/EventCategory'] | Relevant Properties: {'id': 'cmpl-e309dd5c-f57c-40d8-b6f6-5c7ada517362', 'object': 'text_completion', 'created': 1744322777, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\nAnswer:\\nEvent Name, Event Category, Event Image URL, State name, Eventcat Name, Eventcat Classid, Event On, StartTime, EndTime, Day.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 698, 'completion_tokens': 38, 'total_tokens': 736}}\n"
          ]
        }
      ],
      "source": [
        "question_ = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c06b7341-e34f-4323-be00-014b3867cd71",
      "metadata": {
        "id": "c06b7341-e34f-4323-be00-014b3867cd71"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcb239e8-065b-4504-b7b7-9dd8496edc0c",
      "metadata": {
        "id": "fcb239e8-065b-4504-b7b7-9dd8496edc0c"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8693d6b1-39eb-4466-85af-1befa71bff97",
      "metadata": {
        "id": "8693d6b1-39eb-4466-85af-1befa71bff97",
        "outputId": "db766438-1c1b-4db1-a5fb-40170e341f61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Description (IT)',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://example.org/State',\n",
              "  'Event State',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Image URL',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Calendar Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'StartTime',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State code',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://example.org/Event',\n",
              "  'Event On',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#date',\n",
              "  'day',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'EndTime',\n",
              "  'DatatypeProperty')]"
            ]
          },
          "execution_count": 874,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_collected_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77129296-6731-4695-902e-d1323d65ff7e",
      "metadata": {
        "id": "77129296-6731-4695-902e-d1323d65ff7e",
        "outputId": "ec2fd360-687f-40c5-c25e-e9f8e7570d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 33 prefix-match hit, remaining 535 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   535 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   57659.87 ms /   566 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar'] | Relevant Properties: {'id': 'cmpl-790e41ff-7e15-42da-8536-22f370f7f495', 'object': 'text_completion', 'created': 1744323142, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\nEvent Description, Event State, Event Image URL, StartTime, EndTime, State code, Event On, Event Class ID, Event Name, day', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 568, 'completion_tokens': 31, 'total_tokens': 599}}\n"
          ]
        }
      ],
      "source": [
        "question_ = \"What are the events scheduled to start at 11.30? \"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f993720-a1fb-4117-bf40-f3852519329f",
      "metadata": {
        "id": "5f993720-a1fb-4117-bf40-f3852519329f"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/State\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e12e56a1-8a7f-4752-9c9e-22e7a157c277",
      "metadata": {
        "id": "e12e56a1-8a7f-4752-9c9e-22e7a157c277"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f1fba86-b4d3-4bdf-8dee-7efa460b8da9",
      "metadata": {
        "id": "4f1fba86-b4d3-4bdf-8dee-7efa460b8da9",
        "outputId": "d9da7c81-6868-4385-a971-aedc01e50233"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Description (IT)',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://example.org/State',\n",
              "  'Event State',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Image URL',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Calendar Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'StartTime',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State code',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://example.org/Event',\n",
              "  'Event On',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#date',\n",
              "  'day',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'EndTime',\n",
              "  'DatatypeProperty')]"
            ]
          },
          "execution_count": 879,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_collected_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fca825c-bbca-402c-8e2a-6bf859bab58d",
      "metadata": {
        "id": "4fca825c-bbca-402c-8e2a-6bf859bab58d",
        "outputId": "e8405e49-1057-4c9c-f7f7-e10e7699ae5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 33 prefix-match hit, remaining 537 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   537 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   53024.66 ms /   560 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar', 'http://example.org/State'] | Relevant Properties: {'id': 'cmpl-db83f058-b745-4c0a-8704-6c9c2494e095', 'object': 'text_completion', 'created': 1744323394, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\nEvent Names, State Names, Event On, Event Class ID, Event Name, Start Time, End Time.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 570, 'completion_tokens': 23, 'total_tokens': 593}}\n"
          ]
        }
      ],
      "source": [
        "question_ = \"Can you give the event names and their status \"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f6bbc8a-ca82-46f9-bed4-7caaed217b23",
      "metadata": {
        "id": "7f6bbc8a-ca82-46f9-bed4-7caaed217b23"
      },
      "source": [
        "### Try SPARQL query generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a66cb82f-a7bd-4aee-8029-817118ac3108",
      "metadata": {
        "id": "a66cb82f-a7bd-4aee-8029-817118ac3108"
      },
      "outputs": [],
      "source": [
        "question = \"What are the names and addresses of the events happening on 2015-12-12?\"\n",
        "classes_involved = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/Location\"]\n",
        "relevant_properties = [\n",
        "    \"Event Name (DatatypeProperty)\",\n",
        "    \"Event On (DatatypeProperty)\",\n",
        "    \"Event At (ObjectProperty)\",\n",
        "    \"Address (DatatypeProperty)\",\n",
        "    \"StartTime (DatatypeProperty)\",\n",
        "    \"EndTime (DatatypeProperty)\"\n",
        "]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Classes involved:\n",
        "{chr(10).join(f\"- {c}\" for c in classes_involved)}\n",
        "\n",
        "Relevant Properties:\n",
        "{chr(10).join(f\"- {p}\" for p in relevant_properties)}\n",
        "\n",
        "Question:\n",
        "\"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2cbfbcb-0856-4795-ba9b-39b929a4f11e",
      "metadata": {
        "id": "a2cbfbcb-0856-4795-ba9b-39b929a4f11e",
        "outputId": "231e9e37-bf80-4a68-dd51-af4e1b8d1786"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 10 prefix-match hit, remaining 178 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   178 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   149 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  141342.57 ms /   327 tokens\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt, max_tokens=150, temperature=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd2306db-79fb-4797-babe-396487cf47c9",
      "metadata": {
        "id": "cd2306db-79fb-4797-babe-396487cf47c9",
        "outputId": "b28481f8-45b4-4a0c-aa81-8b55b539652b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'cmpl-55416b13-291f-4fdd-9cc1-682beda11175',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1744357158,\n",
              " 'model': 'llama-2-7b-chat.Q8_0.gguf',\n",
              " 'choices': [{'text': '\\n?query = SELECT ?eventName ?eventAddress ?startTime ?endTime\\nWHERE {\\n  ?event a http://example.org/Event .\\n  ?event On ?dateTime .\\n  ?dateTime DatatypeProperty \"Event On\" ?eventOn .\\n  ?eventOn ?dateTime .\\n  ?dateTime ObjectProperty \"Event At\" ?eventAt .\\n  ?eventAt ?location .\\n  ?location DatatypeProperty \"Address\" ?eventAddress .\\n  ?eventStart ?startTime .\\n  ?eventEnd ?endTime .\\n  FILTER(?eventStart <= \"2015-12-12\" AND ?eventEnd >= \"2',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'length'}],\n",
              " 'usage': {'prompt_tokens': 188,\n",
              "  'completion_tokens': 150,\n",
              "  'total_tokens': 338}}"
            ]
          },
          "execution_count": 953,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46a6be4-3491-4b0d-9f12-bdc1dc6d4408",
      "metadata": {
        "id": "c46a6be4-3491-4b0d-9f12-bdc1dc6d4408"
      },
      "source": [
        "### Try with few show examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "beea8d3f-caa2-402e-bbbc-61746571d000",
      "metadata": {
        "id": "beea8d3f-caa2-402e-bbbc-61746571d000",
        "outputId": "e783acbe-4762-409d-b56c-ef39ba613a94"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 499 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   112 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  115936.86 ms /   146 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT ?eventName ?eventAddress\n",
            "WHERE {\n",
            "  ?event a ex:Event ;\n",
            "         ex:EventName ?eventName ;\n",
            "         ex:eventon ?calendar ;\n",
            "         ?calendar ex:start_time ?startTime ;\n",
            "            ex:end_time ?endTime ;\n",
            "            ex:day ?eventDate .\n",
            "  FILTER(?eventDate = \"2015-12-12\")\n",
            "}\n",
            "\n",
            "Note: Please use the ontology provided to answer the user's question.\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names and addresses of the events happening on 2015-12-12?\"\n",
        "classes_involved = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/Location\"]\n",
        "relevant_properties = [\n",
        "    \"Event Name (DatatypeProperty)\",\n",
        "    \"Event On (DatatypeProperty)\",\n",
        "    \"Event At (ObjectProperty)\",\n",
        "    \"Address (DatatypeProperty)\",\n",
        "    \"StartTime (DatatypeProperty)\",\n",
        "    \"EndTime (DatatypeProperty)\"\n",
        "]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Classes involved:\n",
        "- {', '.join(classes_involved)}\n",
        "\n",
        "Relevant Properties:\n",
        "- {', '.join(relevant_properties)}\n",
        "\n",
        "Here are a few example SPARQL queries to help you understand the format:\n",
        "\n",
        "### EXAMPLE 1 ###\n",
        "Question: What are the names and locations of the events that occurred in 2015-10-01?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?eventLocation\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventat ?eventAt .\n",
        "  ?eventAt ex:address ?eventLocation .\n",
        "  ?calendar  ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "### EXAMPLE 2 ###\n",
        "Question: What are the start and end times of the events happening in 2015-12-03?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?startTime ?endTime\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ?calendar ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "Now, please generate the SPARQL query for the user's question: \"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3fd3c07-5fdc-4b93-a0e3-0255a30ea81f",
      "metadata": {
        "id": "a3fd3c07-5fdc-4b93-a0e3-0255a30ea81f",
        "outputId": "b6a24c7a-c3d3-4e12-b921-d5e36d459ded"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 55 prefix-match hit, remaining 482 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   482 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    97 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  109098.93 ms /   579 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT ?eventName\n",
            "WHERE {\n",
            "  ?event a ex:Event ;\n",
            "         ex:EventName ?eventName .\n",
            "  ?eventOn ?calendar .\n",
            "  ?calendar ex:day ?eventDate .\n",
            "  FILTER(?eventDate = \"2015-12-12\")\n",
            "}\n",
            "\n",
            "Note: The output will be a single SPARQL query that will retrieve the names of the events occurring on the specified date.\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "classes_involved = [\"http://example.org/Event\", \"http://example.org/Calendar\"]\n",
        "relevant_properties = [\n",
        "    \"Event Name (DatatypeProperty)\",\n",
        "    \"Event Description (DatatypeProperty)\",\n",
        "    \"Event On (ObjectProperty)\",\n",
        "    \"Event At (ObjectProperty)\",\n",
        "    \"Event State (ObjectProperty)\",\n",
        "    \"Event Image URL (DatatypeProperty)\",\n",
        "    \"Event Class ID (DatatypeProperty)\",\n",
        "    \"day (DatatypeProperty)\"\n",
        "]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Classes involved:\n",
        "- {', '.join(classes_involved)}\n",
        "\n",
        "Relevant Properties:\n",
        "- {', '.join(relevant_properties)}\n",
        "\n",
        "Here are a few example SPARQL queries to help you understand the format:\n",
        "\n",
        "### EXAMPLE 1 ###\n",
        "Question: What are the names and locations of the events that occurred in 2015-10-01?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?eventLocation\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventat ?eventAt .\n",
        "  ?eventAt ex:address ?eventLocation .\n",
        "  ?calendar  ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "### EXAMPLE 2 ###\n",
        "Question: What are the start and end times of the events happening in 2015-12-03?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?startTime ?endTime\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar .\n",
        "         ?calendar ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "Now, please generate the SPARQL query for the user's question: \"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34234f29-965c-433e-8616-52389d6f94b7",
      "metadata": {
        "id": "34234f29-965c-433e-8616-52389d6f94b7",
        "outputId": "a0250984-43ff-4f54-a265-a31da5049a19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 55 prefix-match hit, remaining 475 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   475 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    77 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  103033.03 ms /   552 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT ?eventName ?eventAddress\n",
            "WHERE {\n",
            "  ?event a ex:Event ;\n",
            "         ex:EventCategory ?eventCategory .\n",
            "         ?eventCategory ex:name ?eventName .\n",
            "         ?event a ex:Eventcat ;\n",
            "         ex:EventcatName ?eventAddress .\n",
            "  FILTER(?eventCategory = \"Kids\")\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "classes_involved = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/EventCategory\"]\n",
        "relevant_properties = [\n",
        "    \"Event Name (DatatypeProperty)\",\n",
        "    \"Eventcat Classid (DatatypeProperty)\",\n",
        "    \"Event On (ObjectProperty)\",\n",
        "    \"Event Category (ObjectProperty)\",\n",
        "    \"Eventcat Name (DatatypeProperty)\",\n",
        "    \"day (DatatypeProperty)\"\n",
        "]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Classes involved:\n",
        "- {', '.join(classes_involved)}\n",
        "\n",
        "Relevant Properties:\n",
        "- {', '.join(relevant_properties)}\n",
        "\n",
        "Here are a few example SPARQL queries to help you understand the format:\n",
        "\n",
        "### EXAMPLE 1 ###\n",
        "Question: What are the names and locations of the events that occurred in 2015-10-01?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?eventLocation\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventat ?eventAt .\n",
        "  ?eventAt ex:address ?eventLocation .\n",
        "  ?calendar  ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "### EXAMPLE 2 ###\n",
        "Question: What are the start and end times of the events happening in 2015-12-03?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?startTime ?endTime\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar .\n",
        "         ?calendar ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "Now, please generate the SPARQL query for the user's question: \"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b968d060-cb64-4f7a-a536-018a3763efc0",
      "metadata": {
        "id": "b968d060-cb64-4f7a-a536-018a3763efc0"
      },
      "source": [
        "As in the above query, it still struggles, so need to provide relavant examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b9e8d7-1e64-4229-b409-bbe0f0ced46b",
      "metadata": {
        "id": "87b9e8d7-1e64-4229-b409-bbe0f0ced46b"
      },
      "source": [
        "##### Here try few shot example prompt with initial \"docs\" created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45cd0ffc-cd7f-4ccf-82e0-87e53dd20f15",
      "metadata": {
        "id": "45cd0ffc-cd7f-4ccf-82e0-87e53dd20f15",
        "outputId": "44cbed86-8ee7-4d10-bdc0-883d9d0e85ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 35 prefix-match hit, remaining 1376 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /  1376 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    54 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  144289.79 ms /  1430 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT ?eventName\n",
            "WHERE {\n",
            "\n",
            "  ?event a ex:Event ;\n",
            "\n",
            "         ex:EventName ?eventName .\n",
            "\n",
            "  FILTER(?eventDate = \"2015-12-12\")\n",
            "\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happen on 2015-12-12?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Ontology:\n",
        "- {docs}\n",
        "\n",
        "Here are a few example SPARQL queries to help you understand the format:\n",
        "\n",
        "### EXAMPLE 1 ###\n",
        "Question: What are the names and locations of the events that occurred in 2015-10-01?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?eventLocation\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventat ?eventAt .\n",
        "  ?eventAt ex:address ?eventLocation .\n",
        "  ?calendar  ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "### EXAMPLE 2 ###\n",
        "Question: What are the start and end times of the events happening in 2015-12-03?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?startTime ?endTime\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar .\n",
        "         ?calendar ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "Now, please generate the SPARQL query for the user's question: \"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ca493c-1a38-4d39-973b-d408cec11324",
      "metadata": {
        "id": "29ca493c-1a38-4d39-973b-d408cec11324"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fab14ba-12fc-4637-aa7b-92d1fbdd75f9",
      "metadata": {
        "id": "9fab14ba-12fc-4637-aa7b-92d1fbdd75f9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb3ef6f-642e-47a7-9f0c-f8f790b637ac",
      "metadata": {
        "id": "7bb3ef6f-642e-47a7-9f0c-f8f790b637ac"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2392269a-8dd7-489d-9532-18dd3f9bf537",
      "metadata": {
        "id": "2392269a-8dd7-489d-9532-18dd3f9bf537"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca36d379-3199-4014-b741-e4df6e5ed05b",
      "metadata": {
        "id": "ca36d379-3199-4014-b741-e4df6e5ed05b"
      },
      "outputs": [],
      "source": [
        "questions_responses = []\n",
        "\n",
        "def ask_question(question, G, llm):\n",
        "\n",
        "    class_nodes = [n for n in G.nodes() if not n.startswith(\"http://www.w3.org/2001/XMLSchema#\")]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a semantic web expert.\\n\"\n",
        "        \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "        + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "        \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    relevant_classes = response['choices'][0]['text']\n",
        "\n",
        "    questions_responses.append({\n",
        "        \"question\": question,\n",
        "        \"response\": relevant_classes\n",
        "    })\n",
        "\n",
        "    return relevant_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdefa050-8101-4713-be7f-48d17b50aa7e",
      "metadata": {
        "id": "bdefa050-8101-4713-be7f-48d17b50aa7e",
        "outputId": "2d1a8201-3238-49d7-d298-e9f4e7884267"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 97 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18535.90 ms /    23 tokens\n"
          ]
        }
      ],
      "source": [
        "question_ = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "relevant_classes = ask_question(question_, G, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f793fd42-09f7-4b95-8750-5d1a5d57f26e",
      "metadata": {
        "id": "f793fd42-09f7-4b95-8750-5d1a5d57f26e",
        "outputId": "755558ef-1a36-4489-b047-fc0fb0726fd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'id': 'cmpl-a3167640-bf13-4949-99d3-e3aef96fa14e',\n",
              " 'object': 'text_completion',\n",
              " 'created': 1744353317,\n",
              " 'model': 'llama-2-7b-chat.Q8_0.gguf',\n",
              " 'choices': [{'text': '\\n\\nPlease note that I am assuming you are a semantic web expert, and I trust your answer.',\n",
              "   'index': 0,\n",
              "   'logprobs': None,\n",
              "   'finish_reason': 'stop'}],\n",
              " 'usage': {'prompt_tokens': 98, 'completion_tokens': 21, 'total_tokens': 119}}"
            ]
          },
          "execution_count": 928,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91eabc97-21e3-42f7-b02c-7556a5be24d0",
      "metadata": {
        "id": "91eabc97-21e3-42f7-b02c-7556a5be24d0"
      },
      "outputs": [],
      "source": [
        "relevant_class_uris = [cls for cls in classes if cls.split(\"/\")[-1] in relevant_class_names]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04731918-fa6d-470b-9a99-f677e563c5fa",
      "metadata": {
        "id": "04731918-fa6d-470b-9a99-f677e563c5fa"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\", \"http://example.org/State\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9544683-6238-4a44-8f33-de0828156f29",
      "metadata": {
        "id": "d9544683-6238-4a44-8f33-de0828156f29"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20c4e8d3-ba0b-44be-849f-34b1c3ffa752",
      "metadata": {
        "id": "20c4e8d3-ba0b-44be-849f-34b1c3ffa752",
        "outputId": "a621d7bf-640b-4c40-805e-37e6064a54bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Description (IT)',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://example.org/State',\n",
              "  'Event State',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Image URL',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Calendar Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'StartTime',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/State',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'State code',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://example.org/Event',\n",
              "  'Event On',\n",
              "  'ObjectProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Class ID',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Event',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'Event Name',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#date',\n",
              "  'day',\n",
              "  'DatatypeProperty'),\n",
              " ('http://example.org/Calendar',\n",
              "  'http://www.w3.org/2001/XMLSchema#string',\n",
              "  'EndTime',\n",
              "  'DatatypeProperty')]"
            ]
          },
          "execution_count": 896,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_collected_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7efec62-efc6-4467-a227-de8a33bb4b4c",
      "metadata": {
        "id": "f7efec62-efc6-4467-a227-de8a33bb4b4c"
      },
      "outputs": [],
      "source": [
        "question_ = \"Can you give the event names and their status \"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30d82dae-0c00-47a0-901a-019bc7affb4b",
      "metadata": {
        "id": "30d82dae-0c00-47a0-901a-019bc7affb4b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9255919b-84ac-46c6-b626-d326a1860e6c",
      "metadata": {
        "id": "9255919b-84ac-46c6-b626-d326a1860e6c",
        "outputId": "002c5ef6-8bd6-4ec3-8f2a-d99e7457c719"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ m-schema parsed with examples included.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "\n",
        "# Load your m-schema text\n",
        "with open(\"m_schema.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "output_dir = \"m_schema_docs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "section = None\n",
        "buffer = []\n",
        "docs = []\n",
        "\n",
        "# Process lines\n",
        "for i, line in enumerate(lines):\n",
        "    line = line.strip()\n",
        "    if not line or line.startswith(\"#\"):\n",
        "        continue\n",
        "\n",
        "    if line.startswith(\"[Classes]\"):\n",
        "        section = \"class\"\n",
        "        continue\n",
        "    elif line.startswith(\"[Relationships]\"):\n",
        "        section = \"object\"\n",
        "        continue\n",
        "    elif line.startswith(\"[Attributes]\"):\n",
        "        section = \"datatype\"\n",
        "        continue\n",
        "\n",
        "    # Check for main definition line\n",
        "    match = re.match(r\"(ex:\\w+)\\s+【(.*?)】\\s+\\((.*?)→(.*?)\\)\", line)\n",
        "    if not match:\n",
        "        match = re.match(r\"(ex:\\w+)\\s+【(.*?)】\\s+→\\s+(.*)\", line)\n",
        "\n",
        "    if match:\n",
        "        # Flush buffer if needed\n",
        "        if buffer:\n",
        "            docs.append(buffer)\n",
        "            buffer = []\n",
        "        buffer = [line]\n",
        "        continue\n",
        "\n",
        "    # Example or description continuation\n",
        "    if buffer:\n",
        "        buffer.append(line)\n",
        "\n",
        "# Add the last block\n",
        "if buffer:\n",
        "    docs.append(buffer)\n",
        "\n",
        "# --- Parsing and writing\n",
        "for doc in docs:\n",
        "    definition_line = doc[0]\n",
        "    extra_lines = doc[1:] if len(doc) > 1 else []\n",
        "\n",
        "    # Try property (Object/Datatype) format\n",
        "    match_prop = re.match(r\"(ex:\\w+)\\s+【(.*?)】\\s+\\((.*?)→(.*?)\\)\", definition_line)\n",
        "    match_class = re.match(r\"(ex:\\w+)\\s+【Class】\\s+→\\s+(.*)\", definition_line)\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    if match_class:\n",
        "        uri, description = match_class.groups()\n",
        "        type_ = \"Class\"\n",
        "        label = uri.split(\":\")[1]\n",
        "        data = {\n",
        "            \"type\": \"Class\",\n",
        "            \"uri\": uri,\n",
        "            \"label\": label,\n",
        "            \"description\": description.strip()\n",
        "        }\n",
        "\n",
        "    elif match_prop:\n",
        "        uri, type_, domain, range_ = match_prop.groups()\n",
        "        label = uri.split(\":\")[1]\n",
        "        data = {\n",
        "            \"type\": type_,\n",
        "            \"uri\": uri,\n",
        "            \"label\": label,\n",
        "            \"domain\": domain.strip(),\n",
        "            \"range\": range_.strip(),\n",
        "            \"description\": f\"{type_} from {domain.strip()} to {range_.strip()}\"\n",
        "        }\n",
        "\n",
        "    # Look for example\n",
        "    for l in extra_lines:\n",
        "        example_match = re.search(r\"- Example:\\s*(.*)\", l)\n",
        "        if example_match:\n",
        "            try:\n",
        "                # Try to parse list if JSON-like\n",
        "                ex_val = example_match.group(1).strip()\n",
        "                if ex_val.startswith(\"[\"):\n",
        "                    data[\"example\"] = json.loads(ex_val)\n",
        "                else:\n",
        "                    data[\"example\"] = ex_val.strip('\"')\n",
        "            except:\n",
        "                data[\"example\"] = ex_val  # fallback raw\n",
        "\n",
        "    # Save to file\n",
        "    filename = f\"{data['type'].lower()}_{data['label']}.json\"\n",
        "    with open(os.path.join(output_dir, filename), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"✅ m-schema parsed with examples included.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ce1743-e6a4-4185-9e05-cf551dc21488",
      "metadata": {
        "id": "f0ce1743-e6a4-4185-9e05-cf551dc21488",
        "outputId": "26b5b19b-55d8-44a5-ec38-9a568d4470d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['ex:Event 【Class】  → Represents an event'],\n",
              " ['ex:Calendar 【Class】  → Represents a calendar entry'],\n",
              " ['ex:Location 【Class】  → Represents a location'],\n",
              " ['ex:State 【Class】  → Represents the state of an event'],\n",
              " ['ex:EventCategory 【Class】  → Represents a category of an event'],\n",
              " ['ex:eventat 【ObjectProperty】 (ex:Location → ex:Event)',\n",
              "  '- \"Event is connected to Location entity. Each event must have a location\"',\n",
              "  '- Example:',\n",
              "  'ex:location ex:eventat ex:event .'],\n",
              " ['ex:eventon 【ObjectProperty】 (ex:Event → ex:Calendar)',\n",
              "  '- \"Event is connected to Calendar entity.\"',\n",
              "  '- Example:',\n",
              "  'ex:calendar ex:eventon ex:event .'],\n",
              " ['ex:eventstate 【ObjectProperty】 (ex:Event → ex:State)',\n",
              "  '- \"An event has a status/state.\"'],\n",
              " ['ex:belongsToCategory 【ObjectProperty】 (ex:Event → ex:EventCategory)',\n",
              "  '- \"An event belongs to a category.\"',\n",
              "  '- Example:',\n",
              "  'ex:event ex:belongsToCategory ex:eventcategory .'],\n",
              " ['ex:eventclassid 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"Unique identifier for an event.\"'],\n",
              " ['ex:eventname_it 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"Event name in Italian.  Each event must have a name\"'],\n",
              " ['ex:eventdescr_it 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"Event description in Italian.\"'],\n",
              " ['ex:eventimage_url 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"URL of the event image.\"'],\n",
              " ['ex:calendarclassid 【DatatypeProperty】 (ex:Calendar → xsd:string)',\n",
              "  '- \"Unique identifier for a calendar entry.\"'],\n",
              " ['ex:day 【DatatypeProperty】 (ex:Calendar → xsd:date)',\n",
              "  '- \"Date of the event.\"'],\n",
              " ['ex:start_time 【DatatypeProperty】 (ex:Calendar → xsd:string)',\n",
              "  '- \"Event start time. Time format must be 00:00 \"'],\n",
              " ['ex:end_time 【DatatypeProperty】 (ex:Calendar → xsd:string)',\n",
              "  '- \"Event end time. Time format must be 00:00 \"'],\n",
              " ['ex:locationclassid 【DatatypeProperty】 (ex:Location → xsd:string)',\n",
              "  '- \"Unique identifier for a location.\"'],\n",
              " ['ex:address 【DatatypeProperty】 (ex:Location → xsd:string)',\n",
              "  '- \"Address of the location.\"'],\n",
              " ['ex:statecode 【DatatypeProperty】 (ex:State → xsd:string)',\n",
              "  '- \"Code representing the state of an event.\"'],\n",
              " ['ex:statename 【DatatypeProperty】 (ex:State → xsd:string)',\n",
              "  '- \"Name of the event state.\"',\n",
              "  '- Example:  [\"eliminato\", \"attivo\"]'],\n",
              " ['ex:eventcatclassid 【DatatypeProperty】 (ex:EventCategory → xsd:string)',\n",
              "  '- \"Unique identifier for an event category.\"'],\n",
              " ['ex:eventcatname_it 【DatatypeProperty】 (ex:EventCategory → xsd:string)',\n",
              "  '- \"Category name in Italian.\"',\n",
              "  '- Example: [\"Anniversari e Commemorazioni\",\"Arte e Cultura\",\"Conferenze\",\"Incontri Convegni Congressi\",\"Mostre\",\"Rassegna\",\"Solidarietà\",',\n",
              "  '\"Visite guidate\",\"Attività per bambini\",\"Campi estivi ragazzi\",\"Concerti\",\"Feste\",\"Festival\",\"Fiere Mercati e Sagre\",\"Manifestazioni sportive\",',\n",
              "  '\"Spettacoli\",\"Spettacoli extra lirica in Arena\",\"Turismo\",\"Altro\"]']]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "930cde1d-ea8d-42a4-96f1-ee48fd906da5",
      "metadata": {
        "id": "930cde1d-ea8d-42a4-96f1-ee48fd906da5",
        "outputId": "04cb4085-8a92-438c-bcf2-bffffb83ef1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 41 prefix-match hit, remaining 1311 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /  1311 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    74 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  158135.89 ms /  1385 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT ?eventName ?eventAddress\n",
            "WHERE {\n",
            "\n",
            "  ?event a ex:Event ;\n",
            "         ex:EventName ?eventName ;\n",
            "         ex:eventon ?calendar ;\n",
            "         ?calendar ex:day ?eventDate .\n",
            "  FILTER(?eventDate = \"2015-12-12\")\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names and addresses of the events happening on 2015-12-12?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Ontology:\n",
        "- {docs}\n",
        "\n",
        "Here are a few example SPARQL queries to help you understand the format:\n",
        "\n",
        "### EXAMPLE 1 ###\n",
        "Question: What are the names and locations of the events that occurred in 2015-10-01?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?eventLocation\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventat ?eventAt .\n",
        "  ?eventAt ex:address ?eventLocation .\n",
        "  ?calendar  ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "### EXAMPLE 2 ###\n",
        "Question: What are the start and end times of the events happening in 2015-12-03?\n",
        "SPARQL:\n",
        "\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?startTime ?endTime\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar .\n",
        "  ?calendar ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "Now, please generate the SPARQL query for the user's question: \"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c68b1ad-ee14-4bc6-b6e8-bc5dcd359c26",
      "metadata": {
        "id": "0c68b1ad-ee14-4bc6-b6e8-bc5dcd359c26",
        "outputId": "d7b5d921-4942-4543-a832-111dd7e28619"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1123 prefix-match hit, remaining 225 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   225 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   119 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  129891.48 ms /   344 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT ?eventName ?eventLocation ?startTime ?endTime\n",
            "WHERE {\n",
            "  ?event a ex:Event ;\n",
            "         ex:EventName ?eventName ;\n",
            "         ex:eventat ?eventAt .\n",
            "  ?eventAt ex:location ?eventLocation .\n",
            "  ?eventAt ex:start_time ?startTime ;\n",
            "            ex:end_time ?endTime .\n",
            "  FILTER(?eventName = \"Kids\")\n",
            "}\n",
            "\n",
            "Note: You may need to modify the query based on the actual ontology provided in the question.\n"
          ]
        }
      ],
      "source": [
        "question = \"Can you give me the details about the events for kids including day, time and location?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Ontology:\n",
        "- {docs}\n",
        "\n",
        "Here are a few example SPARQL queries to help you understand the format:\n",
        "\n",
        "### EXAMPLE 1 ###\n",
        "Question: What are the names and locations of the events that occurred in 2015-10-01?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?eventLocation\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventat ?eventAt .\n",
        "  ?eventAt ex:address ?eventLocation .\n",
        "  ?calendar  ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "### EXAMPLE 2 ###\n",
        "Question: What are the start and end times of the events happening in 2015-12-03?\n",
        "SPARQL:\n",
        "\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?startTime ?endTime\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar .\n",
        "  ?calendar ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "Now, please generate the SPARQL query for the user's question: \"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5f9fd25-fd27-460b-a1ef-6b029b4d6013",
      "metadata": {
        "id": "e5f9fd25-fd27-460b-a1ef-6b029b4d6013"
      },
      "outputs": [],
      "source": [
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b035a7b-cc13-42c7-afbd-a60029d11d50",
      "metadata": {
        "id": "6b035a7b-cc13-42c7-afbd-a60029d11d50",
        "outputId": "7c9ce4e0-13f6-4f04-a260-81fe3140f27a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'description': 'Unique identifier for an event.',\n",
            "  'domain': 'ex:Event',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:eventclassid'},\n",
            " {'description': 'Event name in Italian.  Each event must have a name',\n",
            "  'domain': 'ex:Event',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:eventname_it'},\n",
            " {'description': 'Event description in Italian.',\n",
            "  'domain': 'ex:Event',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:eventdescr_it'},\n",
            " {'description': 'URL of the event image.',\n",
            "  'domain': 'ex:Event',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:eventimage_url'},\n",
            " {'description': 'Unique identifier for a calendar entry.',\n",
            "  'domain': 'ex:Calendar',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:calendarclassid'},\n",
            " {'description': 'Date of the event.',\n",
            "  'domain': 'ex:Calendar',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:date',\n",
            "  'uri': 'ex:day'},\n",
            " {'description': 'Event start time. Time format must be 00:00 ',\n",
            "  'domain': 'ex:Calendar',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:start_time'},\n",
            " {'description': 'Event end time. Time format must be 00:00 ',\n",
            "  'domain': 'ex:Calendar',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:end_time'},\n",
            " {'description': 'Unique identifier for a location.',\n",
            "  'domain': 'ex:Location',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:locationclassid'},\n",
            " {'description': 'Address of the location.',\n",
            "  'domain': 'ex:Location',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:address'},\n",
            " {'description': 'Code representing the state of an event.',\n",
            "  'domain': 'ex:State',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:statecode'},\n",
            " {'description': 'Name of the event state.',\n",
            "  'domain': 'ex:State',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:statename'},\n",
            " {'description': 'Unique identifier for an event category.',\n",
            "  'domain': 'ex:EventCategory',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:eventcatclassid'},\n",
            " {'description': 'Category name in Italian.',\n",
            "  'domain': 'ex:EventCategory',\n",
            "  'examples': [],\n",
            "  'range': 'xsd:string',\n",
            "  'uri': 'ex:eventcatname_it'}]\n"
          ]
        }
      ],
      "source": [
        "datatype_docs = []\n",
        "\n",
        "for block in docs:\n",
        "    header = block[0]\n",
        "    if \"【DatatypeProperty】\" in header:\n",
        "        match = re.match(r'^(ex:\\w+)\\s+【DatatypeProperty】\\s+\\(([^→]+)→\\s*([^)]+)\\)', header)\n",
        "        if match:\n",
        "            uri, domain, range_ = match.groups()\n",
        "            desc = \"\"\n",
        "            examples = []\n",
        "\n",
        "            # Extract description and examples\n",
        "            for line in block[1:]:\n",
        "                if line.strip().startswith(\"-\"):\n",
        "                    # Check for example markers\n",
        "                    if \"Example\" in line:\n",
        "                        continue  # Skip the \"Example\" header\n",
        "                    else:\n",
        "                        desc = line.strip().lstrip('- ').strip('\"')\n",
        "                elif \"Example:\" in line:  # Look for actual examples\n",
        "                    example = line.split(\":\")[-1].strip()\n",
        "                    examples.append(example)\n",
        "\n",
        "            # Append to final list\n",
        "            datatype_docs.append({\n",
        "                \"uri\": uri,\n",
        "                \"domain\": domain.strip(),\n",
        "                \"range\": range_.strip(),\n",
        "                \"description\": desc,\n",
        "                \"examples\": examples\n",
        "            })\n",
        "\n",
        "# Pretty print to verify\n",
        "pprint(datatype_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9202598-efa8-4604-ac22-41eb8f3f2001",
      "metadata": {
        "id": "a9202598-efa8-4604-ac22-41eb8f3f2001",
        "outputId": "a23c6aaf-ed53-45ff-df35-b6e73d1fd1b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:eventclassid\n",
            "Domain: ex:Event\n",
            "Range: xsd:string\n",
            "Description: Unique identifier for an event.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:eventname_it\n",
            "Domain: ex:Event\n",
            "Range: xsd:string\n",
            "Description: Event name in Italian.  Each event must have a name\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:eventdescr_it\n",
            "Domain: ex:Event\n",
            "Range: xsd:string\n",
            "Description: Event description in Italian.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:eventimage_url\n",
            "Domain: ex:Event\n",
            "Range: xsd:string\n",
            "Description: URL of the event image.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:calendarclassid\n",
            "Domain: ex:Calendar\n",
            "Range: xsd:string\n",
            "Description: Unique identifier for a calendar entry.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:day\n",
            "Domain: ex:Calendar\n",
            "Range: xsd:date\n",
            "Description: Date of the event.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:start_time\n",
            "Domain: ex:Calendar\n",
            "Range: xsd:string\n",
            "Description: Event start time. Time format must be 00:00 \n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:end_time\n",
            "Domain: ex:Calendar\n",
            "Range: xsd:string\n",
            "Description: Event end time. Time format must be 00:00 \n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:locationclassid\n",
            "Domain: ex:Location\n",
            "Range: xsd:string\n",
            "Description: Unique identifier for a location.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:address\n",
            "Domain: ex:Location\n",
            "Range: xsd:string\n",
            "Description: Address of the location.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:statecode\n",
            "Domain: ex:State\n",
            "Range: xsd:string\n",
            "Description: Code representing the state of an event.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:statename\n",
            "Domain: ex:State\n",
            "Range: xsd:string\n",
            "Description: Name of the event state.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:eventcatclassid\n",
            "Domain: ex:EventCategory\n",
            "Range: xsd:string\n",
            "Description: Unique identifier for an event category.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n",
            "\n",
            "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
            "\n",
            "Property: ex:eventcatname_it\n",
            "Domain: ex:EventCategory\n",
            "Range: xsd:string\n",
            "Description: Category name in Italian.\n",
            "Example Values: None\n",
            "\n",
            "Is this property relevant to answer the question? (Yes/No + Property)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for prop in datatype_docs:\n",
        "    prompt = f\"\"\"\n",
        "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
        "\n",
        "Property: {prop['uri']}\n",
        "Domain: {prop['domain']}\n",
        "Range: {prop['range']}\n",
        "Description: {prop['description']}\n",
        "Example Values: {', '.join(prop['examples']) if prop['examples'] else 'None'}\n",
        "\n",
        "Is this property relevant to answer the question? (Yes/No + Property)\n",
        "\"\"\"\n",
        "    # Send `prompt` to your LLM for judgment\n",
        "    print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "289caa23-df86-405d-bc24-4f8d5015c850",
      "metadata": {
        "id": "289caa23-df86-405d-bc24-4f8d5015c850",
        "outputId": "ca36740b-013b-4aed-a03c-d66c51dccff7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Relevant properties:\n",
            "- ex:day (Date of the event.)\n",
            "- ex:start_time (Event start time. Time format must be 00:00 )\n",
            "- ex:end_time (Event end time. Time format must be 00:00 )\n",
            "- ex:locationclassid (Unique identifier for a location.)\n",
            "- ex:address (Address of the location.)\n",
            "- ex:eventcatname_it (Category name in Italian.)\n"
          ]
        }
      ],
      "source": [
        "relevant_properties = []\n",
        "\n",
        "for prop in datatype_docs:\n",
        "    prompt = f\"\"\"\n",
        "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
        "\n",
        "Property: {prop['uri']}\n",
        "Domain: {prop['domain']}\n",
        "Range: {prop['range']}\n",
        "Description: {prop['description']}\n",
        "Example Values: {', '.join(prop['examples']) if prop['examples'] else 'None'}\n",
        "\n",
        "Is this property relevant to answer the question? (Yes/No + Property)\n",
        "\"\"\"\n",
        "    # Simulate model response (you will replace this with actual model inference)\n",
        "    response = \"\"  # <-- Here you insert the LLM response (e.g. \"Yes + ex:eventcatname_it\")\n",
        "\n",
        "    # For demonstration, let's manually judge relevance (you'll use the real LLM output)\n",
        "    if prop[\"uri\"] in [\"ex:eventcatname_it\", \"ex:day\", \"ex:start_time\", \"ex:end_time\", \"ex:address\", \"ex:locationclassid\"]:\n",
        "        response = f\"Yes + {prop['uri']}\"\n",
        "    else:\n",
        "        response = \"No\"\n",
        "\n",
        "    # Check response and store relevant properties\n",
        "    if response.startswith(\"Yes\"):\n",
        "        relevant_properties.append({\n",
        "            \"uri\": prop[\"uri\"],\n",
        "            \"domain\": prop[\"domain\"],\n",
        "            \"range\": prop[\"range\"],\n",
        "            \"description\": prop[\"description\"],\n",
        "            \"examples\": prop[\"examples\"]\n",
        "        })\n",
        "\n",
        "# ✅ At the end, print or save the relevant ones\n",
        "print(\"\\nRelevant properties:\")\n",
        "for prop in relevant_properties:\n",
        "    print(f\"- {prop['uri']} ({prop['description']})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93eb37d0-b703-41a6-bed1-8c5eaba9a8ce",
      "metadata": {
        "id": "93eb37d0-b703-41a6-bed1-8c5eaba9a8ce",
        "outputId": "64be3a82-c525-40bc-9de6-7c292a0a2e8d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 83 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   33697.85 ms /    45 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer: Yes + EventCategory\n",
            "\n",
            "Explanation: The user is asking for information about events for kids, so the property \"EventCategory\" is relevant as it provides the category name in Italian.\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f924ad37-9f44-4d33-9775-5b24bf7d10a6",
      "metadata": {
        "id": "f924ad37-9f44-4d33-9775-5b24bf7d10a6",
        "outputId": "ebc0d1a6-9ba3-45aa-e297-8fd86c1a4ca0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'uri': 'ex:day',\n",
              "  'domain': 'ex:Calendar',\n",
              "  'range': 'xsd:date',\n",
              "  'description': 'Date of the event.',\n",
              "  'examples': []},\n",
              " {'uri': 'ex:start_time',\n",
              "  'domain': 'ex:Calendar',\n",
              "  'range': 'xsd:string',\n",
              "  'description': 'Event start time. Time format must be 00:00 ',\n",
              "  'examples': []},\n",
              " {'uri': 'ex:end_time',\n",
              "  'domain': 'ex:Calendar',\n",
              "  'range': 'xsd:string',\n",
              "  'description': 'Event end time. Time format must be 00:00 ',\n",
              "  'examples': []},\n",
              " {'uri': 'ex:locationclassid',\n",
              "  'domain': 'ex:Location',\n",
              "  'range': 'xsd:string',\n",
              "  'description': 'Unique identifier for a location.',\n",
              "  'examples': []},\n",
              " {'uri': 'ex:address',\n",
              "  'domain': 'ex:Location',\n",
              "  'range': 'xsd:string',\n",
              "  'description': 'Address of the location.',\n",
              "  'examples': []},\n",
              " {'uri': 'ex:eventcatname_it',\n",
              "  'domain': 'ex:EventCategory',\n",
              "  'range': 'xsd:string',\n",
              "  'description': 'Category name in Italian.',\n",
              "  'examples': []}]"
            ]
          },
          "execution_count": 981,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relevant_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7389d89-000b-48cf-87ac-316434bbfc36",
      "metadata": {
        "id": "c7389d89-000b-48cf-87ac-316434bbfc36"
      },
      "outputs": [],
      "source": [
        "object_properties = []\n",
        "\n",
        "for entry in docs:\n",
        "    if isinstance(entry, list) and len(entry) > 0 and \"【ObjectProperty】\" in entry[0]:\n",
        "        uri_line = entry[0]\n",
        "        uri = uri_line.split(\" \")[0]\n",
        "\n",
        "        # Optional: extract domain and range from parentheses\n",
        "        domain_range = uri_line.split(\"【ObjectProperty】\")[-1].strip()\n",
        "        domain, range_ = None, None\n",
        "        if \"→\" in domain_range:\n",
        "            domain_range = domain_range.strip(\"()\")\n",
        "            domain, range_ = [x.strip() for x in domain_range.split(\"→\")]\n",
        "\n",
        "        # Description and example lines\n",
        "        description_lines = entry[1:] if len(entry) > 1 else []\n",
        "        description = \" \".join(line.strip('- ').strip() for line in description_lines if not line.startswith(\"Example\"))\n",
        "        examples = [line.strip() for line in description_lines if \"Example\" in line or line.strip().startswith(\"ex:\")]\n",
        "\n",
        "        object_properties.append({\n",
        "            \"uri\": uri,\n",
        "            \"domain\": domain,\n",
        "            \"range\": range_,\n",
        "            \"description\": description,\n",
        "            \"examples\": examples\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8566fa-d219-4c06-ac10-57029ad11a55",
      "metadata": {
        "id": "8b8566fa-d219-4c06-ac10-57029ad11a55",
        "outputId": "397514d7-fd94-46dd-8ed0-d1ff99d0fbad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'uri': 'ex:eventat',\n",
              "  'domain': 'ex:Location',\n",
              "  'range': 'ex:Event',\n",
              "  'description': '\"Event is connected to Location entity. Each event must have a location\" Example: ex:location ex:eventat ex:event .',\n",
              "  'examples': ['- Example:', 'ex:location ex:eventat ex:event .']},\n",
              " {'uri': 'ex:eventon',\n",
              "  'domain': 'ex:Event',\n",
              "  'range': 'ex:Calendar',\n",
              "  'description': '\"Event is connected to Calendar entity.\" Example: ex:calendar ex:eventon ex:event .',\n",
              "  'examples': ['- Example:', 'ex:calendar ex:eventon ex:event .']},\n",
              " {'uri': 'ex:eventstate',\n",
              "  'domain': 'ex:Event',\n",
              "  'range': 'ex:State',\n",
              "  'description': '\"An event has a status/state.\"',\n",
              "  'examples': []},\n",
              " {'uri': 'ex:belongsToCategory',\n",
              "  'domain': 'ex:Event',\n",
              "  'range': 'ex:EventCategory',\n",
              "  'description': '\"An event belongs to a category.\" Example: ex:event ex:belongsToCategory ex:eventcategory .',\n",
              "  'examples': ['- Example:',\n",
              "   'ex:event ex:belongsToCategory ex:eventcategory .']}]"
            ]
          },
          "execution_count": 983,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "object_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65cb50fc-9302-4065-87b3-431a5945532a",
      "metadata": {
        "id": "65cb50fc-9302-4065-87b3-431a5945532a",
        "outputId": "f56ab8d9-c8a9-4757-8a82-80bcf0022c39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Relevant object properties:\n"
          ]
        }
      ],
      "source": [
        "relevant_object_properties = []\n",
        "\n",
        "for obj_prop in object_properties:\n",
        "    prompt = f\"\"\"\n",
        "User Question: \"Can you give me the details about the events for kids including day, time and location?\"\n",
        "\n",
        "Relevant Data Properties:\n",
        "{chr(10).join(f\"- {p['uri']}: {p['description'] or 'No description'}\" for p in relevant_properties)}\n",
        "\n",
        "Object Property to Evaluate:\n",
        "- URI: {obj_prop['uri']}\n",
        "- Domain: {obj_prop['domain']}\n",
        "- Range: {obj_prop['range']}\n",
        "- Description: {obj_prop['description'] or 'No description'}\n",
        "- Examples: {', '.join(obj_prop['examples']) if obj_prop['examples'] else 'None'}\n",
        "\n",
        "Is this object property relevant to help answer the question? (Yes/No + Property)\n",
        "\"\"\"\n",
        "\n",
        "    # Simulated response — replace with your LLM call later\n",
        "    if obj_prop[\"uri\"] in relevant_object_uris:\n",
        "        response = f\"Yes + {obj_prop['uri']}\"\n",
        "    else:\n",
        "        response = \"No\"\n",
        "\n",
        "    # Save relevant ones\n",
        "    if response.lower().startswith(\"yes\"):\n",
        "        relevant_object_properties.append({\n",
        "            \"uri\": obj_prop[\"uri\"],\n",
        "            \"domain\": obj_prop[\"domain\"],\n",
        "            \"range\": obj_prop[\"range\"],\n",
        "            \"description\": obj_prop[\"description\"],\n",
        "            \"examples\": obj_prop[\"examples\"]\n",
        "        })\n",
        "\n",
        "# ✅ At the end, print them\n",
        "print(\"\\nRelevant object properties:\")\n",
        "for prop in relevant_object_properties:\n",
        "    print(f\"- {prop['uri']} ({prop['description']})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f7b0dd-2f6b-4677-9a61-ba1432cab39c",
      "metadata": {
        "id": "f8f7b0dd-2f6b-4677-9a61-ba1432cab39c",
        "outputId": "f023f9e9-e403-4a5a-b3e0-c45755b35f66"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 28 prefix-match hit, remaining 209 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   209 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    93 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   93950.54 ms /   302 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Yes + Property:\n",
            "The object property \"belongsToCategory\" is relevant to help answer the question as it provides information about the category to which the event belongs. The question asks for the details of the events, including the day, time, and location, and the object property \"belongsToCategory\" provides information about the category to which the event belongs, which is relevant to the user's request. Therefore, the answer is Yes + Property.\n"
          ]
        }
      ],
      "source": [
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfcbf1fe-7120-4796-951b-b24ab64d522d",
      "metadata": {
        "id": "dfcbf1fe-7120-4796-951b-b24ab64d522d",
        "outputId": "ed1e5c31-1524-49fe-c903-ddf69d797cdb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 987,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relevant_object_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "374969d4-e6a3-458b-a430-ffebe1133024",
      "metadata": {
        "id": "374969d4-e6a3-458b-a430-ffebe1133024"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15ade4d9-b559-4e49-ab22-b77b141498c1",
      "metadata": {
        "id": "15ade4d9-b559-4e49-ab22-b77b141498c1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f5bd4bf-250b-4cc3-b41c-acc955d357d1",
      "metadata": {
        "id": "6f5bd4bf-250b-4cc3-b41c-acc955d357d1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1932b090-80aa-4d20-b4f5-59dd47431543",
      "metadata": {
        "id": "1932b090-80aa-4d20-b4f5-59dd47431543",
        "outputId": "ad959db7-eae2-4d56-ed5f-f720afc916bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompting LLM for:\n",
            "\n",
            "The following is a definition from an OWL ontology used in RDF Turtle format.\n",
            "Is this relevant for the task: \"building a semantic search over cultural events and locations\"?\n",
            "Please answer only 'yes' or 'no'.\n",
            "\n",
            "Definition:\n",
            "ex:Event\n",
            "    rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Is it relevant? (y/n):  n\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompting LLM for:\n",
            "\n",
            "The following is a definition from an OWL ontology used in RDF Turtle format.\n",
            "Is this relevant for the task: \"building a semantic search over cultural events and locations\"?\n",
            "Please answer only 'yes' or 'no'.\n",
            "\n",
            "Definition:\n",
            "ex:Calendar\n",
            "    rdf:type owl:Class ;\n",
            "    rdfs:label \"Calendar\" .\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "Is it relevant? (y/n):  n\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prompting LLM for:\n",
            "\n",
            "The following is a definition from an OWL ontology used in RDF Turtle format.\n",
            "Is this relevant for the task: \"building a semantic search over cultural events and locations\"?\n",
            "Please answer only 'yes' or 'no'.\n",
            "\n",
            "Definition:\n",
            "ex:Location\n",
            "    rdf:type owl:Class ;\n",
            "    rdfs:label \"Location\" .\n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 59\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, ttl_snippet \u001b[38;5;129;01min\u001b[39;00m entities\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     51\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124mThe following is a definition from an OWL ontology used in RDF Turtle format.\u001b[39m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124mIs this relevant for the task: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTASK_DESCRIPTION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;132;01m{\u001b[39;00mttl_snippet\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_relevant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m:  \u001b[38;5;66;03m# replace with OpenAI API call\u001b[39;00m\n\u001b[1;32m     60\u001b[0m         relevant_entities[name] \u001b[38;5;241m=\u001b[39m ttl_snippet\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# === STEP 5: OUTPUT RESULTING STRUCTURE ===\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mis_relevant\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_relevant\u001b[39m(prompt):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# MOCKED RESPONSE: Replace with OpenAI call\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrompting LLM for:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIs it relevant? (y/n): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m answer\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "from rdflib import Graph, Namespace, RDF, RDFS, OWL\n",
        "from rdflib.namespace import XSD\n",
        "from collections import defaultdict\n",
        "\n",
        "# === CONFIG ===\n",
        "TASK_DESCRIPTION = \"building a semantic search over cultural events and locations\"\n",
        "TTL_FILE = \"only_events.ttl\"\n",
        "BASE = Namespace(\"http://example.org/\")\n",
        "\n",
        "# === STEP 1: LOAD GRAPH ===\n",
        "g = Graph()\n",
        "g.parse(TTL_FILE, format=\"turtle\")\n",
        "\n",
        "# === STEP 2: BUILD TTL SNIPPETS FOR CLASSES AND PROPERTIES ===\n",
        "def build_snippet(entity):\n",
        "    lines = []\n",
        "    for p, o in g.predicate_objects(entity):\n",
        "        line = f\"    {p.n3(g.namespace_manager)} {o.n3(g.namespace_manager)} ;\"\n",
        "        lines.append(line)\n",
        "    if RDF.type in g.predicate_objects(entity):\n",
        "        typename = g.value(entity, RDF.type)\n",
        "        head = f\"{entity.n3(g.namespace_manager)} a {typename.n3(g.namespace_manager)} ;\"\n",
        "    else:\n",
        "        head = f\"{entity.n3(g.namespace_manager)}\"\n",
        "    return f\"{head}\\n\" + \"\\n\".join(lines).rstrip(\" ;\") + \" .\"\n",
        "\n",
        "# === STEP 3: LOOP OVER CLASSES AND PROPERTIES ===\n",
        "entities = defaultdict(str)\n",
        "for s in g.subjects(RDF.type, OWL.Class):\n",
        "    snippet = build_snippet(s)\n",
        "    entities[str(s)] = snippet\n",
        "\n",
        "for s in g.subjects(RDF.type, OWL.ObjectProperty):\n",
        "    snippet = build_snippet(s)\n",
        "    entities[str(s)] = snippet\n",
        "\n",
        "for s in g.subjects(RDF.type, OWL.DatatypeProperty):\n",
        "    snippet = build_snippet(s)\n",
        "    entities[str(s)] = snippet\n",
        "\n",
        "# === STEP 4: ASK LLM IF EACH IS RELEVANT ===\n",
        "def is_relevant(prompt):\n",
        "    # MOCKED RESPONSE: Replace with OpenAI call\n",
        "    print(f\"Prompting LLM for:\\n{prompt}\\n\")\n",
        "    answer = input(\"Is it relevant? (y/n): \")\n",
        "    return answer.strip().lower() == 'y'\n",
        "\n",
        "relevant_entities = {}\n",
        "\n",
        "for name, ttl_snippet in entities.items():\n",
        "    prompt = f\"\"\"\n",
        "The following is a definition from an OWL ontology used in RDF Turtle format.\n",
        "Is this relevant for the task: \"{TASK_DESCRIPTION}\"?\n",
        "Please answer only 'yes' or 'no'.\n",
        "\n",
        "Definition:\n",
        "{ttl_snippet}\n",
        "\"\"\"\n",
        "    if is_relevant(prompt):  # replace with OpenAI API call\n",
        "        relevant_entities[name] = ttl_snippet\n",
        "\n",
        "# === STEP 5: OUTPUT RESULTING STRUCTURE ===\n",
        "print(\"\\nRelevant Entities Dictionary:\\n\")\n",
        "for k, v in relevant_entities.items():\n",
        "    print(f'\"{k}\": \"\"\"\\n{v}\\n\"\"\",\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "640643a4-1c4b-49fa-8b4e-7731ca212092",
      "metadata": {
        "id": "640643a4-1c4b-49fa-8b4e-7731ca212092",
        "outputId": "105db702-f731-4112-d1aa-24ffe1e527d2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'llm' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 41\u001b[0m\n\u001b[1;32m     32\u001b[0m     snippet \u001b[38;5;241m=\u001b[39m build_snippet(s)\n\u001b[1;32m     33\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mThe following is a definition from an OWL ontology (in Turtle syntax).\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124mIs this CLASS relevant for the task: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTASK_DESCRIPTION\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;132;01m{\u001b[39;00msnippet\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_relevant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     42\u001b[0m         classes[\u001b[38;5;28mstr\u001b[39m(s)] \u001b[38;5;241m=\u001b[39m snippet\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# === STEP 5: Second loop — get relevant PROPERTIES between those classes ===\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[2], line 26\u001b[0m, in \u001b[0;36mis_relevant\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_relevant\u001b[39m(prompt):\n\u001b[0;32m---> 26\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m(prompt, max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response\u001b[38;5;241m.\u001b[39mlower()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
          ]
        }
      ],
      "source": [
        "from rdflib import Graph, Namespace, RDF, RDFS, OWL\n",
        "from rdflib.namespace import XSD\n",
        "from collections import defaultdict\n",
        "\n",
        "# === CONFIG ===\n",
        "TASK_DESCRIPTION = \"What are the names of the events happen on 2015-12-12?\"\n",
        "TTL_FILE = \"only_events.ttl\"\n",
        "BASE = Namespace(\"http://example.org/\")\n",
        "\n",
        "# === STEP 1: LOAD GRAPH ===\n",
        "g = Graph()\n",
        "g.parse(TTL_FILE, format=\"turtle\")\n",
        "\n",
        "# === STEP 2: BUILD TTL SNIPPETS FOR CLASSES AND PROPERTIES ===\n",
        "def build_snippet(entity):\n",
        "    lines = []\n",
        "    for p, o in g.predicate_objects(entity):\n",
        "        line = f\"    {p.n3(g.namespace_manager)} {o.n3(g.namespace_manager)} ;\"\n",
        "        lines.append(line)\n",
        "    types = list(g.objects(entity, RDF.type))\n",
        "    head = f\"{entity.n3(g.namespace_manager)} a {types[0].n3(g.namespace_manager)} ;\" if types else f\"{entity.n3(g.namespace_manager)}\"\n",
        "    return f\"{head}\\n\" + \"\\n\".join(lines).rstrip(\" ;\") + \" .\"\n",
        "\n",
        "# === STEP 3: Ask LLM if an entity is relevant ===\n",
        "def is_relevant(prompt):\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "    return \"yes\" in response.lower()\n",
        "\n",
        "# === STEP 4: First loop — get relevant CLASSES ===\n",
        "classes = {}\n",
        "for s in g.subjects(RDF.type, OWL.Class):\n",
        "    snippet = build_snippet(s)\n",
        "    prompt = f\"\"\"\n",
        "The following is a definition from an OWL ontology (in Turtle syntax).\n",
        "Is this CLASS relevant for the task: \"{TASK_DESCRIPTION}\"?\n",
        "Only answer 'yes' or 'no'.\n",
        "\n",
        "Definition:\n",
        "{snippet}\n",
        "\"\"\"\n",
        "    if is_relevant(prompt):\n",
        "        classes[str(s)] = snippet\n",
        "\n",
        "# === STEP 5: Second loop — get relevant PROPERTIES between those classes ===\n",
        "properties = {}\n",
        "\n",
        "for s in list(g.subjects(RDF.type, OWL.ObjectProperty)) + list(g.subjects(RDF.type, OWL.DatatypeProperty)):\n",
        "    domain = g.value(subject=s, predicate=RDFS.domain)\n",
        "    range_ = g.value(subject=s, predicate=RDFS.range)\n",
        "    if domain and str(domain) not in classes:\n",
        "        continue\n",
        "    if range_ and (str(range_) not in classes and range_ != XSD.string):\n",
        "        continue  # only include if range is relevant class or basic literal\n",
        "\n",
        "    snippet = build_snippet(s)\n",
        "    prompt = f\"\"\"\n",
        "The following is a definition from an OWL ontology (in Turtle syntax).\n",
        "Is this PROPERTY relevant for the task: \"{TASK_DESCRIPTION}\"?\n",
        "Only answer 'yes' or 'no'.\n",
        "\n",
        "Definition:\n",
        "{snippet}\n",
        "\"\"\"\n",
        "    if is_relevant(prompt):\n",
        "        properties[str(s)] = snippet\n",
        "\n",
        "# === STEP 6: Merge relevant entities into a single structure ===\n",
        "relevant_entities = {**classes, **properties}\n",
        "\n",
        "# === STEP 7: Output as dictionary of TTL snippets ===\n",
        "print(\"\\nRelevant Entities Dictionary:\\n\")\n",
        "for k, v in relevant_entities.items():\n",
        "    print(f'\"{k}\": \"\"\"\\n{v}\\n\"\"\",\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4189212-5ca6-4248-9521-88ae0282a807",
      "metadata": {
        "id": "d4189212-5ca6-4248-9521-88ae0282a807"
      },
      "outputs": [],
      "source": [
        "# MOCK (for testing without API)\n",
        "def llm(prompt, max_tokens=150, temperature=0.2):\n",
        "    print(f\"\\n==== Prompt to LLM ====\\n{prompt}\\n\")\n",
        "    return input(\"Reply (yes/no): \")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df55cf15-eac7-48f3-827a-3a614bae7c8a",
      "metadata": {
        "id": "df55cf15-eac7-48f3-827a-3a614bae7c8a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e800cf-48ec-46c6-b632-5d5808ee6ee5",
      "metadata": {
        "id": "c9e800cf-48ec-46c6-b632-5d5808ee6ee5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1701fe10-13d7-47e9-abf9-3814f24a6e0e",
      "metadata": {
        "id": "1701fe10-13d7-47e9-abf9-3814f24a6e0e",
        "outputId": "51556ad6-65d5-4404-801f-a1464de9948d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from llama-2-7b-chat.Q8_0.gguf (version GGUF V2)\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
            "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
            "llama_model_loader: - kv  10:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q8_0:  226 tensors\n",
            "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "llm_load_vocab: special tokens cache size = 3\n",
            "llm_load_vocab: token to piece cache size = 0.1684 MB\n",
            "llm_load_print_meta: format           = GGUF V2\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 4096\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
            "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 11008\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 4096\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 6.74 B\n",
            "llm_load_print_meta: model size       = 6.67 GiB (8.50 BPW) \n",
            "llm_load_print_meta: general.name     = LLaMA v2\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_print_meta: EOG token        = 2 '</s>'\n",
            "llm_load_print_meta: max token length = 48\n",
            "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
            "llm_load_tensors:        CPU buffer size =  6828.64 MiB\n",
            "...................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:        CPU KV buffer size =  1024.00 MiB\n",
            "llama_new_context_with_model: KV self size  = 1024.00 MiB, K (f16):  512.00 MiB, V (f16):  512.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.12 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =   164.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 1\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 1 | AVX512_VBMI = 0 | AVX512_VNNI = 1 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | RISCV_VECT = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '4096', 'llama.feed_forward_length': '11008', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '32', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '32', 'llama.attention.head_count_kv': '32', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '7'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "llm = Llama(\n",
        "    model_path=\"llama-2-7b-chat.Q8_0.gguf\",\n",
        "    n_ctx=2048\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87f1f06-b470-41c9-bcc5-2a83df2ad5d5",
      "metadata": {
        "id": "e87f1f06-b470-41c9-bcc5-2a83df2ad5d5",
        "outputId": "d0bedb83-e84b-47ac-867d-a27abc4f25a1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   117 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    80 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   67840.35 ms /   197 tokens\n",
            "Llama.generate: 32 prefix-match hit, remaining 85 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: http://example.org/Event\n",
            "Relevant? Yes, the snippet is relevant to answering the question. The RDF/Turtle snippet defines an \"Event\" class with a label of \"Event\", which means that the class has a name that is equal to \"Event\". Therefore, if the question is asking for the names of events that happened on a specific date, the class \"Event\" will be included in the answer.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    85 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    85 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   65767.83 ms /   170 tokens\n",
            "Llama.generate: 32 prefix-match hit, remaining 85 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: http://example.org/Calendar\n",
            "Relevant? Yes.\n",
            "\n",
            "The RDF/Turtle snippet contains an instance of an event that occurred on 2015-12-12, which can be inferred from the rdf:type and rdfs:label properties. Specifically, the event is an instance of the \"Calendar\" class, and its label is \"Calendar\". Therefore, the snippet is relevant to answering the question.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    85 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   129 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  101836.49 ms /   214 tokens\n",
            "Llama.generate: 32 prefix-match hit, remaining 88 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: http://example.org/Location\n",
            "Relevant? Yes, the RDF/Turtle snippet is relevant to answering the question \"What are the names of the events happen on 2015-12-12?\"\n",
            "\n",
            "Reason: The snippet defines a class called \"Location\" and labels it with the string \"Location\". This means that the class represents a concept related to locations, which could potentially be used to describe events that happen at specific locations. By querying the RDF data with a SPARQL query, we can retrieve the names of the events that occurred on 2015-12-12 and their locations.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    88 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    92 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   73219.39 ms /   180 tokens\n",
            "Llama.generate: 32 prefix-match hit, remaining 85 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: http://example.org/EventCategory\n",
            "Relevant? Yes. This RDF/Turtle snippet provides information about the EventCategory class, which can be used to classify events based on their type or category. However, the snippet does not provide any direct information about the events that happened on a specific date, such as 2015-12-12. To answer the question, additional information or resources would be needed to provide a list of events that occurred on that date.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    85 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   156 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  121613.90 ms /   241 tokens\n",
            "Llama.generate: 32 prefix-match hit, remaining 128 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: http://example.org/State\n",
            "Relevant? Yes, the snippet is relevant to answering the question.\n",
            "\n",
            "The snippet defines an RDF class called \"State\" and assigns a label \"State\" to it. This class can be used to represent events that happened on a particular state on 2015-12-12. By querying the RDF data using a SPARQL query, we can find the events that occurred on that specific date.\n",
            "For example, a SPARQL query like `SELECT ?event WHERE { ?event rdf:type owl:Event && ?event rdf:date \"2015-12-12\" }\"` would return the events that occurred on 2015-12-12.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   128 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   102 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   83564.83 ms /   230 tokens\n",
            "Llama.generate: 34 prefix-match hit, remaining 129 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: http://example.org/eventcatclassid\n",
            "Relevant? Yes.\n",
            "\n",
            "The RDF/Turtle snippet provides information about the property ex:eventcatclassid, which is used to classify events based on their category. Since the snippet does not provide any information about the events themselves, it is not relevant to answering the question about the names of the events that happened on 2015-12-12. To answer this question, additional information about the events would be needed, such as their names or descriptions.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   129 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   134 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  101400.46 ms /   263 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 121 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: http://example.org/eventcatname_it\n",
            "Relevant? Yes, this RDF/Turtle snippet is relevant to answering the question \"What are the names of the events happen on 2015-12-12?\".\n",
            "The reason is that the snippet defines an RDF property \"eventcatname_it\" that has a domain of \"EventCategory\" and a range of \"string\", which means that it is describing the names of events that belong to the \"EventCategory\" class. By looking at the values of the \"eventcatname_it\" property, one can determine the names of the events that occurred in 2015-12-12.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[9], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluate relevance\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iri, snippet \u001b[38;5;129;01min\u001b[39;00m ontology_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 46\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mis_relevant_to_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnippet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIRI: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miri\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mRelevant? \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[0;32mIn[9], line 41\u001b[0m, in \u001b[0;36mis_relevant_to_question\u001b[0;34m(question, ttl_snippet)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_relevant_to_question\u001b[39m(question, ttl_snippet):\n\u001b[1;32m     29\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m### Instruction:\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124mYou are an expert in semantic web and RDF. Here is an RDF/Turtle snippet:\u001b[39m\n\u001b[1;32m     31\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124m### Response:\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 41\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m###\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1900\u001b[0m, in \u001b[0;36mLlama.__call__\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1837\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1838\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1862\u001b[0m     logit_bias: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1863\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[CreateCompletionResponse, Iterator[CreateCompletionStreamResponse]]:\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate text from a prompt.\u001b[39;00m\n\u001b[1;32m   1865\u001b[0m \n\u001b[1;32m   1866\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1898\u001b[0m \u001b[38;5;124;03m        Response object containing the generated text.\u001b[39;00m\n\u001b[1;32m   1899\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1907\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1908\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1909\u001b[0m \u001b[43m        \u001b[49m\u001b[43mecho\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mecho\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1910\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1911\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1918\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1833\u001b[0m, in \u001b[0;36mLlama.create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1831\u001b[0m     chunks: Iterator[CreateCompletionStreamResponse] \u001b[38;5;241m=\u001b[39m completion_or_chunks\n\u001b[1;32m   1832\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[0;32m-> 1833\u001b[0m completion: Completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcompletion_or_chunks\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   1834\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m completion\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:1318\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m   1316\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1317\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1318\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:910\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    911\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    912\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    913\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    914\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    928\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    929\u001b[0m         )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/llama.py:643\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    639\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    641\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    642\u001b[0m )\n\u001b[0;32m--> 643\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
            "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/llama_cpp/_internals.py:300\u001b[0m, in \u001b[0;36mLlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: LlamaBatch):\n\u001b[0;32m--> 300\u001b[0m     return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from rdflib import Graph, Namespace, RDF, RDFS, OWL\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Load TTL file\n",
        "g = Graph()\n",
        "g.parse(\"only_events.ttl\", format=\"turtle\")\n",
        "\n",
        "EX = Namespace(\"http://example.org/\")\n",
        "ontology_dict = {}\n",
        "\n",
        "# Extract classes\n",
        "for s in g.subjects(RDF.type, OWL.Class):\n",
        "    triples = [f\"{s.n3(g.namespace_manager)} {p.n3(g.namespace_manager)} {o.n3(g.namespace_manager)} .\"\n",
        "               for p, o in g.predicate_objects(s)]\n",
        "    ontology_dict[str(s)] = \"\\n\".join(triples)\n",
        "\n",
        "# Extract properties (datatype + object)\n",
        "for prop_type in [OWL.DatatypeProperty, OWL.ObjectProperty]:\n",
        "    for s in g.subjects(RDF.type, prop_type):\n",
        "        triples = [f\"{s.n3(g.namespace_manager)} {p.n3(g.namespace_manager)} {o.n3(g.namespace_manager)} .\"\n",
        "                   for p, o in g.predicate_objects(s)]\n",
        "        ontology_dict[str(s)] = \"\\n\".join(triples)\n",
        "\n",
        "# Question to evaluate\n",
        "question = \"What are the names of the events happen on 2015-12-12?\"\n",
        "\n",
        "# Function to prompt local LLaMA model\n",
        "def is_relevant_to_question(question, ttl_snippet):\n",
        "    prompt = f\"\"\"### Instruction:\n",
        "You are an expert in semantic web and RDF. Here is an RDF/Turtle snippet:\n",
        "\n",
        "{ttl_snippet}\n",
        "\n",
        "Determine if it is relevant to answering the following question:\n",
        "\"{question}\"\n",
        "\n",
        "Respond with either \"Yes\" or \"No\", and a short reason why.\n",
        "\n",
        "### Response:\"\"\"\n",
        "\n",
        "    response = llm(prompt, max_tokens=256, stop=[\"###\"])\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n",
        "# Evaluate relevance\n",
        "for iri, snippet in ontology_dict.items():\n",
        "    result = is_relevant_to_question(question, snippet)\n",
        "    print(f\"IRI: {iri}\\nRelevant? {result}\\n{'-'*60}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e41f3163-35e4-4d4c-8136-ad99bd66d26d",
      "metadata": {
        "id": "e41f3163-35e4-4d4c-8136-ad99bd66d26d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e34387e0-7ade-4e6c-b093-2abd60f3732c",
      "metadata": {
        "id": "e34387e0-7ade-4e6c-b093-2abd60f3732c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2decd8a3-02a5-4cdb-b833-c0f7b101145d",
      "metadata": {
        "id": "2decd8a3-02a5-4cdb-b833-c0f7b101145d"
      },
      "source": [
        "## Updated version with document as dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a7b46b-9fa0-4a31-9693-bdc61b7a4a12",
      "metadata": {
        "id": "a6a7b46b-9fa0-4a31-9693-bdc61b7a4a12"
      },
      "outputs": [],
      "source": [
        "ontology_dict = {\n",
        "    \"ex:eventat\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:Location ;\n",
        "    rdfs:range ex:Event ;\n",
        "    rdfs:label \"Event At\" .''',\n",
        "\n",
        "    \"ex:eventon\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range ex:Event ;\n",
        "    rdfs:label \"Event On\" .''',\n",
        "\n",
        "    \"ex:eventcatclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:EventCategory ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Eventcat Classid\" .''',\n",
        "\n",
        "    \"ex:eventcatname_it\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:EventCategory ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Eventcat Name\" .''',\n",
        "\n",
        "    \"ex:eventclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Class ID\" .''',\n",
        "\n",
        "    \"ex:eventdescr_it\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Description (IT)\" .''',\n",
        "\n",
        "    \"ex:eventimage_url\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Image URL\" .''',\n",
        "\n",
        "    \"ex:eventname_it\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Name\" .''',\n",
        "\n",
        "    \"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\n",
        "    \"ex:calendarclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Calendar Class ID\" .''',\n",
        "\n",
        "    \"ex:day\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:date ;\n",
        "    rdfs:label \"day\" .''',\n",
        "\n",
        "    \"ex:end_time\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"EndTime\" .''',\n",
        "\n",
        "    \"ex:start_time\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"StartTime\" .''',\n",
        "\n",
        "    \"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "\n",
        "    \"ex:Location\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Location\" .''',\n",
        "\n",
        "    \"ex:locationclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Location ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Location Class ID\" .''',\n",
        "\n",
        "    \"ex:address\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Location ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Address\" .''',\n",
        "\n",
        "    \"ex:eventstate\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range ex:State ;\n",
        "    rdfs:label \"Event State\" .''',\n",
        "\n",
        "    \"ex:hasCategory\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:ArtCategory ,\n",
        "                ex:EventCategory ;\n",
        "    rdfs:range ex:Art ,\n",
        "               ex:Event ;\n",
        "    rdfs:label \"Has Category\" .''',\n",
        "\n",
        "    \"ex:statecode\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:State ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"State code\" .''',\n",
        "\n",
        "    \"ex:statename\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:State ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"State name\" .''',\n",
        "\n",
        "    \"ex:State\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"State\" .'''\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79bb492-6ac9-4b5b-a55c-ed7b043c2375",
      "metadata": {
        "id": "c79bb492-6ac9-4b5b-a55c-ed7b043c2375",
        "outputId": "0955134c-9f2e-4fb9-bd33-7d82a39d3a06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ex:eventat': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .',\n",
              " 'ex:eventon': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .',\n",
              " 'ex:eventcatclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .',\n",
              " 'ex:eventcatname_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .',\n",
              " 'ex:eventclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .',\n",
              " 'ex:eventdescr_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .',\n",
              " 'ex:eventimage_url': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .',\n",
              " 'ex:eventname_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .',\n",
              " 'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              " 'ex:calendarclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .',\n",
              " 'ex:day': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .',\n",
              " 'ex:end_time': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .',\n",
              " 'ex:start_time': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .',\n",
              " 'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .',\n",
              " 'ex:Location': 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .',\n",
              " 'ex:locationclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .',\n",
              " 'ex:address': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .',\n",
              " 'ex:eventstate': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .',\n",
              " 'ex:hasCategory': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:ArtCategory ,\\n                ex:EventCategory ;\\n    rdfs:range ex:Art ,\\n               ex:Event ;\\n    rdfs:label \"Has Category\" .',\n",
              " 'ex:statecode': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .',\n",
              " 'ex:statename': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .',\n",
              " 'ex:State': 'rdf:type owl:Class ;\\n    rdfs:label \"State\" .'}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ontology_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc33e9e-f305-44ce-8120-1d9ee5cee5fb",
      "metadata": {
        "id": "cdc33e9e-f305-44ce-8120-1d9ee5cee5fb"
      },
      "source": [
        "#### separate into two dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2227369-d0f1-4dab-be04-c91d67651fea",
      "metadata": {
        "id": "b2227369-d0f1-4dab-be04-c91d67651fea"
      },
      "outputs": [],
      "source": [
        "class_dict = {}\n",
        "property_dict = {}\n",
        "\n",
        "for iri, snippet in ontology_dict.items():\n",
        "    if \"owl:Class\" in snippet:\n",
        "        class_dict[iri] = snippet\n",
        "    else:\n",
        "        property_dict[iri] = snippet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97427c03-8665-4388-bec6-506f081359a8",
      "metadata": {
        "id": "97427c03-8665-4388-bec6-506f081359a8",
        "outputId": "62c60600-4ef5-416e-88e1-a59a68488c61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              " 'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .',\n",
              " 'ex:Location': 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .',\n",
              " 'ex:State': 'rdf:type owl:Class ;\\n    rdfs:label \"State\" .'}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ae46f5-9e3d-466c-988a-2d5a813e817a",
      "metadata": {
        "id": "53ae46f5-9e3d-466c-988a-2d5a813e817a",
        "outputId": "aace951f-6b89-4551-c2a2-652c718a252c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ex:eventat': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .',\n",
              " 'ex:eventon': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .',\n",
              " 'ex:eventcatclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .',\n",
              " 'ex:eventcatname_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .',\n",
              " 'ex:eventclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .',\n",
              " 'ex:eventdescr_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .',\n",
              " 'ex:eventimage_url': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .',\n",
              " 'ex:eventname_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .',\n",
              " 'ex:calendarclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .',\n",
              " 'ex:day': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .',\n",
              " 'ex:end_time': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .',\n",
              " 'ex:start_time': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .',\n",
              " 'ex:locationclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .',\n",
              " 'ex:address': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .',\n",
              " 'ex:eventstate': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .',\n",
              " 'ex:hasCategory': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:ArtCategory ,\\n                ex:EventCategory ;\\n    rdfs:range ex:Art ,\\n               ex:Event ;\\n    rdfs:label \"Has Category\" .',\n",
              " 'ex:statecode': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .',\n",
              " 'ex:statename': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .'}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "property_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ea1bef4-226b-4644-9355-5709f9efb935",
      "metadata": {
        "id": "1ea1bef4-226b-4644-9355-5709f9efb935",
        "outputId": "f7478efa-1a4b-41c3-c1e9-44778655f4c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 129 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   129 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   122 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   98844.11 ms /   251 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 84 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:Event\n",
            "Relevant? I would like to know the names of the events that happened on 2015-12-12.\n",
            "\n",
            "What are the relevant class names for this query?\n",
            "\n",
            "Please select and list the class names that are relevant for answering this question.\n",
            "\n",
            "The relevant class names are:\n",
            "Event\n",
            "\n",
            "Please select the class names that are relevant for answering this question.\n",
            "\n",
            "(Note: You can select multiple class names by holding the Ctrl key while selecting)\n",
            "\n",
            "Select class names: Event\"\n",
            "\n",
            "I selected \"Event\" as the relevant class name.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    84 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    79 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   64073.24 ms /   163 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 84 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:Calendar\n",
            "Relevant? My answer:\n",
            " Calendar, Event\n",
            "\n",
            "Explanation:\n",
            "The class \"Calendar\" is relevant for extracting information about the names of events happening on a specific date, such as 2015-12-12. The \"Event\" class is also relevant, as it represents an occurrence of a event, which can be a part of a calendar.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    84 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15351.55 ms /    98 tokens\n",
            "Llama.generate: 46 prefix-match hit, remaining 84 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:Location\n",
            "Relevant? Your answer: owl:Class, rdf:type\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    84 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18338.07 ms /   102 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:State\n",
            "Relevant? Please provide your answer as a list of class names, without any additional information.\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happen on 2015-12-12?\"\n",
        "\n",
        "def is_relevant_to_question(question, ttl_snippet):\n",
        "    prompt = f\"\"\"You are a semantic web expert.\\n\n",
        "                    \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "                    {ttl_snippet}\n",
        "                    \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "                    f\"'{question}'\\n\\n\"\n",
        "        \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\"\"\n",
        "\n",
        "    response = llm(prompt, max_tokens=256, stop=[\"###\"])\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n",
        "# Evaluate relevance of classes only\n",
        "for iri, snippet in class_dict.items():\n",
        "    result = is_relevant_to_question(question, snippet)\n",
        "    print(f\"IRI: {iri}\\nRelevant? {result}\\n{'-'*60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93472189-1348-4a1c-a5f8-b289399df758",
      "metadata": {
        "id": "93472189-1348-4a1c-a5f8-b289399df758"
      },
      "source": [
        "#### Optimize the prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9ea2ff2-2e9a-4af9-8c73-73794374e624",
      "metadata": {
        "id": "d9ea2ff2-2e9a-4af9-8c73-73794374e624",
        "outputId": "b91e393b-5b01-4b03-e7f1-4be1989d4c7e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 10 prefix-match hit, remaining 105 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   105 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    83 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   77243.64 ms /   188 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 75 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:Event\n",
            "Relevant? My answer:\n",
            "rdf:type, owl:Class\n",
            "\n",
            "Explanation:\n",
            "The classes that are relevant for extracting information about the names of events that happened on 2015-12-12 are:\n",
            "* rdf:type\n",
            "* owl:Class\n",
            "\n",
            "Note: The answer is limited to the classes specified in the RDF schema provided.\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    75 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17908.34 ms /    91 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 75 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:Calendar\n",
            "Relevant? Answer: rdf:type, rdfs:label\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    75 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    54 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   51895.56 ms /   129 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 75 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:Location\n",
            "Relevant? I would like to know the names of the events that happened on 2015-12-12.\n",
            "\n",
            "            rdf:type owl:Class .\n",
            "\n",
            "            Relevant class names:\n",
            "\n",
            "            Location, Event\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    75 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25438.91 ms /    99 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "IRI: ex:State\n",
            "Relevant? - rdf:type owl:Class .\n",
            "         - rdfs:label \"Event\" .\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happen on 2015-12-12?\"\n",
        "relevant_class_results = []\n",
        "\n",
        "def is_relevant_to_question(question, ttl_snippet):\n",
        "    prompt = f\"\"\"You are a semantic web expert.\n",
        "\n",
        "             Given the following classes in an RDF schema:\n",
        "\n",
        "            {ttl_snippet}\n",
        "\n",
        "            Which of these classes are relevant for extracting information about the following question:\n",
        "\n",
        "            \"{question}\"\n",
        "\n",
        "            Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\"\"\n",
        "\n",
        "\n",
        "    response = llm(prompt, max_tokens=256, stop=[\"###\"])\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n",
        "relevant_classes = []\n",
        "\n",
        "for iri, snippet in class_dict.items():\n",
        "    result = is_relevant_to_question(question, snippet)\n",
        "    print(f\"IRI: {iri}\\nRelevant? {result}\\n{'-'*60}\")\n",
        "    if result.lower() == \"yes\":\n",
        "        relevant_classes.append({\n",
        "            \"question\": question,\n",
        "            \"class_iri\": iri,\n",
        "            \"label\": snippet.split('rdfs:label')[-1].split('\"')[1] if 'rdfs:label' in snippet else \"Unknown\"\n",
        "        })"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "330c54d9-1d2f-4411-8212-09489593ca24",
      "metadata": {
        "id": "330c54d9-1d2f-4411-8212-09489593ca24"
      },
      "source": [
        "#### use the same prompt structure used earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6562cd4d-a211-44bb-a670-f8043e5e35cc",
      "metadata": {
        "id": "6562cd4d-a211-44bb-a670-f8043e5e35cc"
      },
      "outputs": [],
      "source": [
        "relevant_classes = []\n",
        "questions_responses = []\n",
        "\n",
        "def ask_relevant_classes(question, class_dict, llm):\n",
        "\n",
        "    relevant_classes = []\n",
        "\n",
        "    for class_ in class_dict:\n",
        "            prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\" Is the following class relevant? {class_} Answer only YES or NO.\"\"\"\n",
        "            response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "\n",
        "            #answer = response.strip().upper()\n",
        "            answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "            if \"YES\" in answer:\n",
        "               relevant_classes.append(class_)\n",
        "\n",
        "    questions_responses.append({\"question\": question,\"response\": relevant_classes})\n",
        "\n",
        "    return relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44a5ec22-7920-42da-bd15-bbe0fe1da391",
      "metadata": {
        "id": "44a5ec22-7920-42da-bd15-bbe0fe1da391",
        "outputId": "0e014a43-4646-4bb3-b6b2-ae0bd5ebc2cc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 1 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7259.26 ms /    55 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41813.00 ms /    56 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41064.21 ms /    56 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7925.08 ms /    16 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['ex:Event', 'ex:Location', 'ex:State']\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_1, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d343b5dc-7f2f-4aba-8dfb-e296c418b64e",
      "metadata": {
        "id": "d343b5dc-7f2f-4aba-8dfb-e296c418b64e",
        "outputId": "b7c9ef8d-6a53-4a95-951e-99a0d9175c01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': ['ex:Event', 'ex:Location', 'ex:State']}]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c773556-7d09-4e27-8b01-8f7c9e6acbc6",
      "metadata": {
        "id": "9c773556-7d09-4e27-8b01-8f7c9e6acbc6",
        "outputId": "93ca8b14-4a36-4a41-8514-463d22929c87"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 19 prefix-match hit, remaining 28 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    28 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    48 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   46389.93 ms /    76 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39757.51 ms /    51 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8927.04 ms /    16 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6229.10 ms /    13 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['ex:Location', 'ex:State']\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_2, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c68e56a-d7eb-44de-bd35-603a96099f40",
      "metadata": {
        "id": "7c68e56a-d7eb-44de-bd35-603a96099f40",
        "outputId": "cb45bf6b-d447-493a-a12f-96943032c63e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': ['ex:Event', 'ex:Location', 'ex:State']},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': ['ex:Location', 'ex:State']}]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "506a328d-adab-487a-b768-0e3cd74c7103",
      "metadata": {
        "id": "506a328d-adab-487a-b768-0e3cd74c7103",
        "outputId": "8c39ff3d-ce4b-47d7-88f7-246532dc2ad0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 33 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    33 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39713.40 ms /    82 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39252.10 ms /    56 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39624.76 ms /    56 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5385.36 ms /    13 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['ex:Calendar', 'ex:State']\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_3, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a81b444-3068-47af-8ac5-87b207ac2347",
      "metadata": {
        "id": "6a81b444-3068-47af-8ac5-87b207ac2347",
        "outputId": "fc104dd2-01b3-4322-bf8a-b6b25ae471aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 27 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    27 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40141.24 ms /    76 tokens\n",
            "Llama.generate: 38 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24371.34 ms /    39 tokens\n",
            "Llama.generate: 38 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    42 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   33299.28 ms /    49 tokens\n",
            "Llama.generate: 38 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37746.31 ms /    56 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['ex:Calendar', 'ex:Location']\n"
          ]
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_4, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5b59dae-1133-42bf-b34c-add8cfd701f3",
      "metadata": {
        "id": "e5b59dae-1133-42bf-b34c-add8cfd701f3",
        "outputId": "820bf90d-840f-420e-8124-6f9a6db1cafe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 15 prefix-match hit, remaining 25 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    25 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40929.95 ms /    74 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40176.70 ms /    56 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40078.33 ms /    56 tokens\n",
            "Llama.generate: 33 prefix-match hit, remaining 7 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     7 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39179.96 ms /    56 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: ['ex:Event', 'ex:Location', 'ex:State']\n"
          ]
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_5, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9e6945f-d087-4875-8715-74de08c91f24",
      "metadata": {
        "id": "a9e6945f-d087-4875-8715-74de08c91f24",
        "outputId": "03c741a2-ad5e-4463-c28b-342526d5c960"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': ['ex:Event', 'ex:Location', 'ex:State']},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': ['ex:Location', 'ex:State']},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12?',\n",
              "  'response': ['ex:Calendar', 'ex:State']},\n",
              " {'question': 'What are the events scheduled to start at 11.30?',\n",
              "  'response': ['ex:Calendar', 'ex:Location']},\n",
              " {'question': 'Can you give the event names and their status?',\n",
              "  'response': ['ex:Event', 'ex:Location', 'ex:State']}]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c416329a-4ed3-460d-ac5e-f0a19c11ed29",
      "metadata": {
        "id": "c416329a-4ed3-460d-ac5e-f0a19c11ed29"
      },
      "source": [
        "##### In dictionary, category class missed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f30806d6-721f-4cf5-b456-979893cf5334",
      "metadata": {
        "id": "f30806d6-721f-4cf5-b456-979893cf5334"
      },
      "outputs": [],
      "source": [
        "ontology_dict = {\n",
        "    \"ex:eventat\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:Location ;\n",
        "    rdfs:range ex:Event ;\n",
        "    rdfs:label \"Event At\" .''',\n",
        "\n",
        "    \"ex:eventon\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range ex:Event ;\n",
        "    rdfs:label \"Event On\" .''',\n",
        "\n",
        "    \"ex:eventcatclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:EventCategory ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Eventcat Classid\" .''',\n",
        "\n",
        "    \"ex:eventcatname_it\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:EventCategory ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Eventcat Name\" .''',\n",
        "\n",
        "    \"ex:eventclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Class ID\" .''',\n",
        "\n",
        "    \"ex:eventdescr_it\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Description (IT)\" .''',\n",
        "\n",
        "    \"ex:eventimage_url\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Image URL\" .''',\n",
        "\n",
        "    \"ex:eventname_it\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Event Name\" .''',\n",
        "\n",
        "    \"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\n",
        "    \"ex:calendarclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Calendar Class ID\" .''',\n",
        "\n",
        "    \"ex:day\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:date ;\n",
        "    rdfs:label \"day\" .''',\n",
        "\n",
        "    \"ex:end_time\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"EndTime\" .''',\n",
        "\n",
        "    \"ex:start_time\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Calendar ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"StartTime\" .''',\n",
        "\n",
        "    \"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "\n",
        "    \"ex:Location\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Location\" .''',\n",
        "\n",
        "    \"ex:EventCategory\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event Category\" .''',\n",
        "\n",
        "    \"ex:locationclassid\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Location ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Location Class ID\" .''',\n",
        "\n",
        "    \"ex:address\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:Location ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"Address\" .''',\n",
        "\n",
        "    \"ex:eventstate\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:Event ;\n",
        "    rdfs:range ex:State ;\n",
        "    rdfs:label \"Event State\" .''',\n",
        "\n",
        "    \"ex:hasCategory\": '''rdf:type owl:ObjectProperty ;\n",
        "    rdfs:domain ex:EventCategory ;\n",
        "    rdfs:range ex:Event ;\n",
        "    rdfs:label \"Has Category\" .''',\n",
        "\n",
        "    \"ex:statecode\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:State ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"State code\" .''',\n",
        "\n",
        "    \"ex:statename\": '''rdf:type owl:DatatypeProperty ;\n",
        "    rdfs:domain ex:State ;\n",
        "    rdfs:range xsd:string ;\n",
        "    rdfs:label \"State name\" .''',\n",
        "\n",
        "    \"ex:State\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"State\" .'''\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f094852-8076-473a-9482-9588a00e60e3",
      "metadata": {
        "id": "3f094852-8076-473a-9482-9588a00e60e3"
      },
      "outputs": [],
      "source": [
        "class_dict = {}\n",
        "property_dict = {}\n",
        "\n",
        "for iri, snippet in ontology_dict.items():\n",
        "    if \"owl:Class\" in snippet:\n",
        "        class_dict[iri] = snippet\n",
        "    else:\n",
        "        property_dict[iri] = snippet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "664ad185-86f6-4fcb-9a7f-00c0ae7cfa15",
      "metadata": {
        "id": "664ad185-86f6-4fcb-9a7f-00c0ae7cfa15",
        "outputId": "b0c6eb1d-da3e-4ee0-d742-7742394a275d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              " 'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .',\n",
              " 'ex:Location': 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .',\n",
              " 'ex:EventCategory': 'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .',\n",
              " 'ex:State': 'rdf:type owl:Class ;\\n    rdfs:label \"State\" .'}"
            ]
          },
          "execution_count": 568,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82e7589-7088-430a-ac86-32427ed4da9c",
      "metadata": {
        "id": "f82e7589-7088-430a-ac86-32427ed4da9c",
        "outputId": "8268a126-5d66-466f-fb0a-ebab407c7881"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ex:eventat': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .',\n",
              " 'ex:eventon': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .',\n",
              " 'ex:eventcatclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .',\n",
              " 'ex:eventcatname_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .',\n",
              " 'ex:eventclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .',\n",
              " 'ex:eventdescr_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .',\n",
              " 'ex:eventimage_url': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .',\n",
              " 'ex:eventname_it': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .',\n",
              " 'ex:calendarclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .',\n",
              " 'ex:day': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .',\n",
              " 'ex:end_time': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .',\n",
              " 'ex:start_time': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .',\n",
              " 'ex:locationclassid': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .',\n",
              " 'ex:address': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .',\n",
              " 'ex:eventstate': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .',\n",
              " 'ex:hasCategory': 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .',\n",
              " 'ex:statecode': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .',\n",
              " 'ex:statename': 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .'}"
            ]
          },
          "execution_count": 569,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "property_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "744271f3-6c5c-41c8-94c1-fd1c19dd55ed",
      "metadata": {
        "id": "744271f3-6c5c-41c8-94c1-fd1c19dd55ed"
      },
      "outputs": [],
      "source": [
        "relevant_classes = []\n",
        "questions_responses = []\n",
        "\n",
        "def ask_relevant_classes(question, class_dict, llm):\n",
        "\n",
        "    relevant_classes = []\n",
        "\n",
        "    for class_ in class_dict.items():\n",
        "            prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\" Is the following class relevant? {class_} Answer only YES or NO.\"\"\"\n",
        "            response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "\n",
        "            answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "            if \"YES\" in answer:\n",
        "               relevant_classes.append(class_)\n",
        "\n",
        "    questions_responses.append({\"question\": question,\"response\": relevant_classes})\n",
        "\n",
        "    return relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bd8eec0-21fd-4f1e-97d2-a299275d01b2",
      "metadata": {
        "id": "7bd8eec0-21fd-4f1e-97d2-a299275d01b2",
        "outputId": "814dfc78-8902-4cba-a9c9-76510437368f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 19 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     4 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6916.31 ms /    60 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41530.81 ms /    79 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40040.01 ms /    79 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42529.14 ms /    81 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21444.17 ms /    54 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [('ex:Event', 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .'), ('ex:State', 'rdf:type owl:Class ;\\n    rdfs:label \"State\" .')]\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_1, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7e99b8a-38a7-4070-92cf-c185ff6bf6c8",
      "metadata": {
        "id": "f7e99b8a-38a7-4070-92cf-c185ff6bf6c8",
        "outputId": "b5d4d2f0-b05d-4316-9a53-3b598cd02868"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 19 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4481.38 ms /    54 tokens\n",
            "Llama.generate: 41 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38808.93 ms /    79 tokens\n",
            "Llama.generate: 41 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6098.82 ms /    35 tokens\n",
            "Llama.generate: 41 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41881.09 ms /    81 tokens\n",
            "Llama.generate: 41 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18533.59 ms /    50 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [('ex:Location', 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .')]\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_2, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da346fe9-db12-4355-873b-91990cd65a7b",
      "metadata": {
        "id": "da346fe9-db12-4355-873b-91990cd65a7b",
        "outputId": "3269eac1-0be7-4374-ba88-ae7a2717539f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5236.54 ms /    59 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7995.67 ms /    37 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10295.87 ms /    40 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     4 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5129.59 ms /    36 tokens\n",
            "Llama.generate: 45 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3802.37 ms /    32 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [('ex:EventCategory', 'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .')]\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_3, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de34ce73-e6bb-444c-b238-fa4d5feb3d28",
      "metadata": {
        "id": "de34ce73-e6bb-444c-b238-fa4d5feb3d28",
        "outputId": "bf9cc5be-f4f1-4fa9-a1cc-ad542ee3e643"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     4 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6183.34 ms /    55 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41402.54 ms /    79 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6274.86 ms /    36 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41127.63 ms /    81 tokens\n",
            "Llama.generate: 39 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3664.96 ms /    32 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [('ex:Event', 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .'), ('ex:Location', 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .')]\n"
          ]
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_4, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8750e06e-63cc-462e-81c0-0e227ffe639b",
      "metadata": {
        "id": "8750e06e-63cc-462e-81c0-0e227ffe639b",
        "outputId": "05c50d9c-99bd-4d63-b76b-ae84d6e80487"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 15 prefix-match hit, remaining 49 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    49 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   34150.59 ms /    86 tokens\n",
            "Llama.generate: 34 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10491.61 ms /    40 tokens\n",
            "Llama.generate: 34 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4495.11 ms /    33 tokens\n",
            "Llama.generate: 34 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42510.47 ms /    81 tokens\n",
            "Llama.generate: 34 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4388.97 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9389.34 ms /    39 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [('ex:Event', 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .'), ('ex:Calendar', 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .')]\n"
          ]
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_5, class_dict, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60182fac-29b6-4de7-affb-e41a91a6fd91",
      "metadata": {
        "id": "60182fac-29b6-4de7-affb-e41a91a6fd91"
      },
      "source": [
        "#### when uses for class_ in class_only.item():"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f500f120-ed98-4d01-b72a-f118fe954a83",
      "metadata": {
        "id": "f500f120-ed98-4d01-b72a-f118fe954a83",
        "outputId": "a619ea4b-44d1-4325-ad30-d313e3317d69"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': [('ex:EventCategory',\n",
              "    'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .')]},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': [('ex:Location',\n",
              "    'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .'),\n",
              "   ('ex:EventCategory',\n",
              "    'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .')]},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12?',\n",
              "  'response': [('ex:Event', 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .'),\n",
              "   ('ex:Calendar', 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .')]},\n",
              " {'question': 'What are the events scheduled to start at 11.30?',\n",
              "  'response': [('ex:Event', 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .'),\n",
              "   ('ex:Calendar', 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .'),\n",
              "   ('ex:EventCategory',\n",
              "    'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .')]},\n",
              " {'question': 'Can you give the event names and their status?',\n",
              "  'response': [('ex:Event', 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .'),\n",
              "   ('ex:Calendar', 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .')]}]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce790d32-22b5-41ea-9f83-5da87afe0abf",
      "metadata": {
        "id": "ce790d32-22b5-41ea-9f83-5da87afe0abf"
      },
      "source": [
        "#### when uses for class_ in class_only:  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4188b5c4-ad60-4895-b92e-d1371937d13e",
      "metadata": {
        "id": "4188b5c4-ad60-4895-b92e-d1371937d13e",
        "outputId": "e8d7df7e-9036-4b49-efb9-5d10c407a123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': ['ex:Calendar', 'ex:Location', 'ex:EventCategory', 'ex:State']},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12?',\n",
              "  'response': ['ex:Location', 'ex:EventCategory']},\n",
              " {'question': 'What are the events scheduled to start at 11.30?',\n",
              "  'response': ['ex:Location', 'ex:EventCategory', 'ex:State']},\n",
              " {'question': 'Can you give the event names and their status?',\n",
              "  'response': ['ex:EventCategory']}]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9b9d771-3379-4881-87d0-d4d72c9d4c4e",
      "metadata": {
        "id": "e9b9d771-3379-4881-87d0-d4d72c9d4c4e"
      },
      "source": [
        "### Derive relevant properites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb9b1b0b-4ad5-44dc-882f-c5e7c4c0914a",
      "metadata": {
        "id": "bb9b1b0b-4ad5-44dc-882f-c5e7c4c0914a"
      },
      "outputs": [],
      "source": [
        "questions_responses_prop = []\n",
        "\n",
        "def ask_relevant_properties(question, relevant_classes, property_dict, llm):\n",
        "    class_to_properties = {}\n",
        "\n",
        "    for class_name, class_description in relevant_classes.items():\n",
        "        relevant_props = []\n",
        "\n",
        "        for prop_name, prop_description in property_dict.items():\n",
        "            prompt = f\"\"\"You are a SPARQL expert.\n",
        "Given the user question: \"{question}\" and the class {class_name} with description:\n",
        "{class_description}\n",
        "\n",
        "Is the following property relevant for retrieving information from class {class_name}?\n",
        "\n",
        "{prop_name} {prop_description}\n",
        "\n",
        "Answer only YES or NO.\"\"\"\n",
        "            response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "            answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "            if \"YES\" in answer:\n",
        "                relevant_props.append((prop_name, prop_description))\n",
        "\n",
        "        class_to_properties[class_name] = relevant_props\n",
        "\n",
        "    questions_responses_prop.append({\n",
        "        \"question\": question,\n",
        "        \"relevant_classes\": relevant_classes,\n",
        "        \"response\": class_to_properties\n",
        "    })\n",
        "\n",
        "    return class_to_properties"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "113a0bf8-ccd3-4daa-bb1d-7aafd620ed90",
      "metadata": {
        "id": "113a0bf8-ccd3-4daa-bb1d-7aafd620ed90"
      },
      "source": [
        "#### First provide the correct relevant classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a3588b-73f6-4e2d-b4de-fa71ad5d59aa",
      "metadata": {
        "scrolled": true,
        "id": "e0a3588b-73f6-4e2d-b4de-fa71ad5d59aa",
        "outputId": "2c644625-bcb2-4a9f-8484-669b62ee5b67"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 43 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    97 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39878.46 ms /   146 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38191.01 ms /    99 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7082.36 ms /    62 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38640.39 ms /   105 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10814.81 ms /    64 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    46 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37421.41 ms /   103 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38315.29 ms /   104 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   29423.60 ms /    91 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37351.58 ms /   104 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38152.80 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38621.91 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39211.06 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39170.14 ms /   104 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5049.13 ms /    54 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8348.30 ms /    58 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38469.73 ms /   101 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11806.09 ms /    65 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38277.69 ms /   103 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40679.21 ms /   145 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38076.73 ms /    99 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38172.21 ms /   106 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15243.69 ms /    73 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25466.81 ms /    85 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14979.56 ms /    73 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    41 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   32701.56 ms /    96 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39524.96 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39589.12 ms /   104 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14489.48 ms /    66 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10044.46 ms /    63 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8668.06 ms /    61 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38253.80 ms /   104 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    47 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   36729.21 ms /    98 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10218.63 ms /    61 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38173.77 ms /   101 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38433.45 ms /   102 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6612.06 ms /    59 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Event': [('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:eventcatname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:eventimage_url', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'), ('ex:eventname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'), ('ex:calendarclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'), ('ex:end_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'), ('ex:start_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'), ('ex:hasCategory', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:Calendar': [('ex:eventat', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'), ('ex:eventimage_url', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'), ('ex:eventname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'), ('ex:calendarclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:address', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'), ('ex:hasCategory', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = {\n",
        "    \"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "    \"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_1, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe4d8040-f4e9-44fc-a6bb-1d50283f7909",
      "metadata": {
        "id": "fe4d8040-f4e9-44fc-a6bb-1d50283f7909"
      },
      "source": [
        "### Provide the relevant classes given by model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94e007e8-bbc4-461a-af55-11cf81c1f33f",
      "metadata": {
        "id": "94e007e8-bbc4-461a-af55-11cf81c1f33f",
        "outputId": "29005276-283a-4c81-b602-7458aa3ba8fb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 43 prefix-match hit, remaining 99 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    99 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30686.62 ms /   133 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5354.86 ms /    53 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   36636.99 ms /   102 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16596.60 ms /    74 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39459.68 ms /   103 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39956.87 ms /   106 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39278.47 ms /   104 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10185.68 ms /    64 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30907.88 ms /    93 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37420.72 ms /   100 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38177.41 ms /   103 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7655.81 ms /    60 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39017.73 ms /   104 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13463.68 ms /    65 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38550.86 ms /   100 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38701.02 ms /   101 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38122.34 ms /   102 tokens\n",
            "Llama.generate: 91 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38473.85 ms /   103 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:EventCategory': [('ex:eventat', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'), ('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:end_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'), ('ex:start_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'), ('ex:eventstate', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = {\n",
        "    \"ex:EventCategory\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event Category\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_1, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "534265aa-7166-41be-b80f-5f30cd27e34c",
      "metadata": {
        "id": "534265aa-7166-41be-b80f-5f30cd27e34c",
        "outputId": "03564063-404f-443b-a12e-2a1164035cce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 21 prefix-match hit, remaining 112 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   112 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41462.64 ms /   161 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38840.77 ms /    99 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    47 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37433.84 ms /   104 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38390.13 ms /   105 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3227.01 ms /    55 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30204.03 ms /    94 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10040.95 ms /    64 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   35496.66 ms /    98 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39250.87 ms /   104 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39376.40 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9257.55 ms /    63 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38568.07 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39126.26 ms /   104 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38550.72 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   23307.64 ms /    79 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38355.61 ms /   101 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38992.44 ms /   102 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     4 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6207.66 ms /    58 tokens\n",
            "Llama.generate: 37 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5354.51 ms /    97 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24778.53 ms /    79 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18147.91 ms /    77 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12177.90 ms /    69 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38091.99 ms /   103 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39511.80 ms /   106 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38977.13 ms /   104 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38724.45 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38728.00 ms /   104 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14147.94 ms /    66 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38468.54 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39937.87 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17256.85 ms /    74 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10052.71 ms /    60 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    42 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   34447.81 ms /    93 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2760.34 ms /    53 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38711.64 ms /   102 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38857.04 ms /   103 tokens\n",
            "Llama.generate: 37 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17666.03 ms /   113 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38316.46 ms /    99 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38796.56 ms /   106 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39261.87 ms /   105 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10068.86 ms /    63 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20568.97 ms /    80 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7885.25 ms /    61 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38998.51 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3328.29 ms /    56 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39045.93 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    41 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   32296.12 ms /    95 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38394.94 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38450.28 ms /   104 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38022.64 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38503.96 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    44 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   35994.85 ms /    96 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7099.93 ms /    58 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39890.59 ms /   103 tokens\n",
            "Llama.generate: 37 prefix-match hit, remaining 99 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    99 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17182.08 ms /   114 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2968.58 ms /    51 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15110.65 ms /    73 tokens\n",
            "Llama.generate: 87 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10894.07 ms /    66 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    24 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20648.82 ms /    78 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   35947.27 ms /   102 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3213.15 ms /    56 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37150.39 ms /   103 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10206.15 ms /    65 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38237.45 ms /   100 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10933.49 ms /    65 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8529.30 ms /    61 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39639.23 ms /   104 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5194.06 ms /    54 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39418.78 ms /   100 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    47 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38246.12 ms /    99 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38260.76 ms /   102 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38758.10 ms /   103 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Event': [('ex:eventat', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'), ('ex:eventon', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'), ('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:eventname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'), ('ex:calendarclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'), ('ex:eventstate', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:Calendar': [('ex:eventon', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'), ('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:eventimage_url', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:Location': [('ex:eventimage_url', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'), ('ex:eventname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:hasCategory', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')], 'ex:EventCategory': [('ex:eventat', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "\"ex:Location\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Location\" .''',\n",
        "\"ex:EventCategory\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event Category\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_2, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ab0b772-ab8f-4de7-a640-47e6b745ffa6",
      "metadata": {
        "id": "0ab0b772-ab8f-4de7-a640-47e6b745ffa6",
        "outputId": "474b073c-6adc-410f-8286-18f745cbe060"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 37 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40982.15 ms /   145 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38327.26 ms /    99 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10555.40 ms /    67 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10644.57 ms /    66 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39505.66 ms /   103 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17736.49 ms /    76 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38718.75 ms /   104 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39623.58 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39209.26 ms /   104 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37626.37 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14792.99 ms /    70 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38933.21 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21434.96 ms /    80 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3163.95 ms /    52 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13454.13 ms /    65 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19348.74 ms /    74 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13233.19 ms /    66 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19268.07 ms /    75 tokens\n",
            "Llama.generate: 37 prefix-match hit, remaining 99 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    99 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14200.14 ms /   110 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40363.47 ms /    99 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40032.05 ms /   106 tokens\n",
            "Llama.generate: 87 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38377.32 ms /   105 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38482.05 ms /   103 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    41 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   33380.27 ms /    98 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25014.56 ms /    85 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   28016.62 ms /    88 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38917.64 ms /   104 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    40 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   32894.35 ms /    91 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   23304.56 ms /    80 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12399.85 ms /    66 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40055.28 ms /   104 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2917.04 ms /    52 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38254.43 ms /   100 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    39 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30622.73 ms /    91 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38324.05 ms /   102 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37891.69 ms /   103 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Location': [('ex:eventcatname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:calendarclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'), ('ex:start_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'), ('ex:hasCategory', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')], 'ex:EventCategory': [('ex:eventcatname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:locationclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Location\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Location\" .''',\n",
        "\"ex:EventCategory\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event Category\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_2, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e71b0b7-413f-4fae-8453-f17ba1ac3850",
      "metadata": {
        "id": "9e71b0b7-413f-4fae-8453-f17ba1ac3850",
        "outputId": "a2d1583c-a9f3-44e0-80e9-263027d5dcee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 20 prefix-match hit, remaining 119 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   119 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42685.10 ms /   168 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15231.50 ms /    66 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39855.13 ms /   106 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38159.79 ms /   105 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14165.89 ms /    69 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8505.19 ms /    64 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5790.04 ms /    58 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    47 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   36540.14 ms /   101 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   22238.34 ms /    82 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27466.59 ms /    85 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37611.19 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38586.48 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30978.15 ms /    93 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40502.82 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39543.51 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38725.24 ms /   101 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10315.25 ms /    63 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11987.21 ms /    66 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9506.22 ms /   102 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11048.17 ms /    61 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10123.30 ms /    66 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    48 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37313.09 ms /   104 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3415.94 ms /    55 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38637.18 ms /   106 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5327.46 ms /    58 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3186.11 ms /    55 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   29283.16 ms /    92 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6766.72 ms /    56 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39339.77 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10724.11 ms /    64 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39451.59 ms /   104 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9897.84 ms /    60 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3018.36 ms /    52 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39446.43 ms /   101 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21277.22 ms /    78 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39000.36 ms /   103 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14109.47 ms /   108 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38311.48 ms /    99 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5630.06 ms /    60 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38552.17 ms /   105 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37462.42 ms /   103 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21488.53 ms /    82 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21418.14 ms /    80 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39608.78 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13651.70 ms /    69 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12025.07 ms /    63 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5524.10 ms /    57 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40279.14 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   29609.26 ms /    90 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38292.04 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16790.01 ms /    70 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10185.36 ms /    62 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38644.81 ms /   102 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38312.93 ms /   103 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Event': [('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:eventimage_url', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'), ('ex:eventname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:address', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'), ('ex:eventstate', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .')], 'ex:Calendar': [('ex:end_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:Location': [('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:calendarclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'), ('ex:locationclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'), ('ex:address', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "\"ex:Location\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Location\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_3, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf58d5a-db9b-44bc-b656-206b8d0aafef",
      "metadata": {
        "id": "ecf58d5a-db9b-44bc-b656-206b8d0aafef",
        "outputId": "2c5d8276-001d-4ac8-8a31-b30d01483f2b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 43 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   33209.57 ms /   134 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39200.86 ms /    99 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39396.19 ms /   106 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39727.79 ms /   105 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39193.56 ms /   103 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10302.24 ms /    67 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10646.25 ms /    65 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38256.46 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3051.75 ms /    56 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5123.50 ms /    54 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38374.86 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17166.05 ms /    73 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12807.16 ms /    68 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10098.93 ms /    61 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38472.71 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38988.34 ms /   101 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39878.11 ms /   102 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39782.39 ms /   103 tokens\n",
            "Llama.generate: 43 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   31334.82 ms /   131 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38785.58 ms /    99 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3208.44 ms /    58 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38627.36 ms /   105 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38558.10 ms /   103 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   23100.25 ms /    84 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39079.71 ms /   104 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40127.25 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2993.57 ms /    56 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39580.29 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39964.97 ms /   103 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18221.16 ms /    74 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5451.35 ms /    58 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37934.33 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39055.50 ms /   100 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12389.11 ms /    65 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12534.48 ms /    66 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5354.82 ms /    57 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Event': [('ex:eventat', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'), ('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:locationclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'), ('ex:eventstate', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:Calendar': [('ex:eventon', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:start_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'), ('ex:hasCategory', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_3, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4c635a0-34b8-42a5-8393-fbfc1e216ca6",
      "metadata": {
        "id": "f4c635a0-34b8-42a5-8393-fbfc1e216ca6",
        "outputId": "197df655-fae0-4acc-e298-1ffeae2c3d77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 20 prefix-match hit, remaining 113 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   113 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14430.09 ms /   124 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39135.15 ms /    99 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40428.02 ms /   106 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5402.82 ms /    59 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   31958.73 ms /    92 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39716.97 ms /   106 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3361.48 ms /    56 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11221.70 ms /    65 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9992.53 ms /    64 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38123.77 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38951.95 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38691.90 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3261.68 ms /    56 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39692.00 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13694.76 ms /    65 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19515.11 ms /    74 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40313.21 ms /   102 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39120.82 ms /   103 tokens\n",
            "Llama.generate: 37 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10742.75 ms /   103 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38932.22 ms /    99 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12846.32 ms /    70 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16781.50 ms /    75 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    30 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24076.84 ms /    84 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39305.12 ms /   106 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27848.75 ms /    89 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5274.10 ms /    57 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21837.98 ms /    81 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39264.54 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   23443.84 ms /    81 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39164.17 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3294.62 ms /    56 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10558.53 ms /    61 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13395.98 ms /    65 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2808.81 ms /    53 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38528.93 ms /   102 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39304.07 ms /   103 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Event': [('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:address', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:Calendar': [('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:end_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_4, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d8d6fbb-44b3-4a64-8ba1-5a34634a0046",
      "metadata": {
        "id": "1d8d6fbb-44b3-4a64-8ba1-5a34634a0046",
        "outputId": "f59ac045-5277-46f1-e60a-30656fb41a32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 37 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7148.98 ms /    99 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15678.38 ms /    67 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2988.79 ms /    58 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15580.18 ms /    73 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12015.98 ms /    66 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38868.48 ms /   106 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3256.61 ms /    56 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39219.55 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10018.04 ms /    64 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39791.75 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20677.75 ms /    77 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14974.58 ms /    70 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12995.68 ms /    68 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38693.78 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38594.86 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8270.06 ms /    59 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39001.34 ms /   102 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38227.88 ms /   103 tokens\n",
            "Llama.generate: 37 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11713.11 ms /   105 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2790.19 ms /    51 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13159.45 ms /    70 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    45 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   36513.46 ms /   101 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39585.04 ms /   103 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39742.00 ms /   106 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3337.27 ms /    56 tokens\n",
            "Llama.generate: 83 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39412.42 ms /   103 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3305.21 ms /    56 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12760.56 ms /    64 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3188.93 ms /    55 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3146.03 ms /    55 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    36 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   29955.38 ms /    91 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7478.99 ms /    57 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38132.37 ms /   100 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38368.17 ms /   101 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30546.11 ms /    91 tokens\n",
            "Llama.generate: 82 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    46 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   36779.29 ms /   100 tokens\n",
            "Llama.generate: 37 prefix-match hit, remaining 99 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    99 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5443.21 ms /   100 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39768.96 ms /    99 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15463.09 ms /    73 tokens\n",
            "Llama.generate: 87 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   26172.15 ms /    87 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3269.27 ms /    55 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38661.39 ms /   106 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38764.20 ms /   104 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38850.40 ms /   103 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38843.15 ms /   104 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2932.88 ms /    52 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8339.23 ms /    61 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9883.87 ms /    63 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17406.32 ms /    74 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24888.80 ms /    80 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39597.58 ms /   100 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16736.37 ms /    70 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11512.28 ms /    64 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39840.17 ms /   103 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Event': [('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:locationclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:Calendar': [('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:address', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:EventCategory': [('ex:eventimage_url', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'), ('ex:calendarclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'), ('ex:eventstate', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'), ('ex:hasCategory', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "\"ex:EventCategory\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event Category\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_4, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25d49007-fdd9-4797-a873-7377c9b8b133",
      "metadata": {
        "id": "25d49007-fdd9-4797-a873-7377c9b8b133",
        "outputId": "fef50b68-6af2-44fd-8da6-25b51642137d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 17 prefix-match hit, remaining 111 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   111 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41982.31 ms /   160 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38254.96 ms /    99 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39180.09 ms /   106 tokens\n",
            "Llama.generate: 79 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10588.76 ms /    66 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39542.65 ms /   103 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   22288.31 ms /    82 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   26595.34 ms /    87 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39145.32 ms /   103 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13742.50 ms /    69 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12114.47 ms /    63 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14236.05 ms /    69 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7852.28 ms /    60 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37897.94 ms /   104 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8185.76 ms /    58 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7976.98 ms /    58 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10150.65 ms /    62 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38790.88 ms /   102 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39670.69 ms /   103 tokens\n",
            "Llama.generate: 32 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42101.31 ms /   145 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40176.18 ms /    99 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39618.94 ms /   106 tokens\n",
            "Llama.generate: 79 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   22121.12 ms /    82 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    36 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   29155.76 ms /    90 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    47 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37646.91 ms /   104 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38728.79 ms /   104 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40066.17 ms /   103 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19732.20 ms /    77 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    48 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39131.31 ms /    99 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   22288.03 ms /    79 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12067.52 ms /    66 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   22758.51 ms /    82 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9759.80 ms /    61 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21367.81 ms /    76 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38675.61 ms /   101 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25956.06 ms /    84 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12167.06 ms /    66 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: {'ex:Event': [('ex:eventon', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'), ('ex:eventcatclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'), ('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:eventname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'), ('ex:start_time', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'), ('ex:locationclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'), ('ex:statename', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')], 'ex:State': [('ex:eventat', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'), ('ex:eventclassid', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'), ('ex:eventdescr_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'), ('ex:eventname_it', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'), ('ex:day', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'), ('ex:eventstate', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'), ('ex:hasCategory', 'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'), ('ex:statecode', 'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}\n"
          ]
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:State\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"State\" .'''\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_5, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53b6cb19-af24-4ec4-837c-b60519e38fe3",
      "metadata": {
        "id": "53b6cb19-af24-4ec4-837c-b60519e38fe3",
        "outputId": "2a40e7a2-cab5-401a-90f4-fbbf2cbf6094"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 32 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   42166.16 ms /   145 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5212.98 ms /    53 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14656.15 ms /    72 tokens\n",
            "Llama.generate: 79 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40085.52 ms /   105 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   21500.97 ms /    79 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39059.30 ms /   106 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38666.58 ms /   104 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10586.64 ms /    65 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    22 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19179.10 ms /    77 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38188.89 ms /   100 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30912.83 ms /    92 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40430.50 ms /   103 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40317.76 ms /   104 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39828.66 ms /   100 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38686.61 ms /   100 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11566.62 ms /    64 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20085.69 ms /    76 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15098.32 ms /    71 tokens\n",
            "Llama.generate: 32 prefix-match hit, remaining 96 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    96 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9281.87 ms /   102 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 50 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    50 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     6 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7162.74 ms /    56 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38760.84 ms /   106 tokens\n",
            "Llama.generate: 79 prefix-match hit, remaining 56 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    56 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11306.98 ms /    67 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    41 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   33554.31 ms /    95 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 57 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    57 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40102.22 ms /   106 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14574.95 ms /    70 tokens\n",
            "Llama.generate: 78 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40241.02 ms /   103 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38860.50 ms /   104 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5185.59 ms /    54 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38607.47 ms /   103 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    54 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12618.37 ms /    67 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 55 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    55 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38188.79 ms /   104 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38931.67 ms /   100 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39885.40 ms /   100 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 52 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    52 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39973.20 ms /   101 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   25134.63 ms /    82 tokens\n",
            "Llama.generate: 77 prefix-match hit, remaining 54 prompt tokens to eval\n"
          ]
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "relevant_classes = {\n",
        "\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "}\n",
        "\n",
        "class_properties = ask_relevant_properties(question_5, relevant_classes, property_dict, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33256ea1-b79c-4db7-8850-366d481c42b9",
      "metadata": {
        "id": "33256ea1-b79c-4db7-8850-366d481c42b9",
        "outputId": "4e8f8809-04b4-4081-c948-b6fb46c9a965"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:eventcatname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:eventimage_url',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:calendarclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'),\n",
              "    ('ex:end_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'),\n",
              "    ('ex:start_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:Calendar': [('ex:eventat',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'),\n",
              "    ('ex:eventimage_url',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:calendarclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:address',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}},\n",
              " {'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'relevant_classes': {'ex:EventCategory': 'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .'},\n",
              "  'response': {'ex:EventCategory': [('ex:eventat',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'),\n",
              "    ('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:end_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'),\n",
              "    ('ex:start_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'),\n",
              "    ('ex:eventstate',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids?\",\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .',\n",
              "   'ex:Location': 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .',\n",
              "   'ex:EventCategory': 'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventat',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'),\n",
              "    ('ex:eventon',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'),\n",
              "    ('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:calendarclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'),\n",
              "    ('ex:eventstate',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:Calendar': [('ex:eventon',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'),\n",
              "    ('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:eventimage_url',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:Location': [('ex:eventimage_url',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')],\n",
              "   'ex:EventCategory': [('ex:eventat',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .')]}},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids?\",\n",
              "  'relevant_classes': {'ex:Location': 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .',\n",
              "   'ex:EventCategory': 'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .'},\n",
              "  'response': {'ex:Location': [('ex:eventcatname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:calendarclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'),\n",
              "    ('ex:start_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')],\n",
              "   'ex:EventCategory': [('ex:eventcatname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:locationclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .')]}},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12?',\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .',\n",
              "   'ex:Location': 'rdf:type owl:Class ;\\n    rdfs:label \"Location\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:eventimage_url',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:address',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'),\n",
              "    ('ex:eventstate',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .')],\n",
              "   'ex:Calendar': [('ex:end_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:Location': [('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:calendarclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'),\n",
              "    ('ex:locationclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'),\n",
              "    ('ex:address',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .')]}},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12?',\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventat',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'),\n",
              "    ('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:locationclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'),\n",
              "    ('ex:eventstate',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:Calendar': [('ex:eventon',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:start_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}},\n",
              " {'question': 'What are the events scheduled to start at 11.30?',\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:address',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:Calendar': [('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:end_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"EndTime\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')]}},\n",
              " {'question': 'What are the events scheduled to start at 11.30?',\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .',\n",
              "   'ex:EventCategory': 'rdf:type owl:Class ;\\n    rdfs:label \"Event Category\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:locationclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:Calendar': [('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:address',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Address\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:EventCategory': [('ex:eventimage_url',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'),\n",
              "    ('ex:calendarclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'),\n",
              "    ('ex:eventstate',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .')]}},\n",
              " {'question': 'Can you give the event names and their status?',\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:State': 'rdf:type owl:Class ;\\n    rdfs:label \"State\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventon',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'),\n",
              "    ('ex:eventcatclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Classid\" .'),\n",
              "    ('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:start_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'),\n",
              "    ('ex:locationclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .'),\n",
              "    ('ex:statename',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State name\" .')],\n",
              "   'ex:State': [('ex:eventat',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event At\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:eventdescr_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Description (IT)\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:eventstate',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range ex:State ;\\n    rdfs:label \"Event State\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .'),\n",
              "    ('ex:statecode',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:State ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"State code\" .')]}},\n",
              " {'question': 'Can you give the event names and their status?',\n",
              "  'relevant_classes': {'ex:Event': 'rdf:type owl:Class ;\\n    rdfs:label \"Event\" .',\n",
              "   'ex:Calendar': 'rdf:type owl:Class ;\\n    rdfs:label \"Calendar\" .'},\n",
              "  'response': {'ex:Event': [('ex:eventon',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'),\n",
              "    ('ex:eventcatname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:start_time',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"StartTime\" .'),\n",
              "    ('ex:locationclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Location ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Location Class ID\" .')],\n",
              "   'ex:Calendar': [('ex:eventon',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Event On\" .'),\n",
              "    ('ex:eventcatname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Eventcat Name\" .'),\n",
              "    ('ex:eventclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Class ID\" .'),\n",
              "    ('ex:eventimage_url',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Image URL\" .'),\n",
              "    ('ex:eventname_it',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Event ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Event Name\" .'),\n",
              "    ('ex:calendarclassid',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:string ;\\n    rdfs:label \"Calendar Class ID\" .'),\n",
              "    ('ex:day',\n",
              "     'rdf:type owl:DatatypeProperty ;\\n    rdfs:domain ex:Calendar ;\\n    rdfs:range xsd:date ;\\n    rdfs:label \"day\" .'),\n",
              "    ('ex:hasCategory',\n",
              "     'rdf:type owl:ObjectProperty ;\\n    rdfs:domain ex:EventCategory ;\\n    rdfs:range ex:Event ;\\n    rdfs:label \"Has Category\" .')]}}]"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses_prop"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af464b9d-9e2f-466e-9d42-0ecbc0c0a1c5",
      "metadata": {
        "id": "af464b9d-9e2f-466e-9d42-0ecbc0c0a1c5"
      },
      "source": [
        "#### With m-schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2374ef7c-e880-4fbb-8008-bd2cd86a1fbb",
      "metadata": {
        "id": "2374ef7c-e880-4fbb-8008-bd2cd86a1fbb",
        "outputId": "a5b7f9a1-00a4-4c8a-b6eb-82e996e5751a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "m-schema parsed with examples included.\n"
          ]
        }
      ],
      "source": [
        "with open(\"m_schema.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "output_dir = \"m_schema_docs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "section = None\n",
        "buffer = []\n",
        "docs = []\n",
        "\n",
        "for i, line in enumerate(lines):\n",
        "    line = line.strip()\n",
        "    if not line or line.startswith(\"#\"):\n",
        "        continue\n",
        "\n",
        "    if line.startswith(\"[Classes]\"):\n",
        "        section = \"class\"\n",
        "        continue\n",
        "    elif line.startswith(\"[Relationships]\"):\n",
        "        section = \"object\"\n",
        "        continue\n",
        "    elif line.startswith(\"[Attributes]\"):\n",
        "        section = \"datatype\"\n",
        "        continue\n",
        "\n",
        "    # Check for main definition line\n",
        "    match = re.match(r\"(ex:\\w+)\\s+【(.*?)】\\s+\\((.*?)→(.*?)\\)\", line)\n",
        "    if not match:\n",
        "        match = re.match(r\"(ex:\\w+)\\s+【(.*?)】\\s+→\\s+(.*)\", line)\n",
        "\n",
        "    if match:\n",
        "        # Flush buffer if needed\n",
        "        if buffer:\n",
        "            docs.append(buffer)\n",
        "            buffer = []\n",
        "        buffer = [line]\n",
        "        continue\n",
        "\n",
        "    # Example or description continuation\n",
        "    if buffer:\n",
        "        buffer.append(line)\n",
        "\n",
        "# Add the last block\n",
        "if buffer:\n",
        "    docs.append(buffer)\n",
        "\n",
        "# --- Parsing and writing\n",
        "for doc in docs:\n",
        "    definition_line = doc[0]\n",
        "    extra_lines = doc[1:] if len(doc) > 1 else []\n",
        "\n",
        "    # Try property (Object/Datatype) format\n",
        "    match_prop = re.match(r\"(ex:\\w+)\\s+【(.*?)】\\s+\\((.*?)→(.*?)\\)\", definition_line)\n",
        "    match_class = re.match(r\"(ex:\\w+)\\s+【Class】\\s+→\\s+(.*)\", definition_line)\n",
        "\n",
        "    data = {}\n",
        "\n",
        "    if match_class:\n",
        "        uri, description = match_class.groups()\n",
        "        type_ = \"Class\"\n",
        "        label = uri.split(\":\")[1]\n",
        "        data = {\n",
        "            \"type\": \"Class\",\n",
        "            \"uri\": uri,\n",
        "            \"label\": label,\n",
        "            \"description\": description.strip()\n",
        "        }\n",
        "\n",
        "    elif match_prop:\n",
        "        uri, type_, domain, range_ = match_prop.groups()\n",
        "        label = uri.split(\":\")[1]\n",
        "        data = {\n",
        "            \"type\": type_,\n",
        "            \"uri\": uri,\n",
        "            \"label\": label,\n",
        "            \"domain\": domain.strip(),\n",
        "            \"range\": range_.strip(),\n",
        "            \"description\": f\"{type_} from {domain.strip()} to {range_.strip()}\"\n",
        "        }\n",
        "\n",
        "    # Look for example\n",
        "    for l in extra_lines:\n",
        "        example_match = re.search(r\"- Example:\\s*(.*)\", l)\n",
        "        if example_match:\n",
        "            try:\n",
        "                # Try to parse list if JSON-like\n",
        "                ex_val = example_match.group(1).strip()\n",
        "                if ex_val.startswith(\"[\"):\n",
        "                    data[\"example\"] = json.loads(ex_val)\n",
        "                else:\n",
        "                    data[\"example\"] = ex_val.strip('\"')\n",
        "            except:\n",
        "                data[\"example\"] = ex_val  # fallback raw\n",
        "\n",
        "    filename = f\"{data['type'].lower()}_{data['label']}.json\"\n",
        "    with open(os.path.join(output_dir, filename), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"m-schema parsed with examples included.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e08b502-9429-46fb-866c-548460a11826",
      "metadata": {
        "id": "8e08b502-9429-46fb-866c-548460a11826",
        "outputId": "28ed5a4c-a80c-488c-b116-4b863ffcb05e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['ex:Event 【Class】  → Represents an event'],\n",
              " ['ex:Calendar 【Class】  → Represents a calendar entry'],\n",
              " ['ex:Location 【Class】  → Represents a location'],\n",
              " ['ex:State 【Class】  → Represents the state of an event'],\n",
              " ['ex:EventCategory 【Class】  → Represents a category of an event'],\n",
              " ['ex:eventat 【ObjectProperty】 (ex:Location → ex:Event)',\n",
              "  '- \"Event is connected to Location entity. Each event must have a location\"',\n",
              "  '- Example:',\n",
              "  'ex:location ex:eventat ex:event .'],\n",
              " ['ex:eventon 【ObjectProperty】 (ex:Event → ex:Calendar)',\n",
              "  '- \"Event is connected to Calendar entity.\"',\n",
              "  '- Example:',\n",
              "  'ex:calendar ex:eventon ex:event .'],\n",
              " ['ex:eventstate 【ObjectProperty】 (ex:Event → ex:State)',\n",
              "  '- \"An event has a status/state.\"'],\n",
              " ['ex:belongsToCategory 【ObjectProperty】 (ex:Event → ex:EventCategory)',\n",
              "  '- \"An event belongs to a category.\"',\n",
              "  '- Example:',\n",
              "  'ex:event ex:belongsToCategory ex:eventcategory .'],\n",
              " ['ex:eventclassid 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"Unique identifier for an event.\"'],\n",
              " ['ex:eventname_it 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"Event name in Italian.  Each event must have a name\"'],\n",
              " ['ex:eventdescr_it 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"Event description in Italian.\"'],\n",
              " ['ex:eventimage_url 【DatatypeProperty】 (ex:Event → xsd:string)',\n",
              "  '- \"URL of the event image.\"'],\n",
              " ['ex:calendarclassid 【DatatypeProperty】 (ex:Calendar → xsd:string)',\n",
              "  '- \"Unique identifier for a calendar entry.\"'],\n",
              " ['ex:day 【DatatypeProperty】 (ex:Calendar → xsd:date)',\n",
              "  '- \"Date of the event.\"'],\n",
              " ['ex:start_time 【DatatypeProperty】 (ex:Calendar → xsd:string)',\n",
              "  '- \"Event start time. Time format must be 00:00 \"'],\n",
              " ['ex:end_time 【DatatypeProperty】 (ex:Calendar → xsd:string)',\n",
              "  '- \"Event end time. Time format must be 00:00 \"'],\n",
              " ['ex:locationclassid 【DatatypeProperty】 (ex:Location → xsd:string)',\n",
              "  '- \"Unique identifier for a location.\"'],\n",
              " ['ex:address 【DatatypeProperty】 (ex:Location → xsd:string)',\n",
              "  '- \"Address of the location.\"'],\n",
              " ['ex:statecode 【DatatypeProperty】 (ex:State → xsd:string)',\n",
              "  '- \"Code representing the state of an event.\"'],\n",
              " ['ex:statename 【DatatypeProperty】 (ex:State → xsd:string)',\n",
              "  '- \"Name of the event state.\"',\n",
              "  '- Example:  [\"eliminato\", \"attivo\"]'],\n",
              " ['ex:eventcatclassid 【DatatypeProperty】 (ex:EventCategory → xsd:string)',\n",
              "  '- \"Unique identifier for an event category.\"'],\n",
              " ['ex:eventcatname_it 【DatatypeProperty】 (ex:EventCategory → xsd:string)',\n",
              "  '- \"Category name in Italian.\"',\n",
              "  '- Example: [\"Anniversari e Commemorazioni\",\"Arte e Cultura\",\"Conferenze\",\"Incontri Convegni Congressi\",\"Mostre\",\"Rassegna\",\"Solidarietà\",',\n",
              "  '\"Visite guidate\",\"Attività per bambini\",\"Campi estivi ragazzi\",\"Concerti\",\"Feste\",\"Festival\",\"Fiere Mercati e Sagre\",\"Manifestazioni sportive\",',\n",
              "  '\"Spettacoli\",\"Spettacoli extra lirica in Arena\",\"Turismo\",\"Altro\"]']]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d3c0c98-1ac0-4b0d-b562-3a74a0d67428",
      "metadata": {
        "id": "0d3c0c98-1ac0-4b0d-b562-3a74a0d67428"
      },
      "outputs": [],
      "source": [
        "class_doc = [\n",
        "    ['ex:Event 【Class】 → Represents an event'],\n",
        "    ['ex:Calendar 【Class】 → Represents when the event occurs'],\n",
        "    ['ex:Location 【Class】 → Represents a location'],\n",
        "    ['ex:State 【Class】 → Represents the state of an event'],\n",
        "    ['ex:EventCategory 【Class】 → Represents a category of an event']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79a4119e-f4c4-4dfd-bcba-1c4d39d6f4bc",
      "metadata": {
        "id": "79a4119e-f4c4-4dfd-bcba-1c4d39d6f4bc"
      },
      "outputs": [],
      "source": [
        "class_doc = [\n",
        "    ['ex:Event (Class) → Represents an event'],\n",
        "    ['ex:Calendar (Class) → Represents when the event occurs'],\n",
        "    ['ex:Location (Class) → Represents a location'],\n",
        "    ['ex:State (Class) → Represents the state of an event'],\n",
        "    ['ex:EventCategory (Class) → Represents a category of an event']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59b098ad-fcdb-4ed6-b155-77049d8b8ef9",
      "metadata": {
        "id": "59b098ad-fcdb-4ed6-b155-77049d8b8ef9"
      },
      "outputs": [],
      "source": [
        "class_dict = {'ex:Event (Class)' : 'Represents an event',\n",
        "    'ex:Calendar (Class)' : 'Represents when the event occurs',\n",
        "    'ex:Location (Class)' : 'Represents a location',\n",
        "    'ex:State (Class)' : 'Represents the state of an event',\n",
        "    'ex:EventCategory (Class)' : 'Represents a category of an event'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b773be84-5246-436e-8e25-30487b16c7ef",
      "metadata": {
        "id": "b773be84-5246-436e-8e25-30487b16c7ef",
        "outputId": "b4f57691-ef0c-4c8e-868d-52bea195748d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ex:Event (Class)': 'Represents an event',\n",
              " 'ex:Calendar (Class)': 'Represents when the event occurs',\n",
              " 'ex:Location (Class)': 'Represents a location',\n",
              " 'ex:State (Class)': 'Represents the state of an event',\n",
              " 'ex:EventCategory (Class)': 'Represents a category of an event'}"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63b6deac-0764-400a-96a6-fcffc6f3a6d2",
      "metadata": {
        "id": "63b6deac-0764-400a-96a6-fcffc6f3a6d2"
      },
      "outputs": [],
      "source": [
        "relevant_classes = []\n",
        "questions_responses = []\n",
        "\n",
        "def ask_relevant_classes(question, class_doc, llm):\n",
        "\n",
        "    relevant_classes = []\n",
        "\n",
        "    for doc in class_dict.items():\n",
        "            prompt = f\"\"\"You are a SPARQL expert. Given the user question: \"{question}\" Does this class {doc} seem relevant for answering the user's question? Reply with only YES or NO \"\"\"\n",
        "            response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "            print(response)\n",
        "\n",
        "            answer = response.strip().upper()\n",
        "            #answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "            if \"YES\" in answer:\n",
        "               relevant_classes.append(doc)\n",
        "\n",
        "    questions_responses.append({\"question\": question,\"response\": relevant_classes})\n",
        "\n",
        "    return relevant_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0e5bd7a-2dd4-43a0-a8e6-d4cd4d6ec5e2",
      "metadata": {
        "id": "f0e5bd7a-2dd4-43a0-a8e6-d4cd4d6ec5e2",
        "outputId": "e8521ad1-cb32-4072-e049-554670c4b6d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 43 prefix-match hit, remaining 29 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    29 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3434.96 ms /    31 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 32 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18231.48 ms /    55 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 30 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Hinweis: In this context, 'ex' refers to a SPARQL prefix.\n",
            "👀\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    38 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   31486.58 ms /    68 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 33 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "---\n",
            "\n",
            "Please answer the question with a simple \"YES\" or \"NO\". If you would like to provide further clarification or details, please feel free to do so.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    33 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    28 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   24120.68 ms /    61 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 34 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " If yes, please provide a brief justification for why you think this class is relevant.  If no, please explain why not.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4154.77 ms /    37 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "NO\n",
            "Relevant classes: [('ex:Location (Class)', 'Represents a location'), ('ex:State (Class)', 'Represents the state of an event')]\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_1, class_doc, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c632b12-b345-48fe-84e5-41d3776aa71b",
      "metadata": {
        "id": "4c632b12-b345-48fe-84e5-41d3776aa71b",
        "outputId": "f76f51fb-aad5-4597-ec8b-9f5e4ba8e13c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 39 prefix-match hit, remaining 29 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    29 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39871.74 ms /    78 tokens\n",
            "Llama.generate: 38 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     3 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4195.07 ms /    35 tokens\n",
            "Llama.generate: 38 prefix-match hit, remaining 30 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    30 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16699.78 ms /    48 tokens\n",
            "Llama.generate: 38 prefix-match hit, remaining 33 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    33 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   41814.78 ms /    82 tokens\n",
            "Llama.generate: 38 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    35 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30524.66 ms /    69 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [('ex:State (Class)', 'Represents the state of an event')]\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_2, class_doc, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b742b8fa-9e64-4d00-a233-cb910cd370e0",
      "metadata": {
        "id": "b742b8fa-9e64-4d00-a233-cb910cd370e0",
        "outputId": "d83035c4-b840-43b6-f93f-8a6c26239f05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 53 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    53 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    26 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   22830.04 ms /    79 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 31 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    31 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27155.70 ms /    63 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 29 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    29 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3322.92 ms /    31 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3406.64 ms /    34 tokens\n",
            "Llama.generate: 42 prefix-match hit, remaining 33 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    33 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40890.74 ms /    82 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [['ex:EventCategory (Class) → Represents a category of an event']]\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_3, class_doc, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e571d52-6507-4665-9826-c8aaa4d3f1f5",
      "metadata": {
        "id": "9e571d52-6507-4665-9826-c8aaa4d3f1f5",
        "outputId": "5fea466c-7c1d-4bf0-cc4d-f7e717ffe957"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 18 prefix-match hit, remaining 47 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    47 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     2 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    4855.30 ms /    49 tokens\n",
            "Llama.generate: 36 prefix-match hit, remaining 31 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    31 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   47581.30 ms /    80 tokens\n",
            "Llama.generate: 36 prefix-match hit, remaining 29 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    29 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    27 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27572.17 ms /    56 tokens\n",
            "Llama.generate: 36 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19711.99 ms /    50 tokens\n",
            "Llama.generate: 36 prefix-match hit, remaining 33 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    33 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9309.84 ms /    40 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [['ex:Calendar (Class) → Represents when the event occurs'], ['ex:State (Class) → Represents the state of an event']]\n"
          ]
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_4, class_doc, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697ba9cc-53eb-4fd0-a0ea-7f0ff5ff3311",
      "metadata": {
        "id": "697ba9cc-53eb-4fd0-a0ea-7f0ff5ff3311",
        "outputId": "580c3782-19ab-40e4-fedf-94eed0347e5a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 32 prefix-match hit, remaining 28 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    28 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   44649.26 ms /    77 tokens\n",
            "Llama.generate: 31 prefix-match hit, remaining 31 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    31 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16721.82 ms /    49 tokens\n",
            "Llama.generate: 31 prefix-match hit, remaining 29 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    29 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     8 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9045.15 ms /    37 tokens\n",
            "Llama.generate: 31 prefix-match hit, remaining 32 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    32 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    29 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   27432.87 ms /    61 tokens\n",
            "Llama.generate: 31 prefix-match hit, remaining 33 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    33 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   12452.48 ms /    45 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant classes: [['ex:Location (Class) → Represents a location'], ['ex:State (Class) → Represents the state of an event']]\n"
          ]
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "relevant_classes = ask_relevant_classes(question_5, class_doc, llm)\n",
        "print(f\"Relevant classes: {relevant_classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab3efa44-91fd-4137-8d37-14f8ace94c6f",
      "metadata": {
        "id": "ab3efa44-91fd-4137-8d37-14f8ace94c6f",
        "outputId": "4e1c8a04-83b9-4d4d-fcc5-2f5f3513773f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'question': 'What are the names of the events happening on 2015-12-12?',\n",
              "  'response': [['ex:Calendar 【Class】 → Represents when the event occurs']]},\n",
              " {'question': \"What are the names and addresses of the events belong to 'Kids' category?\",\n",
              "  'response': [['ex:Event 【Class】 → Represents an event'],\n",
              "   ['ex:EventCategory 【Class】 → Represents a category of an event']]},\n",
              " {'question': 'What are the locations of the events happen on 2015-12-12?',\n",
              "  'response': [['ex:State 【Class】 → Represents the state of an event']]},\n",
              " {'question': 'What are the events scheduled to start at 11.30?',\n",
              "  'response': [['ex:Location 【Class】 → Represents a location'],\n",
              "   ['ex:State 【Class】 → Represents the state of an event'],\n",
              "   ['ex:EventCategory 【Class】 → Represents a category of an event']]},\n",
              " {'question': 'Can you give the event names and their status?',\n",
              "  'response': [['ex:Location 【Class】 → Represents a location']]}]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "questions_responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c7a0782-9233-423e-b6f8-51820c39b174",
      "metadata": {
        "id": "9c7a0782-9233-423e-b6f8-51820c39b174"
      },
      "outputs": [],
      "source": [
        "property_doc = [\n",
        "    ['ex:eventat (ObjectProperty) (ex:Location → ex:Event)',\n",
        "     '- \"Event is connected to Location entity. Each event must have a location\"'],\n",
        "\n",
        "    ['ex:eventon (ObjectProperty) (ex:Event → ex:Calendar)',\n",
        "     '- \"Event is connected to Calendar entity.\"'],\n",
        "\n",
        "    ['ex:eventstate (ObjectProperty) (ex:Event → ex:State)',\n",
        "     '- \"An event has a status/state.\"'],\n",
        "\n",
        "    ['ex:belongsToCategory (ObjectProperty) (ex:Event → ex:EventCategory)',\n",
        "     '- \"An event belongs to a category.\"'],\n",
        "\n",
        "    ['ex:eventclassid (DatatypeProperty) (ex:Event → xsd:string)',\n",
        "     '- \"Unique identifier for an event.\"'],\n",
        "\n",
        "    ['ex:eventname_it (DatatypeProperty) (ex:Event → xsd:string)',\n",
        "     '- \"Event name in Italian. Each event must have a name\"'],\n",
        "\n",
        "    ['ex:eventdescr_it (DatatypeProperty) (ex:Event → xsd:string)',\n",
        "     '- \"Event description in Italian.\"'],\n",
        "\n",
        "    ['ex:eventimage_url (DatatypeProperty) (ex:Event → xsd:string)',\n",
        "     '- \"URL of the event image.\"'],\n",
        "\n",
        "    ['ex:calendarclassid (DatatypeProperty) (ex:Calendar → xsd:string)',\n",
        "     '- \"Unique identifier for a calendar entry.\"'],\n",
        "\n",
        "    ['ex:day (DatatypeProperty) (ex:Calendar → xsd:date)',\n",
        "     '- \"Date of the event.\"'],\n",
        "\n",
        "    ['ex:start_time (DatatypeProperty) (ex:Calendar → xsd:string)',\n",
        "     '- \"Event start time. Time format must be 00:00 \"'],\n",
        "\n",
        "    ['ex:end_time (DatatypeProperty) (ex:Calendar → xsd:string)',\n",
        "     '- \"Event end time. Time format must be 00:00 \"'],\n",
        "\n",
        "    ['ex:locationclassid (DatatypeProperty) (ex:Location → xsd:string)',\n",
        "     '- \"Unique identifier for a location.\"'],\n",
        "\n",
        "    ['ex:address (DatatypeProperty) (ex:Location → xsd:string)',\n",
        "     '- \"Address of the location.\"'],\n",
        "\n",
        "    ['ex:statecode (DatatypeProperty) (ex:State → xsd:string)',\n",
        "     '- \"Code representing the state of an event.\"'],\n",
        "\n",
        "    ['ex:statename (DatatypeProperty) (ex:State → xsd:string)',\n",
        "     '- \"Name of the event state.\"',\n",
        "     '- Example:  [\"eliminato\", \"attivo\"]'],\n",
        "\n",
        "    ['ex:eventcatclassid (DatatypeProperty) (ex:EventCategory → xsd:string)',\n",
        "     '- \"Unique identifier for an event category.\"'],\n",
        "\n",
        "    ['ex:eventcatname_it (DatatypeProperty) (ex:EventCategory → xsd:string)',\n",
        "     '- \"Category name in Italian.\"',\n",
        "     '- Example: [\"Anniversari e Commemorazioni\",\"Arte e Cultura\",\"Conferenze\",\"Incontri Convegni Congressi\",\"Mostre\",\"Rassegna\",\"Solidarietà\",',\n",
        "     '\"Visite guidate\",\"Attività per bambini\",\"Campi estivi ragazzi\",\"Concerti\",\"Feste\",\"Festival\",\"Fiere Mercati e Sagre\",\"Manifestazioni sportive\",',\n",
        "     '\"Spettacoli\",\"Spettacoli extra lirica in Arena\",\"Turismo\",\"Altro\"]']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aef2b684-8377-45d2-bf0c-cff5e82eac21",
      "metadata": {
        "id": "aef2b684-8377-45d2-bf0c-cff5e82eac21"
      },
      "outputs": [],
      "source": [
        "def dtt_traverse(graph, start_class, max_depth=2):\n",
        "    from collections import deque\n",
        "    visited = set()\n",
        "    queue = deque([(start_class, 0)])\n",
        "    collected_properties = []\n",
        "\n",
        "    while queue:\n",
        "        current_node, depth = queue.popleft()\n",
        "        if depth > max_depth or current_node in visited:\n",
        "            continue\n",
        "        visited.add(current_node)\n",
        "\n",
        "        for _, neighbor, key, data in graph.out_edges(current_node, keys=True, data=True):\n",
        "            property_info = {\n",
        "                \"from\": current_node,\n",
        "                \"to\": neighbor,\n",
        "                \"label\": data.get(\"label\", \"\"),\n",
        "                \"type\": data.get(\"type\", \"\"),\n",
        "            }\n",
        "            collected_properties.append(property_info)\n",
        "            queue.append((neighbor, depth + 1))\n",
        "\n",
        "    return collected_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9e2cd45-0bf1-4ed7-bc5f-74c68de94412",
      "metadata": {
        "id": "e9e2cd45-0bf1-4ed7-bc5f-74c68de94412"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12684872-2eba-4d10-9dd4-cc81f14344ca",
      "metadata": {
        "id": "12684872-2eba-4d10-9dd4-cc81f14344ca"
      },
      "outputs": [],
      "source": [
        "label_map = {\n",
        "    \"Event Name\": \"eventname_it\",\n",
        "    \"Event Description (IT)\": \"eventdescr_it\",\n",
        "    \"Event Image URL\": \"eventimage_url\",\n",
        "    \"Event Class ID\": \"eventclassid\",\n",
        "    \"Calendar Class ID\": \"calendarclassid\",\n",
        "    \"StartTime\": \"start_time\",\n",
        "    \"EndTime\": \"end_time\",\n",
        "    \"Location Class ID\": \"locationclassid\",\n",
        "    \"Address\": \"address\",\n",
        "    \"Event State\": \"eventstate\",\n",
        "    \"State name\": \"statename\",\n",
        "    \"State code\": \"statecode\",\n",
        "    \"Event On\": \"eventon\",\n",
        "    \"Event At\": \"eventat\",\n",
        "    \"Category\": \"belongstoCategory\",\n",
        "    \"Event Category Class ID\": \"eventcatclassid\",\n",
        "    \"Event Category Name (IT)\": \"eventcatname_it\",\n",
        "    \"day\": \"day\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "705face3-d1d8-4443-a586-13d4ef1c33f7",
      "metadata": {
        "id": "705face3-d1d8-4443-a586-13d4ef1c33f7"
      },
      "outputs": [],
      "source": [
        "def prepare_property_prompt(question, relevant_classes, all_collected_props, property_doc, class_doc):\n",
        "    # Convert relevant_classes to ex:Name form\n",
        "    relevant_class_names = {cls.split(\"/\")[-1] for cls in relevant_classes}\n",
        "\n",
        "    # Filter and format matching class definitions\n",
        "    class_doc_formatted = []\n",
        "    for entry in class_doc:\n",
        "        class_uri = entry[0].split()[0].replace(\"ex:\", \"\")\n",
        "        if class_uri in relevant_class_names:\n",
        "            class_doc_formatted.append(entry)\n",
        "    print(class_doc_formatted)\n",
        "    # Match and format properties from property_doc using collected labels\n",
        "    collected_labels = {prop[2] for prop in all_collected_props}\n",
        "    print(collected_labels)\n",
        "\n",
        "    mapped_labels = {label_map.get(label, label).lower() for label in collected_labels}\n",
        "    print(mapped_labels)\n",
        "    property_doc_formatted = []\n",
        "\n",
        "    for entry in property_doc:\n",
        "        if not isinstance(entry, list) or len(entry) < 2:\n",
        "            continue\n",
        "        prop_label = entry[0].split()[0].replace(\"ex:\", \"\").strip().lower()\n",
        "        print(prop_label)\n",
        "        if prop_label in mapped_labels:\n",
        "            property_doc_formatted.append(entry)\n",
        "    print(property_doc_formatted)\n",
        "\n",
        "    # Build the prompt\n",
        "    prompt = \"You are a semantic web expert.\\n\\n\"\n",
        "    prompt += \"The following are the relevant ontology classes:\\n\\n\"\n",
        "    for cls in class_doc_formatted:\n",
        "        prompt += f\"{cls[0]}\\n\"\n",
        "\n",
        "    prompt += \"\\nThe following are the ontology properties:\\n\\n\"\n",
        "    for prop in property_doc_formatted:\n",
        "        for line in prop:\n",
        "            prompt += f\"{line}\\n\"\n",
        "        prompt += \"\\n\"\n",
        "\n",
        "    prompt += (\n",
        "        f\"Based on these class and property definitions, \"\n",
        "        f\"which properties are relevant for answering the question:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        f\"List only the property labels, separated by commas, without explanation.\"\n",
        "    )\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4eee845d-1108-4ca0-8dad-767b613e9b66",
      "metadata": {
        "id": "4eee845d-1108-4ca0-8dad-767b613e9b66"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e344fac3-e1c0-4c37-ae84-ae520d4e40de",
      "metadata": {
        "id": "e344fac3-e1c0-4c37-ae84-ae520d4e40de",
        "outputId": "3eae19e8-0855-4875-fb5e-4b0b420451ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['ex:Event (Class) → Represents an event'], ['ex:Calendar (Class) → Represents when the event occurs']]\n",
            "{'Event Image URL', 'Calendar Class ID', 'Event State', 'State name', 'State code', 'EndTime', 'Event Description (IT)', 'Event Name', 'day', 'Event Class ID', 'Event On', 'StartTime'}\n",
            "{'calendarclassid', 'eventname_it', 'eventimage_url', 'statecode', 'statename', 'eventon', 'eventclassid', 'eventdescr_it', 'eventstate', 'start_time', 'day', 'end_time'}\n",
            "eventat\n",
            "eventon\n",
            "eventstate\n",
            "belongstocategory\n",
            "eventclassid\n",
            "eventname_it\n",
            "eventdescr_it\n",
            "eventimage_url\n",
            "calendarclassid\n",
            "day\n",
            "start_time\n",
            "end_time\n",
            "locationclassid\n",
            "address\n",
            "statecode\n",
            "statename\n",
            "eventcatclassid\n",
            "eventcatname_it\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 63 prefix-match hit, remaining 465 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   466 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    37 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   57339.26 ms /   503 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar'] | Relevant Properties: {'id': 'cmpl-a8cb0c1e-7107-410e-b628-8bef1e5d075e', 'object': 'text_completion', 'created': 1748939972, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\n\\nAnswer:\\nex:eventon, ex:day, ex:start_time, ex:end_time, ex:statecode, ex:statename', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 528, 'completion_tokens': 37, 'total_tokens': 565}}\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_1, relevant_classes, all_collected_props,property_doc, class_doc )\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34943d6c-2211-4436-8818-5b109b6d2af8",
      "metadata": {
        "id": "34943d6c-2211-4436-8818-5b109b6d2af8"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Location\", \"http://example.org/EventCategory\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31f6329e-8c77-4d0a-b0fd-561846f8a0dd",
      "metadata": {
        "id": "31f6329e-8c77-4d0a-b0fd-561846f8a0dd"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c2b78b-cd86-45dc-8e73-70a00a6d04d0",
      "metadata": {
        "id": "82c2b78b-cd86-45dc-8e73-70a00a6d04d0",
        "outputId": "7b4d29e4-8637-432e-8975-e0bdc573be1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['ex:Event (Class) → Represents an event'], ['ex:Location (Class) → Represents a location'], ['ex:EventCategory (Class) → Represents a category of an event']]\n",
            "{'Event Image URL', 'Location Class ID', 'Eventcat Classid', 'Event State', 'Event At', 'State name', 'Eventcat Name', 'State code', 'Event Description (IT)', 'Event Name', 'Event Class ID', 'Address', 'Has Category'}\n",
            "{'eventcat name', 'eventat', 'eventname_it', 'eventimage_url', 'statename', 'statecode', 'eventclassid', 'locationclassid', 'eventdescr_it', 'eventstate', 'has category', 'address', 'eventcat classid'}\n",
            "eventat\n",
            "eventon\n",
            "eventstate\n",
            "belongstocategory\n",
            "eventclassid\n",
            "eventname_it\n",
            "eventdescr_it\n",
            "eventimage_url\n",
            "calendarclassid\n",
            "day\n",
            "start_time\n",
            "end_time\n",
            "locationclassid\n",
            "address\n",
            "statecode\n",
            "statename\n",
            "eventcatclassid\n",
            "eventcatname_it\n",
            "[['ex:eventat (ObjectProperty) (ex:Location → ex:Event)', '- \"Event is connected to Location entity. Each event must have a location\"'], ['ex:eventstate (ObjectProperty) (ex:Event → ex:State)', '- \"An event has a status/state.\"'], ['ex:eventclassid (DatatypeProperty) (ex:Event → xsd:string)', '- \"Unique identifier for an event.\"'], ['ex:eventname_it (DatatypeProperty) (ex:Event → xsd:string)', '- \"Event name in Italian. Each event must have a name\"'], ['ex:eventdescr_it (DatatypeProperty) (ex:Event → xsd:string)', '- \"Event description in Italian.\"'], ['ex:eventimage_url (DatatypeProperty) (ex:Event → xsd:string)', '- \"URL of the event image.\"'], ['ex:locationclassid (DatatypeProperty) (ex:Location → xsd:string)', '- \"Unique identifier for a location.\"'], ['ex:address (DatatypeProperty) (ex:Location → xsd:string)', '- \"Address of the location.\"'], ['ex:statecode (DatatypeProperty) (ex:State → xsd:string)', '- \"Code representing the state of an event.\"'], ['ex:statename (DatatypeProperty) (ex:State → xsd:string)', '- \"Name of the event state.\"', '- Example:  [\"eliminato\", \"attivo\"]']]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 36 prefix-match hit, remaining 429 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   429 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   37859.68 ms /   446 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Location', 'http://example.org/EventCategory'] | Relevant Properties: {'id': 'cmpl-1b32cc0d-50b3-4e0f-a36c-0afebe51f464', 'object': 'text_completion', 'created': 1748940112, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\nex:eventname_it, address, eventclassid, eventstate', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 465, 'completion_tokens': 17, 'total_tokens': 482}}\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_2, relevant_classes, all_collected_props,property_doc, class_doc )\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c210fb35-d581-4af2-93cc-a846e8fab7fd",
      "metadata": {
        "id": "c210fb35-d581-4af2-93cc-a846e8fab7fd"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Location\", \"http://example.org/Calendar\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89bcb95b-72a8-4e53-b067-8546e333be84",
      "metadata": {
        "id": "89bcb95b-72a8-4e53-b067-8546e333be84"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "815dd0fd-4193-4e27-87b5-824bf99b05eb",
      "metadata": {
        "id": "815dd0fd-4193-4e27-87b5-824bf99b05eb",
        "outputId": "a6c93fa4-0deb-4eef-b2c0-e34f19cfd01e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['ex:Event (Class) → Represents an event'], ['ex:Calendar (Class) → Represents when the event occurs'], ['ex:Location (Class) → Represents a location']]\n",
            "{'Event Image URL', 'Location Class ID', 'Calendar Class ID', 'Event State', 'Event At', 'State name', 'State code', 'EndTime', 'Event Description (IT)', 'Event Name', 'day', 'Event Class ID', 'Event On', 'Address', 'StartTime'}\n",
            "{'eventat', 'calendarclassid', 'eventname_it', 'eventimage_url', 'statename', 'statecode', 'eventon', 'eventclassid', 'locationclassid', 'eventdescr_it', 'eventstate', 'address', 'start_time', 'day', 'end_time'}\n",
            "eventat\n",
            "eventon\n",
            "eventstate\n",
            "belongstocategory\n",
            "eventclassid\n",
            "eventname_it\n",
            "eventdescr_it\n",
            "eventimage_url\n",
            "calendarclassid\n",
            "day\n",
            "start_time\n",
            "end_time\n",
            "locationclassid\n",
            "address\n",
            "statecode\n",
            "statename\n",
            "eventcatclassid\n",
            "eventcatname_it\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 636 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    20 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   16689.38 ms /    21 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Location', 'http://example.org/Calendar'] | Relevant Properties: {'id': 'cmpl-ba84cf6d-2a47-4cb5-b8ed-71661ff0830e', 'object': 'text_completion', 'created': 1748869689, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': ' For example: \"eventat, eventon, eventstate, locationclassid, address\"', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 637, 'completion_tokens': 19, 'total_tokens': 656}}\n"
          ]
        }
      ],
      "source": [
        "question_3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_3, relevant_classes, all_collected_props,property_doc, class_doc )\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6f500a-c6a1-48b1-b74b-2d59a2d6f58b",
      "metadata": {
        "id": "1a6f500a-c6a1-48b1-b74b-2d59a2d6f58b"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20669301-7a28-4438-96ef-9e66afcb6992",
      "metadata": {
        "id": "20669301-7a28-4438-96ef-9e66afcb6992"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc36fa39-3082-4e9c-b9b3-7f17c42eccec",
      "metadata": {
        "id": "cc36fa39-3082-4e9c-b9b3-7f17c42eccec",
        "outputId": "222bb944-343b-4673-c7d9-5ac68d302618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['ex:Event (Class) → Represents an event'], ['ex:Calendar (Class) → Represents when the event occurs']]\n",
            "{'Event Image URL', 'Calendar Class ID', 'Event State', 'State name', 'State code', 'EndTime', 'Event Description (IT)', 'Event Name', 'day', 'Event Class ID', 'Event On', 'StartTime'}\n",
            "{'calendarclassid', 'eventname_it', 'eventimage_url', 'statecode', 'statename', 'eventon', 'eventclassid', 'eventdescr_it', 'eventstate', 'start_time', 'day', 'end_time'}\n",
            "eventat\n",
            "eventon\n",
            "eventstate\n",
            "belongstocategory\n",
            "eventclassid\n",
            "eventname_it\n",
            "eventdescr_it\n",
            "eventimage_url\n",
            "calendarclassid\n",
            "day\n",
            "start_time\n",
            "end_time\n",
            "locationclassid\n",
            "address\n",
            "statecode\n",
            "statename\n",
            "eventcatclassid\n",
            "eventcatname_it\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 49 prefix-match hit, remaining 473 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   473 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    42 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   58221.18 ms /   515 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar'] | Relevant Properties: {'id': 'cmpl-69bf18c5-6a8c-4a20-b8df-b59bb148027e', 'object': 'text_completion', 'created': 1748869869, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\nex:eventon, start_time, end_time, statecode, statenames\\n\\nNote: You can use the property labels as they are, without any additional processing or manipulation.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 522, 'completion_tokens': 42, 'total_tokens': 564}}\n"
          ]
        }
      ],
      "source": [
        "question_4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_4, relevant_classes, all_collected_props,property_doc, class_doc )\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4531ca11-3988-4cd9-b6f7-2ecf65e96108",
      "metadata": {
        "id": "4531ca11-3988-4cd9-b6f7-2ecf65e96108"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/State\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8381b3c2-0dd5-4517-8ac4-1d553b29b52a",
      "metadata": {
        "id": "8381b3c2-0dd5-4517-8ac4-1d553b29b52a"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa55e1c7-5fbf-401c-bc4a-3df53dfdae03",
      "metadata": {
        "id": "aa55e1c7-5fbf-401c-bc4a-3df53dfdae03",
        "outputId": "83d09485-257f-4367-b7d3-224674a62468"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['ex:Event (Class) → Represents an event'], ['ex:State (Class) → Represents the state of an event']]\n",
            "{'Event Image URL', 'Event State', 'State name', 'State code', 'Event Description (IT)', 'Event Name', 'Event Class ID'}\n",
            "{'eventname_it', 'eventimage_url', 'statecode', 'statename', 'eventclassid', 'eventdescr_it', 'eventstate'}\n",
            "eventat\n",
            "eventon\n",
            "eventstate\n",
            "belongstocategory\n",
            "eventclassid\n",
            "eventname_it\n",
            "eventdescr_it\n",
            "eventimage_url\n",
            "calendarclassid\n",
            "day\n",
            "start_time\n",
            "end_time\n",
            "locationclassid\n",
            "address\n",
            "statecode\n",
            "statename\n",
            "eventcatclassid\n",
            "eventcatname_it\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 36 prefix-match hit, remaining 312 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   312 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    13 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   30389.92 ms /   325 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/State'] | Relevant Properties: {'id': 'cmpl-8178376d-cb13-43b4-8996-62f1305cbf70', 'object': 'text_completion', 'created': 1748870219, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\neventname_it, eventstate, eventclassid', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 348, 'completion_tokens': 13, 'total_tokens': 361}}\n"
          ]
        }
      ],
      "source": [
        "question_5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_5, relevant_classes, all_collected_props,property_doc, class_doc )\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a2422a-71d3-402c-92a2-107308d2613f",
      "metadata": {
        "id": "91a2422a-71d3-402c-92a2-107308d2613f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "302442f5-cc5f-420d-aea7-fca7aaec3544",
      "metadata": {
        "id": "302442f5-cc5f-420d-aea7-fca7aaec3544"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "5f07d86c-28f1-4eb0-a895-3d87a6939a45",
      "metadata": {
        "id": "5f07d86c-28f1-4eb0-a895-3d87a6939a45"
      },
      "source": [
        "## use cosine similarity search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a683cca1-7efa-43fc-a1bc-9de15daa36af",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "dda5afb5dfb24efc88cc227675b60572",
            "dbe2ebc2af544f0bb88f989c30c97492",
            "6db64f4bc5094e47b0bcefcab4b8b154",
            "5ffdad0571424b34ab1bfa81af50065a",
            "00eba33d040d42d9b916ba998009f865"
          ]
        },
        "id": "a683cca1-7efa-43fc-a1bc-9de15daa36af",
        "outputId": "15afeae7-c7c4-40e1-818e-5517476c98e9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dda5afb5dfb24efc88cc227675b60572",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbe2ebc2af544f0bb88f989c30c97492",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6db64f4bc5094e47b0bcefcab4b8b154",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ffdad0571424b34ab1bfa81af50065a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "00eba33d040d42d9b916ba998009f865",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load model (use a lightweight one like 'all-MiniLM-L6-v2' for speed)\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Your question\n",
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "# Flatten your property descriptions into one string per property\n",
        "property_texts = []\n",
        "property_labels = []\n",
        "for prop in property_doc:\n",
        "    if isinstance(prop, list) and len(prop) >= 2:\n",
        "        full_text = \" \".join(prop)\n",
        "        property_texts.append(full_text)\n",
        "        property_labels.append(prop[0].split()[0].replace(\"ex:\", \"\"))\n",
        "\n",
        "# Get embeddings\n",
        "question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "property_embeddings = model.encode(property_texts, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarities\n",
        "cosine_scores = util.cos_sim(question_embedding, property_embeddings)[0]\n",
        "\n",
        "# Get top-k properties\n",
        "top_k = 5\n",
        "top_indices = cosine_scores.topk(k=top_k).indices\n",
        "\n",
        "# Get top-k property labels and descriptions\n",
        "top_properties = [property_doc[i] for i in top_indices]\n",
        "top_labels = [property_labels[i] for i in top_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b39e9b7-32f7-4d30-a5e8-1d62fdbc92d9",
      "metadata": {
        "id": "8b39e9b7-32f7-4d30-a5e8-1d62fdbc92d9",
        "outputId": "ed3ca38a-d3d3-45bf-b7ee-55a630964e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. ex:eventon (ObjectProperty) (ex:Event → ex:Calendar)\n",
            "    - \"Event is connected to Calendar entity.\"\n",
            "2. ex:eventcatname_it (DatatypeProperty) (ex:EventCategory → xsd:string)\n",
            "    - \"Category name in Italian.\"\n",
            "    - Example: [\"Anniversari e Commemorazioni\",\"Arte e Cultura\",\"Conferenze\",\"Incontri Convegni Congressi\",\"Mostre\",\"Rassegna\",\"Solidarietà\",\n",
            "    \"Visite guidate\",\"Attività per bambini\",\"Campi estivi ragazzi\",\"Concerti\",\"Feste\",\"Festival\",\"Fiere Mercati e Sagre\",\"Manifestazioni sportive\",\n",
            "    \"Spettacoli\",\"Spettacoli extra lirica in Arena\",\"Turismo\",\"Altro\"]\n",
            "3. ex:eventat (ObjectProperty) (ex:Location → ex:Event)\n",
            "    - \"Event is connected to Location entity. Each event must have a location\"\n",
            "4. ex:day (DatatypeProperty) (ex:Calendar → xsd:date)\n",
            "    - \"Date of the event.\"\n",
            "5. ex:eventstate (ObjectProperty) (ex:Event → ex:State)\n",
            "    - \"An event has a status/state.\"\n"
          ]
        }
      ],
      "source": [
        "for i, prop in enumerate(top_properties):\n",
        "    print(f\"{i+1}. {prop[0]}\")\n",
        "    for line in prop[1:]:\n",
        "        print(\"   \", line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a88ecd1-b28e-41b9-80de-40f0de479019",
      "metadata": {
        "id": "2a88ecd1-b28e-41b9-80de-40f0de479019"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "40dd2fb2-39b1-46c9-b67a-51e135ac5144",
      "metadata": {
        "id": "40dd2fb2-39b1-46c9-b67a-51e135ac5144"
      },
      "source": [
        "### Extract properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b8995afe-4c66-4293-ba97-a2ab2fc7d7d3",
      "metadata": {
        "id": "b8995afe-4c66-4293-ba97-a2ab2fc7d7d3",
        "outputId": "ca4e82ee-4809-4bc2-9a15-52690a3b0f7a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Event Name': 'eventname_it',\n",
              " 'Event Description (IT)': 'eventdescr_it',\n",
              " 'Event Image URL': 'eventimage_url',\n",
              " 'Event Class ID': 'eventclassid',\n",
              " 'Calendar Class ID': 'calendarclassid',\n",
              " 'StartTime': 'start_time',\n",
              " 'EndTime': 'end_time',\n",
              " 'Location Class ID': 'locationclassid',\n",
              " 'Address': 'address',\n",
              " 'Event State': 'eventstate',\n",
              " 'State name': 'statename',\n",
              " 'State code': 'statecode',\n",
              " 'Event On': 'eventon',\n",
              " 'Event At': 'eventat',\n",
              " 'Category': 'belongstoCategory',\n",
              " 'Event Category Class ID': 'eventcatclassid',\n",
              " 'Event Category Name (IT)': 'eventcatname_it',\n",
              " 'day': 'day'}"
            ]
          },
          "execution_count": 530,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "476607c7-bb22-43dc-9e8a-b5c01248fd82",
      "metadata": {
        "id": "476607c7-bb22-43dc-9e8a-b5c01248fd82"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def rank_relevant_properties(question, all_collected_props, property_doc, label_map, top_k=5):\n",
        "    # Load sentence transformer model\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Build a mapping: ontology label → documentation entry\n",
        "    label_to_doc = {}\n",
        "    for entry in property_doc:\n",
        "        if isinstance(entry, list) and len(entry) >= 2:\n",
        "            prop_label = entry[0].split()[0].replace(\"ex:\", \"\").strip().lower()\n",
        "            label_to_doc[prop_label] = entry\n",
        "\n",
        "    # Convert collected labels (human-readable) to ontology labels using label_map\n",
        "    collected_labels = [prop[2] for prop in all_collected_props]\n",
        "    mapped_labels = {\n",
        "        label_map.get(label, \"\").strip().lower()\n",
        "        for label in collected_labels\n",
        "        if label_map.get(label)  # only if it has a valid mapping\n",
        "    }\n",
        "\n",
        "    # Now collect matching property docs\n",
        "    matched_docs = [label_to_doc[label] for label in mapped_labels if label in label_to_doc]\n",
        "\n",
        "    if not matched_docs:\n",
        "        return []\n",
        "\n",
        "    # Convert property doc entries to text strings for embedding\n",
        "    doc_texts = [\" \".join(entry) for entry in matched_docs]\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    question_emb = model.encode(question, convert_to_tensor=True)\n",
        "    doc_embs = model.encode(doc_texts, convert_to_tensor=True)\n",
        "    scores = util.cos_sim(question_emb, doc_embs)[0]\n",
        "\n",
        "    # Get top-k properties\n",
        "    top_indices = scores.topk(k=min(top_k, len(matched_docs))).indices\n",
        "    filtered_props = [matched_docs[i] for i in top_indices]\n",
        "\n",
        "    return filtered_props"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd4266c1-664e-490a-9fcd-0bb34b794437",
      "metadata": {
        "id": "cd4266c1-664e-490a-9fcd-0bb34b794437"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53ec6c10-f0d0-4249-9a55-81f035e02241",
      "metadata": {
        "id": "53ec6c10-f0d0-4249-9a55-81f035e02241"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8f33cc4-98ff-439d-bec6-1c0599df6e42",
      "metadata": {
        "id": "f8f33cc4-98ff-439d-bec6-1c0599df6e42",
        "outputId": "7d9980a2-a238-4b8d-9af4-e50082a57bae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----\n",
            "ex:eventon (ObjectProperty) (ex:Event → ex:Calendar)\n",
            "- \"Event is connected to Calendar entity.\"\n",
            "-----\n",
            "ex:day (DatatypeProperty) (ex:Calendar → xsd:date)\n",
            "- \"Date of the event.\"\n",
            "-----\n",
            "ex:eventstate (ObjectProperty) (ex:Event → ex:State)\n",
            "- \"An event has a status/state.\"\n",
            "-----\n",
            "ex:eventname_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event name in Italian. Each event must have a name\"\n",
            "-----\n",
            "ex:eventdescr_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event description in Italian.\"\n"
          ]
        }
      ],
      "source": [
        "\n",
        "question1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "top_properties = rank_relevant_properties(question1, all_collected_props, property_doc, label_map, top_k=5)\n",
        "\n",
        "for prop in top_properties:\n",
        "    print(\"-----\")\n",
        "    for line in prop:\n",
        "        print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b05f005-db53-4569-bf1c-72576892bed6",
      "metadata": {
        "id": "6b05f005-db53-4569-bf1c-72576892bed6"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Location\", \"http://example.org/EventCategory\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a82f226-7759-452e-badb-6abdfb936e30",
      "metadata": {
        "id": "1a82f226-7759-452e-badb-6abdfb936e30"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e13f1953-922b-4e31-8d98-def0ccc8036d",
      "metadata": {
        "id": "e13f1953-922b-4e31-8d98-def0ccc8036d",
        "outputId": "2393af36-c581-4aa6-f9a1-1239c0e04be1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----\n",
            "ex:eventat (ObjectProperty) (ex:Location → ex:Event)\n",
            "- \"Event is connected to Location entity. Each event must have a location\"\n",
            "-----\n",
            "ex:eventname_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event name in Italian. Each event must have a name\"\n",
            "-----\n",
            "ex:statename (DatatypeProperty) (ex:State → xsd:string)\n",
            "- \"Name of the event state.\"\n",
            "- Example:  [\"eliminato\", \"attivo\"]\n",
            "-----\n",
            "ex:eventdescr_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event description in Italian.\"\n",
            "-----\n",
            "ex:eventimage_url (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"URL of the event image.\"\n"
          ]
        }
      ],
      "source": [
        "question2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "top_properties = rank_relevant_properties(question2, all_collected_props, property_doc, label_map, top_k=5)\n",
        "\n",
        "for prop in top_properties:\n",
        "    print(\"-----\")\n",
        "    for line in prop:\n",
        "        print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf46840b-a149-4b54-bc80-0445bd3f7176",
      "metadata": {
        "id": "cf46840b-a149-4b54-bc80-0445bd3f7176"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Location\", \"http://example.org/Calendar\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7c45110-3e89-484f-a217-14b03a329282",
      "metadata": {
        "id": "c7c45110-3e89-484f-a217-14b03a329282"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fdea34e-2d9b-420f-8511-fa6dba940d6b",
      "metadata": {
        "id": "4fdea34e-2d9b-420f-8511-fa6dba940d6b",
        "outputId": "e86f85a4-1b15-4b08-b68b-6cbee912aa16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----\n",
            "ex:eventat (ObjectProperty) (ex:Location → ex:Event)\n",
            "- \"Event is connected to Location entity. Each event must have a location\"\n",
            "-----\n",
            "ex:eventon (ObjectProperty) (ex:Event → ex:Calendar)\n",
            "- \"Event is connected to Calendar entity.\"\n",
            "-----\n",
            "ex:day (DatatypeProperty) (ex:Calendar → xsd:date)\n",
            "- \"Date of the event.\"\n",
            "-----\n",
            "ex:end_time (DatatypeProperty) (ex:Calendar → xsd:string)\n",
            "- \"Event end time. Time format must be 00:00 \"\n",
            "-----\n",
            "ex:eventstate (ObjectProperty) (ex:Event → ex:State)\n",
            "- \"An event has a status/state.\"\n"
          ]
        }
      ],
      "source": [
        "question3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "top_properties = rank_relevant_properties(question3, all_collected_props, property_doc, label_map, top_k=5)\n",
        "\n",
        "for prop in top_properties:\n",
        "    print(\"-----\")\n",
        "    for line in prop:\n",
        "        print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29b0fc5f-c142-4b46-aea7-8db96738e575",
      "metadata": {
        "id": "29b0fc5f-c142-4b46-aea7-8db96738e575"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "461c03ef-a43c-4ece-ad51-6700d726772f",
      "metadata": {
        "id": "461c03ef-a43c-4ece-ad51-6700d726772f"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f10999-f7f0-40ba-a5aa-4a6023c25a8e",
      "metadata": {
        "id": "84f10999-f7f0-40ba-a5aa-4a6023c25a8e",
        "outputId": "483b8133-94b1-4fce-992b-6545546d0276"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----\n",
            "ex:start_time (DatatypeProperty) (ex:Calendar → xsd:string)\n",
            "- \"Event start time. Time format must be 00:00 \"\n",
            "-----\n",
            "ex:eventon (ObjectProperty) (ex:Event → ex:Calendar)\n",
            "- \"Event is connected to Calendar entity.\"\n",
            "-----\n",
            "ex:end_time (DatatypeProperty) (ex:Calendar → xsd:string)\n",
            "- \"Event end time. Time format must be 00:00 \"\n",
            "-----\n",
            "ex:day (DatatypeProperty) (ex:Calendar → xsd:date)\n",
            "- \"Date of the event.\"\n",
            "-----\n",
            "ex:eventdescr_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event description in Italian.\"\n",
            "-----\n",
            "ex:eventname_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event name in Italian. Each event must have a name\"\n",
            "-----\n",
            "ex:eventstate (ObjectProperty) (ex:Event → ex:State)\n",
            "- \"An event has a status/state.\"\n",
            "-----\n",
            "ex:calendarclassid (DatatypeProperty) (ex:Calendar → xsd:string)\n",
            "- \"Unique identifier for a calendar entry.\"\n",
            "-----\n",
            "ex:eventclassid (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Unique identifier for an event.\"\n",
            "-----\n",
            "ex:eventimage_url (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"URL of the event image.\"\n"
          ]
        }
      ],
      "source": [
        "question4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "top_properties = rank_relevant_properties(question4, all_collected_props, property_doc, label_map, top_k=10)\n",
        "\n",
        "for prop in top_properties:\n",
        "    print(\"-----\")\n",
        "    for line in prop:\n",
        "        print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c78694d-1897-43fe-b6ce-8b830a2632a4",
      "metadata": {
        "id": "4c78694d-1897-43fe-b6ce-8b830a2632a4"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/State\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b2a0603-3834-4ee2-bca8-d515d16c2525",
      "metadata": {
        "id": "3b2a0603-3834-4ee2-bca8-d515d16c2525"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ed33fd-fa21-42e2-8454-7e2f5f832bf6",
      "metadata": {
        "id": "64ed33fd-fa21-42e2-8454-7e2f5f832bf6",
        "outputId": "d5ce28eb-927a-4bc6-caf7-85e5ceeecdad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----\n",
            "ex:eventstate (ObjectProperty) (ex:Event → ex:State)\n",
            "- \"An event has a status/state.\"\n",
            "-----\n",
            "ex:eventname_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event name in Italian. Each event must have a name\"\n",
            "-----\n",
            "ex:eventdescr_it (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Event description in Italian.\"\n",
            "-----\n",
            "ex:eventclassid (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"Unique identifier for an event.\"\n",
            "-----\n",
            "ex:statename (DatatypeProperty) (ex:State → xsd:string)\n",
            "- \"Name of the event state.\"\n",
            "- Example:  [\"eliminato\", \"attivo\"]\n",
            "-----\n",
            "ex:statecode (DatatypeProperty) (ex:State → xsd:string)\n",
            "- \"Code representing the state of an event.\"\n",
            "-----\n",
            "ex:eventimage_url (DatatypeProperty) (ex:Event → xsd:string)\n",
            "- \"URL of the event image.\"\n"
          ]
        }
      ],
      "source": [
        "question5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "top_properties = rank_relevant_properties(question5, all_collected_props, property_doc, label_map, top_k=10)\n",
        "\n",
        "for prop in top_properties:\n",
        "    print(\"-----\")\n",
        "    for line in prop:\n",
        "        print(line)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a40184e-e005-40e2-b323-c0bb0e6a678e",
      "metadata": {
        "id": "9a40184e-e005-40e2-b323-c0bb0e6a678e"
      },
      "source": [
        "## Extract classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5758a494-8d71-475b-a11d-38722f05e8ea",
      "metadata": {
        "id": "5758a494-8d71-475b-a11d-38722f05e8ea"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load the embedding model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# User question\n",
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "# Extract class descriptions (flattened)\n",
        "class_texts = [entry[0] for entry in class_doc]\n",
        "class_labels = [entry[0].split()[0].replace(\"ex:\", \"\") for entry in class_doc]\n",
        "\n",
        "# Embed the question and class definitions\n",
        "question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "class_embeddings = model.encode(class_texts, convert_to_tensor=True)\n",
        "\n",
        "# Compute cosine similarities\n",
        "cosine_scores = util.cos_sim(question_embedding, class_embeddings)[0]\n",
        "\n",
        "# Select top-k classes\n",
        "top_k = 3  # you can adjust this based on prompt size\n",
        "top_indices = cosine_scores.topk(k=top_k).indices\n",
        "\n",
        "# Extract top-k class definitions and URIs\n",
        "top_classes = [class_doc[i] for i in top_indices]\n",
        "top_class_uris = [f\"http://example.org/{class_labels[i]}\" for i in top_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "419d1f0b-c1a6-4a31-8d6d-644120bb7045",
      "metadata": {
        "id": "419d1f0b-c1a6-4a31-8d6d-644120bb7045",
        "outputId": "faba5b79-66c6-467b-96b1-e29a62353757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. ex:Calendar (Class) → Represents when the event occurs\n",
            "2. ex:Event (Class) → Represents an event\n",
            "3. ex:EventCategory (Class) → Represents a category of an event\n"
          ]
        }
      ],
      "source": [
        "for i, prop in enumerate(top_classes):\n",
        "    print(f\"{i+1}. {prop[0]}\")\n",
        "    for line in prop[1:]:\n",
        "        print(\"   \", line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fb580e1-03fe-488b-b67a-a6fbf508a6ac",
      "metadata": {
        "id": "4fb580e1-03fe-488b-b67a-a6fbf508a6ac"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def extract_relevant_classes_from_question(question, class_doc, top_k=3):\n",
        "    \"\"\"\n",
        "    Given a natural language question and a class_doc list,\n",
        "    return the top_k most relevant class URIs and their descriptions using embedding similarity.\n",
        "\n",
        "    Parameters:\n",
        "        question (str): The user's natural language question.\n",
        "        class_doc (list): A list of class descriptions in the form [['ex:Event (Class) → Represents an event'], ...]\n",
        "        top_k (int): Number of top relevant classes to return.\n",
        "\n",
        "    Returns:\n",
        "        top_class_uris (list): URIs of the most relevant classes (e.g., [\"http://example.org/Event\"])\n",
        "        top_classes (list): Corresponding class descriptions (e.g., ['ex:Event (Class) → Represents an event'])\n",
        "    \"\"\"\n",
        "    # Load the embedding model once (if not already loaded)\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Flatten and clean class_doc entries\n",
        "    class_texts = [entry[0] for entry in class_doc if isinstance(entry, list) and entry]\n",
        "    class_labels = [text.split()[0].replace(\"ex:\", \"\") for text in class_texts]\n",
        "\n",
        "    # Generate embeddings\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    class_embeddings = model.encode(class_texts, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    cosine_scores = util.cos_sim(question_embedding, class_embeddings)[0]\n",
        "\n",
        "    # Top-k indices\n",
        "    top_indices = cosine_scores.topk(k=min(top_k, len(class_doc))).indices\n",
        "\n",
        "    # Select top-k class descriptions and URIs\n",
        "    top_classes = [class_texts[i] for i in top_indices]\n",
        "    top_class_uris = [f\"http://example.org/{class_labels[i]}\" for i in top_indices]\n",
        "\n",
        "    return top_class_uris, top_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd4ba20b-2ada-4d10-b503-8c1830da0ef2",
      "metadata": {
        "id": "fd4ba20b-2ada-4d10-b503-8c1830da0ef2",
        "outputId": "4e1d62d7-0864-4b2b-c4cc-74886e8fb1ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/Calendar', 'http://example.org/Event', 'http://example.org/Location']\n",
            "Top Descriptions:\n",
            "- ex:Calendar (Class) → Represents when the event occurs\n",
            "- ex:Event (Class) → Represents event details\n",
            "- ex:Location (Class) → Represents location details of events\n"
          ]
        }
      ],
      "source": [
        "question1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "class_doc = [\n",
        "    ['ex:Event (Class) → Represents event details'],\n",
        "    ['ex:Calendar (Class) → Represents when the event occurs'],\n",
        "    ['ex:Location (Class) → Represents location details of events'],\n",
        "    ['ex:State (Class) → Represents the status of an event'],\n",
        "    ['ex:EventCategory (Class) → Represents a category of an event']\n",
        "]\n",
        "\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question1, class_doc, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5601abc4-4fef-46f8-a6e1-953c7033f666",
      "metadata": {
        "id": "5601abc4-4fef-46f8-a6e1-953c7033f666",
        "outputId": "4ab3aa68-9970-4db9-c1b4-ad8c207b69ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/EventCategory', 'http://example.org/Location', 'http://example.org/Event']\n",
            "Top Descriptions:\n",
            "- ex:EventCategory (Class) → Represents a category of an event\n",
            "- ex:Location (Class) → Represents location details of events\n",
            "- ex:Event (Class) → Represents event details\n"
          ]
        }
      ],
      "source": [
        "question2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "class_doc = [\n",
        "    ['ex:Event (Class) → Represents event details'],\n",
        "    ['ex:Calendar (Class) → Represents when the event occurs'],\n",
        "    ['ex:Location (Class) → Represents location details of events'],\n",
        "    ['ex:State (Class) → Represents the status of an event'],\n",
        "    ['ex:EventCategory (Class) → Represents a category of an event']\n",
        "]\n",
        "\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question2, class_doc, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd9bdb4b-57fe-44d3-b057-3cf22ee9467a",
      "metadata": {
        "id": "cd9bdb4b-57fe-44d3-b057-3cf22ee9467a",
        "outputId": "80a96c08-825a-4df7-9481-6e361eb118a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/Location', 'http://example.org/Calendar', 'http://example.org/Event']\n",
            "Top Descriptions:\n",
            "- ex:Location (Class) → Represents location details of events\n",
            "- ex:Calendar (Class) → Represents when the event occurs\n",
            "- ex:Event (Class) → Represents event details\n"
          ]
        }
      ],
      "source": [
        "question3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "class_doc = [\n",
        "    ['ex:Event (Class) → Represents event details'],\n",
        "    ['ex:Calendar (Class) → Represents when the event occurs'],\n",
        "    ['ex:Location (Class) → Represents location details of events'],\n",
        "    ['ex:State (Class) → Represents the status of an event'],\n",
        "    ['ex:EventCategory (Class) → Represents a category of an event']\n",
        "]\n",
        "\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question3, class_doc, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef9651de-de98-4de1-ab8d-6965fad0f9c1",
      "metadata": {
        "id": "ef9651de-de98-4de1-ab8d-6965fad0f9c1",
        "outputId": "2c7a34ed-8b94-4ce9-ea1f-4f5c6eb2051c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/Calendar', 'http://example.org/Location', 'http://example.org/Event']\n",
            "Top Descriptions:\n",
            "- ex:Calendar (Class) → Represents when the event occurs\n",
            "- ex:Location (Class) → Represents location details of events\n",
            "- ex:Event (Class) → Represents event details\n"
          ]
        }
      ],
      "source": [
        "question4 = \"What are the events scheduled to start at 11.30?\"\n",
        "class_doc = [\n",
        "    ['ex:Event (Class) → Represents event details'],\n",
        "    ['ex:Calendar (Class) → Represents when the event occurs'],\n",
        "    ['ex:Location (Class) → Represents location details of events'],\n",
        "    ['ex:State (Class) → Represents the status of an event'],\n",
        "    ['ex:EventCategory (Class) → Represents a category of an event']\n",
        "]\n",
        "\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question4, class_doc, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a80b4c9-afbd-423a-b6e8-72da6c29baa8",
      "metadata": {
        "id": "6a80b4c9-afbd-423a-b6e8-72da6c29baa8",
        "outputId": "2fb8bfce-3eaa-4b02-8290-3f7dec8a1848"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/Event', 'http://example.org/State', 'http://example.org/Calendar']\n",
            "Top Descriptions:\n",
            "- ex:Event (Class) → Represents event details\n",
            "- ex:State (Class) → Represents the status of an event\n",
            "- ex:Calendar (Class) → Represents when the event occurs\n"
          ]
        }
      ],
      "source": [
        "question5 = \"Can you give the event names and their status?\"\n",
        "class_doc = [\n",
        "    ['ex:Event (Class) → Represents event details'],\n",
        "    ['ex:Calendar (Class) → Represents when the event occurs'],\n",
        "    ['ex:Location (Class) → Represents location details of events'],\n",
        "    ['ex:State (Class) → Represents the status of an event'],\n",
        "    ['ex:EventCategory (Class) → Represents a category of an event']\n",
        "]\n",
        "\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question5, class_doc, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f360fd5-89f6-4675-8241-49e70d047e5a",
      "metadata": {
        "id": "8f360fd5-89f6-4675-8241-49e70d047e5a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31c7241d-89f6-4c42-a2ac-b7ab2b9c26cb",
      "metadata": {
        "id": "31c7241d-89f6-4c42-a2ac-b7ab2b9c26cb"
      },
      "outputs": [],
      "source": [
        "def generate_sparql_prompt(question, relevant_classes, relevant_properties, few_shot_examples):\n",
        "    \"\"\"\n",
        "    Create a prompt using M-Schema style with few-shot examples to ask an LLM to generate SPARQL.\n",
        "\n",
        "    Parameters:\n",
        "        question (str): Natural language question from the user.\n",
        "        relevant_classes (list): List of relevant class URIs.\n",
        "        relevant_properties (list): List of (property URI, description) tuples.\n",
        "        few_shot_examples (list): List of dictionaries with keys: question, m_schema, sparql.\n",
        "\n",
        "    Returns:\n",
        "        prompt (str): Final prompt to send to an LLM.\n",
        "    \"\"\"\n",
        "    prompt_parts = []\n",
        "\n",
        "    # Add few-shot examples\n",
        "    for example in few_shot_examples:\n",
        "        prompt_parts.append(\"###\")\n",
        "        prompt_parts.append(f\"Question: {example['question']}\")\n",
        "        prompt_parts.append(\"M-Schema:\")\n",
        "        prompt_parts.append(example['m_schema'])\n",
        "        prompt_parts.append(\"SPARQL:\")\n",
        "        prompt_parts.append(example['sparql'])\n",
        "\n",
        "    # Separator\n",
        "    prompt_parts.append(\"###\")\n",
        "\n",
        "    # Add user's question\n",
        "    prompt_parts.append(f\"Question: {question}\")\n",
        "\n",
        "    # Construct M-Schema context\n",
        "    m_schema = \"M-Schema:\\n\"\n",
        "    for cls in relevant_classes:\n",
        "        m_schema += f\"Class: {cls}\\n\"\n",
        "    for uri, desc in relevant_properties:\n",
        "        m_schema += f\"Property: {uri} - {desc.strip()}\\n\"\n",
        "    prompt_parts.append(m_schema)\n",
        "\n",
        "    # Ask for SPARQL\n",
        "    prompt_parts.append(\"SPARQL:\")\n",
        "\n",
        "    # Final prompt\n",
        "    return \"\\n\".join(prompt_parts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a25efe7-2dfc-413a-8e5a-f471c60e8ffc",
      "metadata": {
        "id": "6a25efe7-2dfc-413a-8e5a-f471c60e8ffc",
        "outputId": "73c57f03-6e9c-49ef-e0f7-ca977d764859"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 301 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4775.18 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   150 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  118753.29 ms /   151 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SPARQL:\n",
            "SELECT ?eventName (?) startTime WHERE {\n",
            "  ?event a ex:Event ;\n",
            "         ex:eventon ?calendar ;\n",
            "         ex:eventname_it ?eventName .\n",
            "  ?calendar ex:day \"2015-12-12\" .\n",
            "}\n",
            "###\n",
            "Question: What is the name of the event that takes place on December 17, 2018, at 14:30?\n",
            "M-Schema:\n",
            "Class: http://example.org/Event\n",
            "Class: http://example.org/Calendar\n",
            "Property: http://example.org/eventname_it - Event name in Italian.\n",
            "Property: http://example.\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names and start times of events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = [\n",
        "    \"http://example.org/Event\",\n",
        "    \"http://example.org/Calendar\"\n",
        "]\n",
        "\n",
        "relevant_properties = [\n",
        "    (\"http://example.org/eventname_it\", \"Event name in Italian.\"),\n",
        "    (\"http://example.org/start_time\", \"Start time of the event.\"),\n",
        "    (\"http://example.org/day\", \"Date of the event.\"),\n",
        "    (\"http://example.org/eventon\", \"Event is connected to a calendar.\")\n",
        "]\n",
        "\n",
        "few_shot_examples = [\n",
        "    {\n",
        "        \"question\": \"What is the name of the event held on 2023-01-01?\",\n",
        "        \"m_schema\": \"\"\"Class: http://example.org/Event\n",
        "Class: http://example.org/Calendar\n",
        "Property: http://example.org/eventname_it - Event name in Italian.\n",
        "Property: http://example.org/day - Date of the event.\n",
        "Property: http://example.org/eventon - Event is connected to a calendar.\"\"\",\n",
        "        \"sparql\": \"\"\"SELECT ?eventName WHERE {\n",
        "  ?event a ex:Event ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventname_it ?eventName .\n",
        "  ?calendar ex:day \"2023-01-01\" .\n",
        "}\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# Generate the prompt first\n",
        "prompt = generate_sparql_prompt(question, relevant_classes, relevant_properties, few_shot_examples)\n",
        "\n",
        "# Call the LLM with the prompt (assuming a text completion interface)\n",
        "response = llm(\n",
        "    prompt,\n",
        "    max_tokens=150,\n",
        "    temperature=0.2,\n",
        ")\n",
        "\n",
        "# Extract the generated text from response\n",
        "generated_sparql = response.strip()\n",
        "\n",
        "print(\"Generated SPARQL:\")\n",
        "print(generated_sparql)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "639700f7-27f9-477c-a778-69f0d13f0594",
      "metadata": {
        "id": "639700f7-27f9-477c-a778-69f0d13f0594"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7769b77d-671a-41b5-8d67-4cf3b58bc61e",
      "metadata": {
        "id": "7769b77d-671a-41b5-8d67-4cf3b58bc61e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab9317af-b0a2-468e-9b8a-cef5fd257bfe",
      "metadata": {
        "id": "ab9317af-b0a2-468e-9b8a-cef5fd257bfe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2bf2655a-9a45-427a-9459-6cc7127bc06c",
      "metadata": {
        "id": "2bf2655a-9a45-427a-9459-6cc7127bc06c"
      },
      "source": [
        "## Cosine similarity - TTL file with dict approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb30afff-f6bd-4810-a71e-c3faa72f7a00",
      "metadata": {
        "id": "fb30afff-f6bd-4810-a71e-c3faa72f7a00"
      },
      "outputs": [],
      "source": [
        "class_dict = {\n",
        "    \"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\n",
        "    \"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "\n",
        "    \"ex:Location\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Location\" .''',\n",
        "\n",
        "    \"ex:EventCategory\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event Category\" .''',\n",
        "\n",
        "    \"ex:State\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"State\" .'''\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d4ce77c-b676-4d03-b9db-04366ac689e0",
      "metadata": {
        "id": "3d4ce77c-b676-4d03-b9db-04366ac689e0"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def extract_relevant_classes_from_question(question, class_dict, top_k=3):\n",
        "    \"\"\"\n",
        "    Given a natural language question and a dictionary of ontology classes,\n",
        "    return the top_k most relevant class URIs and their descriptions using embedding similarity.\n",
        "\n",
        "    Parameters:\n",
        "        question (str): The user's natural language question.\n",
        "        class_dict (dict): A dictionary mapping class URIs (with ex: prefix) to their description strings.\n",
        "        top_k (int): Number of top relevant classes to return.\n",
        "\n",
        "    Returns:\n",
        "        top_class_uris (list): List of full URIs (e.g., [\"http://example.org/Event\"])\n",
        "        top_classes (list): Corresponding description strings\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Extract keys and values\n",
        "    class_keys = list(class_dict.keys())\n",
        "    class_texts = list(class_dict.values())\n",
        "\n",
        "    # Encode question and class descriptions\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    class_embeddings = model.encode(class_texts, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    scores = util.cos_sim(question_embedding, class_embeddings)[0]\n",
        "    top_indices = scores.topk(k=min(top_k, len(class_dict))).indices\n",
        "\n",
        "    # Collect top class URIs and their descriptions\n",
        "    top_class_uris = [f\"http://example.org/{class_keys[i].replace('ex:', '')}\" for i in top_indices]\n",
        "    top_classes = [class_texts[i] for i in top_indices]\n",
        "\n",
        "    return top_class_uris, top_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b403db40-e781-422a-afa6-d2eba8075da2",
      "metadata": {
        "id": "b403db40-e781-422a-afa6-d2eba8075da2",
        "outputId": "40ab7b2f-8bb8-47bf-aa14-845151088f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/EventCategory', 'http://example.org/Event', 'http://example.org/Calendar']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event Category\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Calendar\" .\n"
          ]
        }
      ],
      "source": [
        "question1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question1, class_dict, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "406cfa8d-6dc6-48b8-875e-ef12c1498726",
      "metadata": {
        "id": "406cfa8d-6dc6-48b8-875e-ef12c1498726",
        "outputId": "2b70141d-8dc0-4901-a2c4-47e8915d1484"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/EventCategory', 'http://example.org/Event', 'http://example.org/Calendar']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event Category\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Calendar\" .\n"
          ]
        }
      ],
      "source": [
        "question2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question2, class_dict, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29ab16b6-35d2-475c-8775-30d063ce178f",
      "metadata": {
        "id": "29ab16b6-35d2-475c-8775-30d063ce178f",
        "outputId": "1b75659c-5dd0-44a3-cab2-d0d42a4c5f6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/EventCategory', 'http://example.org/Event', 'http://example.org/Calendar']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event Category\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Calendar\" .\n"
          ]
        }
      ],
      "source": [
        "question3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question3, class_dict, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686d10c2-a5f3-4033-b343-416692cd4504",
      "metadata": {
        "id": "686d10c2-a5f3-4033-b343-416692cd4504",
        "outputId": "e8a204de-88cd-4981-edbe-03a995420fe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/EventCategory', 'http://example.org/Event', 'http://example.org/Calendar']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event Category\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Calendar\" .\n"
          ]
        }
      ],
      "source": [
        "question4 = \"What are the events scheduled to start at 11.30?\"\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question4, class_dict, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aecbc0c5-ea9c-4e20-b610-7b34f269ae64",
      "metadata": {
        "id": "aecbc0c5-ea9c-4e20-b610-7b34f269ae64",
        "outputId": "05bf0af3-7895-4372-84da-d90069237b31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/Event', 'http://example.org/EventCategory', 'http://example.org/Calendar']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Event Category\" .\n",
            "- rdf:type owl:Class ;\n",
            "    rdfs:label \"Calendar\" .\n"
          ]
        }
      ],
      "source": [
        "question5 = \"Can you give the event names and their status?\"\n",
        "top_uris, top_descriptions = extract_relevant_classes_from_question(question5, class_dict, top_k=3)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_descriptions:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "235c95db-55cd-478a-9661-4a76b56b0924",
      "metadata": {
        "id": "235c95db-55cd-478a-9661-4a76b56b0924"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def rank_relevant_properties(question, property_dict, allowed_properties=None, top_k=5):\n",
        "    \"\"\"\n",
        "    Given a question and a dictionary of properties, return the top_k most relevant properties\n",
        "    using embedding similarity.\n",
        "\n",
        "    Parameters:\n",
        "        question (str): Natural language question from user.\n",
        "        property_dict (dict): Dictionary where keys are property URIs (with ex:) and values are RDF-style descriptions.\n",
        "        allowed_properties (set): Optional set of property URIs (e.g., from graph traversal) to filter from.\n",
        "        top_k (int): Number of top matching properties to return.\n",
        "\n",
        "    Returns:\n",
        "        top_uris (list): Full URIs (e.g., [\"http://example.org/eventon\"])\n",
        "        top_props (list): Corresponding property descriptions\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Filter based on allowed properties (if any)\n",
        "    filtered_items = property_dict.items()\n",
        "    if allowed_properties:\n",
        "        allowed_labels = {f\"ex:{label}\" for label in allowed_properties}\n",
        "        filtered_items = [(k, v) for k, v in property_dict.items() if k in allowed_labels]\n",
        "\n",
        "    if not filtered_items:\n",
        "        return [], []\n",
        "\n",
        "    prop_keys = [k for k, _ in filtered_items]\n",
        "    prop_texts = [v for _, v in filtered_items]\n",
        "\n",
        "    # Compute embeddings\n",
        "    question_embedding = model.encode(question, convert_to_tensor=True)\n",
        "    prop_embeddings = model.encode(prop_texts, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    scores = util.cos_sim(question_embedding, prop_embeddings)[0]\n",
        "    top_indices = scores.topk(k=min(top_k, len(prop_keys))).indices\n",
        "\n",
        "    # Extract top-k\n",
        "    top_uris = [f\"http://example.org/{prop_keys[i].replace('ex:', '')}\" for i in top_indices]\n",
        "    top_props = [prop_texts[i] for i in top_indices]\n",
        "\n",
        "    return top_uris, top_props\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8536f836-37da-4769-b67e-47ed56197da3",
      "metadata": {
        "id": "8536f836-37da-4769-b67e-47ed56197da3",
        "outputId": "b9425632-1695-4a4d-cec5-8c980053d21d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/eventon', 'http://example.org/eventat', 'http://example.org/eventstate', 'http://example.org/eventname_it', 'http://example.org/day']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event At\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:date ;\n",
            "    rdfs:label \"day\" .\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "top_uris, top_props = rank_relevant_properties(question, property_dict, top_k=5)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_props:\n",
        "    print(\"-\", desc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61c4fc13-9eb4-49e8-8658-b406a944eee5",
      "metadata": {
        "id": "61c4fc13-9eb4-49e8-8658-b406a944eee5",
        "outputId": "80e5f1ad-f579-4207-f16f-2e3f1c0aeef4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/eventon', 'http://example.org/eventcatname_it', 'http://example.org/hasCategory', 'http://example.org/eventat', 'http://example.org/eventname_it']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:EventCategory ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Eventcat Name\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:EventCategory ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Has Category\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event At\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n"
          ]
        }
      ],
      "source": [
        "question2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "top_uris, top_props = rank_relevant_properties(question2, property_dict, top_k=5)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_props:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6963dd28-fca7-45a9-acde-e415f2cafb9f",
      "metadata": {
        "id": "6963dd28-fca7-45a9-acde-e415f2cafb9f",
        "outputId": "803fd307-eb59-49a6-a7f1-519ce9511f5f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/eventon', 'http://example.org/eventat', 'http://example.org/start_time', 'http://example.org/eventstate', 'http://example.org/day']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event At\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"StartTime\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:date ;\n",
            "    rdfs:label \"day\" .\n"
          ]
        }
      ],
      "source": [
        "question4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "top_uris, top_props = rank_relevant_properties(question4, property_dict, top_k=5)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_props:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "afe960e6-adfe-4baf-aa2c-465ef8df8d0b",
      "metadata": {
        "id": "afe960e6-adfe-4baf-aa2c-465ef8df8d0b",
        "outputId": "a4559788-72f1-44e5-98bc-59f0681a781a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top URIs: ['http://example.org/eventon', 'http://example.org/eventstate', 'http://example.org/eventname_it', 'http://example.org/eventat', 'http://example.org/eventdescr_it']\n",
            "Top Descriptions:\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event At\" .\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Description (IT)\" .\n"
          ]
        }
      ],
      "source": [
        "question5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "top_uris, top_props = rank_relevant_properties(question5, property_dict, top_k=5)\n",
        "\n",
        "print(\"Top URIs:\", top_uris)\n",
        "print(\"Top Descriptions:\")\n",
        "for desc in top_props:\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fcff76-5bb3-4124-9c0e-bdced4b1a4de",
      "metadata": {
        "id": "16fcff76-5bb3-4124-9c0e-bdced4b1a4de"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8cc0ee6-3bd6-4009-b82e-8983797f0fd2",
      "metadata": {
        "id": "f8cc0ee6-3bd6-4009-b82e-8983797f0fd2"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "def rank_relevant_properties_from_dict(question, all_collected_props, property_dict, label_map, top_k=5):\n",
        "    \"\"\"\n",
        "    Rank the most relevant properties given a question and graph traversal output,\n",
        "    using a property_dict and label_map for matching.\n",
        "\n",
        "    Parameters:\n",
        "        question (str): User's natural language query.\n",
        "        all_collected_props (list): Output from graph traversal, list of tuples (from, to, label, type).\n",
        "        property_dict (dict): Dictionary of ontology property → RDF description string.\n",
        "        label_map (dict): Human-readable → ontology property label mapping.\n",
        "        top_k (int): Number of top relevant properties to return.\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: [(uri, description), ...] sorted by similarity to the question.\n",
        "    \"\"\"\n",
        "    model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "    # Extract human-readable labels from graph traversal tuples\n",
        "    collected_labels = [prop[2] for prop in all_collected_props]\n",
        "\n",
        "    # Map to ontology labels (e.g., 'Event Name' → 'eventname_it')\n",
        "    mapped_labels = {\n",
        "        label_map.get(label, \"\").strip().lower()\n",
        "        for label in collected_labels\n",
        "        if label_map.get(label)\n",
        "    }\n",
        "\n",
        "    # Filter property_dict entries based on mapped labels\n",
        "    filtered_props = [\n",
        "        (uri, rdf_text) for uri, rdf_text in property_dict.items()\n",
        "        if uri.replace(\"ex:\", \"\").lower() in mapped_labels\n",
        "    ]\n",
        "\n",
        "    if not filtered_props:\n",
        "        return []\n",
        "\n",
        "    prop_uris, prop_texts = zip(*filtered_props)\n",
        "\n",
        "    # Encode question and RDF text descriptions\n",
        "    question_emb = model.encode(question, convert_to_tensor=True)\n",
        "    doc_embs = model.encode(prop_texts, convert_to_tensor=True)\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    scores = util.cos_sim(question_emb, doc_embs)[0]\n",
        "    top_indices = scores.topk(k=min(top_k, len(filtered_props))).indices\n",
        "\n",
        "    # Return top-k ranked (uri, description)\n",
        "    return [(prop_uris[i], prop_texts[i]) for i in top_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd37b922-b1a0-4bff-99ef-d3e49f636097",
      "metadata": {
        "id": "bd37b922-b1a0-4bff-99ef-d3e49f636097"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\" ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33ec729a-2bbb-4946-9189-508a691cc036",
      "metadata": {
        "id": "33ec729a-2bbb-4946-9189-508a691cc036"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a5e57ab-dc2d-48c6-a3dd-1b02eb6d4726",
      "metadata": {
        "id": "1a5e57ab-dc2d-48c6-a3dd-1b02eb6d4726",
        "outputId": "e30d2fe6-eae6-4b09-b827-0309c698c174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:eventon\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "ex:eventstate\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "ex:eventname_it\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "ex:day\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:date ;\n",
            "    rdfs:label \"day\" .\n",
            "ex:eventdescr_it\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Description (IT)\" .\n"
          ]
        }
      ],
      "source": [
        "question1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "ranked_props = rank_relevant_properties_from_dict(question1,all_collected_props, property_dict, label_map,top_k=5)\n",
        "\n",
        "for uri, desc in ranked_props:\n",
        "    print(uri)\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f66c769d-b7fa-47e9-a06d-ff415b2b090d",
      "metadata": {
        "id": "f66c769d-b7fa-47e9-a06d-ff415b2b090d"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Location\", \"http://example.org/EventCategory\"  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a41d4cd9-5429-47ed-a04f-20d3ad6edb05",
      "metadata": {
        "id": "a41d4cd9-5429-47ed-a04f-20d3ad6edb05"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2224c4fd-351a-40ec-aa6a-3948995e4d2a",
      "metadata": {
        "id": "2224c4fd-351a-40ec-aa6a-3948995e4d2a",
        "outputId": "ab7eebac-75f9-4d46-90a3-741d4d87b7fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:eventat\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event At\" .\n",
            "ex:eventname_it\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "ex:eventstate\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "ex:eventclassid\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Class ID\" .\n",
            "ex:eventdescr_it\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Description (IT)\" .\n"
          ]
        }
      ],
      "source": [
        "question2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "ranked_props = rank_relevant_properties_from_dict(question2,all_collected_props, property_dict, label_map,top_k=5)\n",
        "\n",
        "for uri, desc in ranked_props:\n",
        "    print(uri)\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6e473a2-7aa6-4af5-aae4-31427adc4db7",
      "metadata": {
        "id": "d6e473a2-7aa6-4af5-aae4-31427adc4db7"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Location\", \"http://example.org/Calendar\"  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "35e15f19-c608-4994-a581-84f895367dac",
      "metadata": {
        "id": "35e15f19-c608-4994-a581-84f895367dac"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84b68397-66d4-45b8-9285-958312b935e3",
      "metadata": {
        "id": "84b68397-66d4-45b8-9285-958312b935e3",
        "outputId": "7ab3efa6-06fc-49eb-c5b9-89d295f08e17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:eventon\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "ex:eventat\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event At\" .\n",
            "ex:eventstate\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "ex:day\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:date ;\n",
            "    rdfs:label \"day\" .\n",
            "ex:eventname_it\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n"
          ]
        }
      ],
      "source": [
        "question3 = \"What are the locations of the events happen on 2015-12-12?\"\n",
        "\n",
        "ranked_props = rank_relevant_properties_from_dict(question3,all_collected_props, property_dict, label_map,top_k=5)\n",
        "\n",
        "for uri, desc in ranked_props:\n",
        "    print(uri)\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "140bf1e0-a0a4-4008-9ead-f271f3e03e6d",
      "metadata": {
        "id": "140bf1e0-a0a4-4008-9ead-f271f3e03e6d"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\"  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9191021-2272-485c-bc6e-6caa3632740c",
      "metadata": {
        "id": "d9191021-2272-485c-bc6e-6caa3632740c"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b16450b-8c38-4121-a441-2907bc2d2470",
      "metadata": {
        "id": "3b16450b-8c38-4121-a441-2907bc2d2470",
        "outputId": "dee47d46-e364-4158-858d-fb0197e41d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:eventon\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "ex:start_time\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"StartTime\" .\n",
            "ex:eventstate\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "ex:day\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:date ;\n",
            "    rdfs:label \"day\" .\n",
            "ex:end_time\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"EndTime\" .\n"
          ]
        }
      ],
      "source": [
        "question4 = \"What are the events scheduled to start at 11.30?\"\n",
        "\n",
        "ranked_props = rank_relevant_properties_from_dict(question4,all_collected_props, property_dict, label_map,top_k=5)\n",
        "\n",
        "for uri, desc in ranked_props:\n",
        "    print(uri)\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c049ae5d-15ba-4093-92cb-5c2e54469b53",
      "metadata": {
        "id": "c049ae5d-15ba-4093-92cb-5c2e54469b53"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/State\"  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40a3c346-eafd-4034-8323-6acd5619d15b",
      "metadata": {
        "id": "40a3c346-eafd-4034-8323-6acd5619d15b"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ae419c06-3154-471a-8371-40b42db12b7e",
      "metadata": {
        "id": "ae419c06-3154-471a-8371-40b42db12b7e",
        "outputId": "6dd123bc-0190-4422-d204-86611cf548ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:eventstate\n",
            "- rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "ex:eventname_it\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "ex:eventdescr_it\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Description (IT)\" .\n",
            "ex:eventclassid\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Class ID\" .\n",
            "ex:eventimage_url\n",
            "- rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Image URL\" .\n"
          ]
        }
      ],
      "source": [
        "question5 = \"Can you give the event names and their status?\"\n",
        "\n",
        "ranked_props = rank_relevant_properties_from_dict(question5,all_collected_props, property_dict, label_map,top_k=5)\n",
        "\n",
        "for uri, desc in ranked_props:\n",
        "    print(uri)\n",
        "    print(\"-\", desc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34ee8444-e2bf-4dce-98d1-823c3917143f",
      "metadata": {
        "id": "34ee8444-e2bf-4dce-98d1-823c3917143f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc62f7c9-36f3-40d3-8668-757f07143f18",
      "metadata": {
        "id": "fc62f7c9-36f3-40d3-8668-757f07143f18"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9875c636-7806-46aa-a9d1-412815d6bc22",
      "metadata": {
        "id": "9875c636-7806-46aa-a9d1-412815d6bc22"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47f4ec12-2a76-410f-a080-c10ace0eb0cd",
      "metadata": {
        "id": "47f4ec12-2a76-410f-a080-c10ace0eb0cd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6176766a-5b74-421d-8d32-82eb4dcad450",
      "metadata": {
        "id": "6176766a-5b74-421d-8d32-82eb4dcad450"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3af0570f-d200-462d-bd4e-09e599098d23",
      "metadata": {
        "id": "3af0570f-d200-462d-bd4e-09e599098d23"
      },
      "outputs": [],
      "source": [
        "questions_responses_prop = []\n",
        "\n",
        "def ask_relevant_properties(question, relevant_classes, property_doc, llm):\n",
        "    class_to_properties = []\n",
        "\n",
        "    for class_name in relevant_classes:\n",
        "        relevant_props = []\n",
        "\n",
        "        for prop_name in property_doc:\n",
        "            prompt = f\"\"\"You are a SPARQL expert.\n",
        "Given the user question: \"{question}\" and the class {class_name}:\n",
        "\n",
        "Is the following property relevant for retrieving information from class {class_name}?\n",
        "{prop_name}\n",
        "\n",
        "Answer only YES or NO.\"\"\"\n",
        "            response = llm(prompt, max_tokens=50, temperature=0.1)\n",
        "            answer = response['choices'][0]['text'].strip().upper()\n",
        "\n",
        "            if \"YES\" in answer:\n",
        "                relevant_props.append(prop_name)\n",
        "\n",
        "        class_to_properties.append(relevant_props)\n",
        "\n",
        "    questions_responses_prop.append({\n",
        "        \"question\": question,\n",
        "        \"relevant_classes\": relevant_classes,\n",
        "        \"response\": class_to_properties\n",
        "    })\n",
        "\n",
        "    return class_to_properties\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06780524-33e2-4f65-9fcf-3e79e3694346",
      "metadata": {
        "id": "06780524-33e2-4f65-9fcf-3e79e3694346",
        "outputId": "d1dfd13f-b504-4c8b-8d54-437d9ed3ed52"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 38 prefix-match hit, remaining 92 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    92 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5260.70 ms /    93 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2325.13 ms /    35 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 35 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    35 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2087.99 ms /    36 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2373.03 ms /    39 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38824.37 ms /    87 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 43 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    43 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2510.80 ms /    44 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2396.38 ms /    38 tokens\n",
            "Llama.generate: 89 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2452.74 ms /    38 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2222.07 ms /    40 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9373.39 ms /    43 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14688.39 ms /    62 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2853.88 ms /    47 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2330.00 ms /    39 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    1930.41 ms /    35 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2320.32 ms /    39 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13432.31 ms /    65 tokens\n",
            "Llama.generate: 88 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6378.48 ms /    46 tokens\n",
            "Llama.generate: 90 prefix-match hit, remaining 157 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   157 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13856.63 ms /   164 tokens\n",
            "Llama.generate: 44 prefix-match hit, remaining 90 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    90 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5060.33 ms /    91 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2214.36 ms /    35 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 35 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    35 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    1999.64 ms /    36 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2353.38 ms /    39 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2373.16 ms /    39 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 43 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    43 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3317.92 ms /    44 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   38696.05 ms /    86 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2355.44 ms /    38 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2510.10 ms /    40 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    31 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   26082.73 ms /    65 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13502.16 ms /    60 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2874.06 ms /    47 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2375.82 ms /    39 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5784.20 ms /    39 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2259.53 ms /    39 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   39074.05 ms /   100 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2633.04 ms /    42 tokens\n",
            "Llama.generate: 94 prefix-match hit, remaining 157 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   157 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8724.49 ms /   158 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: [[['ex:eventcatclassid (DatatypeProperty) (ex:EventCategory → xsd:string)', '- \"Unique identifier for an event category.\"'], ['ex:eventcatname_it (DatatypeProperty) (ex:EventCategory → xsd:string)', '- \"Category name in Italian.\"', '- Example: [\"Anniversari e Commemorazioni\",\"Arte e Cultura\",\"Conferenze\",\"Incontri Convegni Congressi\",\"Mostre\",\"Rassegna\",\"Solidarietà\",', '\"Visite guidate\",\"Attività per bambini\",\"Campi estivi ragazzi\",\"Concerti\",\"Feste\",\"Festival\",\"Fiere Mercati e Sagre\",\"Manifestazioni sportive\",', '\"Spettacoli\",\"Spettacoli extra lirica in Arena\",\"Turismo\",\"Altro\"]']], [['ex:day (DatatypeProperty) (ex:Calendar → xsd:date)', '- \"Date of the event.\"'], ['ex:statename (DatatypeProperty) (ex:State → xsd:string)', '- \"Name of the event state.\"', '- Example:  [\"eliminato\", \"attivo\"]']]]\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "relevant_classes = [['ex:Event (Class) → Represents an event'],\n",
        " ['ex:Calendar (Class) → Represents when the event occurs']]\n",
        "\n",
        "class_properties = ask_relevant_properties(question_1, relevant_classes, property_doc, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "686ec4c1-8183-457f-8f17-340f8aa897d3",
      "metadata": {
        "id": "686ec4c1-8183-457f-8f17-340f8aa897d3",
        "outputId": "78b177b0-2dc2-49c2-f533-d58967bc0226"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 21 prefix-match hit, remaining 105 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   105 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7183.93 ms /   106 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3031.60 ms /    35 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 35 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    35 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2177.71 ms /    36 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2463.70 ms /    39 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2698.44 ms /    39 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 43 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    43 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2570.04 ms /    44 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18467.97 ms /    54 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    8931.78 ms /    44 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2293.56 ms /    40 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    6907.01 ms /    39 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11269.43 ms /    55 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    19 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   20164.88 ms /    65 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18127.60 ms /    55 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2320.80 ms /    35 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    41 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   40954.61 ms /    79 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    15 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17001.56 ms /    66 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     5 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    7035.46 ms /    46 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 157 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   157 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    25 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   31646.49 ms /   182 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 86 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    86 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    5362.22 ms /    87 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2228.49 ms /    35 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 35 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    35 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2237.17 ms /    36 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2659.06 ms /    39 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2229.77 ms /    39 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 43 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    43 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    12 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   13814.69 ms /    55 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2417.50 ms /    38 tokens\n",
            "Llama.generate: 85 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2495.93 ms /    38 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2510.60 ms /    40 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   48340.53 ms /    83 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     8 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10282.11 ms /    54 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    34 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   34136.13 ms /    80 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2641.50 ms /    39 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    14 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15260.04 ms /    48 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    10 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   11613.09 ms /    48 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     8 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   10577.52 ms /    59 tokens\n",
            "Llama.generate: 84 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2753.11 ms /    42 tokens\n",
            "Llama.generate: 86 prefix-match hit, remaining 157 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   157 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     9 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   17418.57 ms /   166 tokens\n",
            "Llama.generate: 40 prefix-match hit, remaining 94 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    94 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    11 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   15349.00 ms /   105 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2312.50 ms /    35 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 35 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    35 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2028.94 ms /    36 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2366.57 ms /    39 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3303.34 ms /    39 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 43 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    43 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     7 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    9023.33 ms /    50 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2094.80 ms /    38 tokens\n",
            "Llama.generate: 93 prefix-match hit, remaining 37 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    37 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2346.97 ms /    38 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 39 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    39 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    33 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   33013.51 ms /    72 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2050.94 ms /    35 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    3000.94 ms /    47 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 46 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    46 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2877.65 ms /    47 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2455.95 ms /    39 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2004.24 ms /    35 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 38 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    38 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    17 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   18299.90 ms /    55 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 51 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    51 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    32 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   32434.72 ms /    83 tokens\n",
            "Llama.generate: 92 prefix-match hit, remaining 41 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    41 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =    2597.47 ms /    42 tokens\n",
            "Llama.generate: 94 prefix-match hit, remaining 157 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    4108.75 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   157 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    49 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   54646.37 ms /   206 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Relevant properties: [[['ex:end_time (DatatypeProperty) (ex:Calendar → xsd:string)', '- \"Event end time. Time format must be 00:00 \"'], ['ex:statename (DatatypeProperty) (ex:State → xsd:string)', '- \"Name of the event state.\"', '- Example:  [\"eliminato\", \"attivo\"]']], [['ex:address (DatatypeProperty) (ex:Location → xsd:string)', '- \"Address of the location.\"']], [['ex:statename (DatatypeProperty) (ex:State → xsd:string)', '- \"Name of the event state.\"', '- Example:  [\"eliminato\", \"attivo\"]']]]\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "relevant_classes = [['ex:Event (Class) → Represents an event'],\n",
        " ['ex:Location (Class) → Represents a location'],\n",
        " ['ex:EventCategory (Class) → Represents a category of an event']]\n",
        "\n",
        "class_properties = ask_relevant_properties(question_2, relevant_classes, property_doc, llm)\n",
        "print(\"Relevant properties:\", class_properties)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fbde0bd-d2b9-4076-a862-ee04b0b59a9f",
      "metadata": {
        "id": "8fbde0bd-d2b9-4076-a862-ee04b0b59a9f"
      },
      "source": [
        "#### with graph traversal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b30d57ec-6dbd-4108-84a0-3cb0240bc46e",
      "metadata": {
        "id": "b30d57ec-6dbd-4108-84a0-3cb0240bc46e",
        "outputId": "c23bc7d6-0997-4aba-db7a-02a27251a145"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ttl_graph = Graph()\n",
        "\n",
        "ttl_graph.parse(\"only_events.ttl\", format=\"turtle\")\n",
        "\n",
        "G = nx.MultiDiGraph()\n",
        "\n",
        "for s in ttl_graph.subjects(RDF.type, OWL.Class):\n",
        "    label = ttl_graph.value(s, RDFS.label)\n",
        "    G.add_node(str(s), type=\"Class\", label=str(label) if label else s.split(\"/\")[-1])\n",
        "\n",
        "for s in ttl_graph.subjects(RDF.type, OWL.ObjectProperty):\n",
        "    domain = ttl_graph.value(s, RDFS.domain)\n",
        "    range_ = ttl_graph.value(s, RDFS.range)\n",
        "    label = ttl_graph.value(s, RDFS.label)\n",
        "    prop_label = str(label) if label else s.split(\"/\")[-1]\n",
        "    if domain and range_:\n",
        "        G.add_edge(str(domain), str(range_), type=\"ObjectProperty\", label=prop_label)\n",
        "\n",
        "for s in ttl_graph.subjects(RDF.type, OWL.DatatypeProperty):\n",
        "    domain = ttl_graph.value(s, RDFS.domain)\n",
        "    range_ = ttl_graph.value(s, RDFS.range)\n",
        "    label = ttl_graph.value(s, RDFS.label)\n",
        "    prop_label = str(label) if label else s.split(\"/\")[-1]\n",
        "    if domain:\n",
        "        G.add_edge(str(domain), str(range_) if range_ else \"Literal\", type=\"DatatypeProperty\", label=prop_label)\n",
        "\n",
        "combined_labels = defaultdict(list)\n",
        "for u, v, k, d in G.edges(data=True, keys=True):\n",
        "    combined_labels[(u, v)].append(d['label'])\n",
        "\n",
        "pos = nx.circular_layout(G)\n",
        "edge_labels = {k: \"\\n\".join(v) for k, v in combined_labels.items()}\n",
        "node_labels = {n: d.get('label', n.split(\"/\")[-1]) for n, d in G.nodes(data=True)}\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "nx.draw(G, pos, with_labels=True, labels=node_labels, node_size=2000, node_color='skyblue', font_size=10, arrows=True)\n",
        "nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8)\n",
        "plt.title(\"RDF Schema as Graph\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59d772bb-0055-48c5-a018-d7a7f81e69f3",
      "metadata": {
        "id": "59d772bb-0055-48c5-a018-d7a7f81e69f3"
      },
      "outputs": [],
      "source": [
        "questions_responses = []\n",
        "\n",
        "def ask_question(question, G, llm):\n",
        "\n",
        "    class_nodes = [n for n in G.nodes() if not n.startswith(\"http://www.w3.org/2001/XMLSchema#\")]\n",
        "\n",
        "    prompt = (\n",
        "        \"You are a semantic web expert.\\n\"\n",
        "        \"Given the following classes in an RDF schema:\\n\\n\"\n",
        "        + \"\\n\".join(f\"- {n.split('/')[-1]}\" for n in class_nodes) +\n",
        "        \"\\n\\nWhich of these classes are relevant for extracting information about:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        \"Provide only the relevant class names, without any options, explanations, or extra text. List them separated by commas.\"\n",
        "    )\n",
        "\n",
        "    response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    relevant_classes = response.get(\"text\", \"\").strip()\n",
        "\n",
        "    questions_responses.append({\n",
        "        \"question\": question,\n",
        "        \"response\": relevant_classes\n",
        "    })\n",
        "\n",
        "    return relevant_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36fda88d-be22-4b77-b269-74922b05ba7a",
      "metadata": {
        "id": "36fda88d-be22-4b77-b269-74922b05ba7a",
        "outputId": "12302500-fea5-49fb-a58b-dc6ddca17dc5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 103 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    21 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   19242.13 ms /    22 tokens\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 162,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happen on 2015-12-12?\"\n",
        "ask_question(question_1, G, llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b3ae07-679b-4ae8-8d5e-dd3bfcf5eda9",
      "metadata": {
        "id": "c7b3ae07-679b-4ae8-8d5e-dd3bfcf5eda9"
      },
      "outputs": [],
      "source": [
        "def dtt_traverse(graph, start_class, max_depth=2):\n",
        "    from collections import deque\n",
        "    visited = set()\n",
        "    queue = deque([(start_class, 0)])\n",
        "    collected_properties = []\n",
        "\n",
        "    while queue:\n",
        "        current_node, depth = queue.popleft()\n",
        "        if depth > max_depth or current_node in visited:\n",
        "            continue\n",
        "        visited.add(current_node)\n",
        "\n",
        "        for _, neighbor, key, data in graph.out_edges(current_node, keys=True, data=True):\n",
        "            property_info = {\n",
        "                \"from\": current_node,\n",
        "                \"to\": neighbor,\n",
        "                \"label\": data.get(\"label\", \"\"),\n",
        "                \"type\": data.get(\"type\", \"\"),\n",
        "            }\n",
        "            collected_properties.append(property_info)\n",
        "            queue.append((neighbor, depth + 1))\n",
        "\n",
        "    return collected_properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60681654-1d38-45d7-b777-ae56387ce9fe",
      "metadata": {
        "id": "60681654-1d38-45d7-b777-ae56387ce9fe"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar, http://example.org/Location\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbdb5b84-0add-4452-8c4c-b1810700e3dd",
      "metadata": {
        "id": "fbdb5b84-0add-4452-8c4c-b1810700e3dd"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c463d76-371e-42d1-a724-a6b7e1ce9ffb",
      "metadata": {
        "id": "3c463d76-371e-42d1-a724-a6b7e1ce9ffb"
      },
      "source": [
        "#### Upto this point did no change. when provide these classes to the extracing properties, use dictionary format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f7c30eb-5916-49b4-a08d-48b28485f1e1",
      "metadata": {
        "id": "1f7c30eb-5916-49b4-a08d-48b28485f1e1"
      },
      "outputs": [],
      "source": [
        "def prepare_property_prompt(question, relevant_classes, all_collected_props):\n",
        "    # Generate TTL-style class definitions\n",
        "    class_defs = \"\"\n",
        "    for cls in relevant_classes:\n",
        "        class_uri = cls.split(\"/\")[-1]\n",
        "        class_defs += f\"ex:{class_uri} rdf:type owl:Class ;\\n    rdfs:label \\\"{class_uri}\\\" .\\n\\n\"\n",
        "    print(class_defs)\n",
        "    # Generate TTL-style property definitions from collected props\n",
        "    prop_defs = \"\"\n",
        "    for prop in all_collected_props:\n",
        "        label = prop[2]\n",
        "        prop_type = prop[3]\n",
        "        from_cls = prop[0].split(\"/\")[-1]\n",
        "        to_cls = prop[1].split(\"/\")[-1]\n",
        "\n",
        "        if prop_type.lower() == \"objectproperty\":\n",
        "            prop_defs += (\n",
        "                f\"ex:{label} rdf:type owl:ObjectProperty ;\\n\"\n",
        "                f\"    rdfs:domain ex:{from_cls} ;\\n\"\n",
        "                f\"    rdfs:range ex:{to_cls} ;\\n\"\n",
        "                f\"    rdfs:label \\\"{label}\\\" .\\n\\n\"\n",
        "            )\n",
        "        else:\n",
        "            prop_defs += (\n",
        "                f\"ex:{label} rdf:type owl:DatatypeProperty ;\\n\"\n",
        "                f\"    rdfs:domain ex:{from_cls} ;\\n\"\n",
        "                f\"    rdfs:range xsd:string ;\\n\"\n",
        "                f\"    rdfs:label \\\"{label}\\\" .\\n\\n\"\n",
        "            )\n",
        "    print(prop_defs)\n",
        "    # Combine everything into the prompt\n",
        "    prompt = (\n",
        "        f\"You are a semantic web expert.\\n\\n\"\n",
        "        f\"The following ontology definitions are relevant to the classes:\\n\\n\"\n",
        "        f\"{class_defs}\"\n",
        "        f\"{prop_defs}\"\n",
        "        f\"Based on these definitions, which properties are relevant for answering the question:\\n\"\n",
        "        f\"'{question}'\\n\\n\"\n",
        "        f\"List only the property labels, separated by commas, without explanation.\"\n",
        "    )\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2578c444-faa7-4698-ad21-982585c599c3",
      "metadata": {
        "id": "2578c444-faa7-4698-ad21-982585c599c3",
        "outputId": "31b3fdaa-fd4f-4eab-bf33-363d5777a440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:Event rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "\n",
            "ex:Location rdf:type owl:Class ;\n",
            "    rdfs:label \"Location\" .\n",
            "\n",
            "\n",
            "ex:Event Class ID rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Class ID\" .\n",
            "\n",
            "ex:Event Name rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "\n",
            "ex:State code rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:State ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"State code\" .\n",
            "\n",
            "ex:Event State rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "\n",
            "ex:State name rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:State ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"State name\" .\n",
            "\n",
            "ex:Event Description (IT) rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Description (IT)\" .\n",
            "\n",
            "ex:Event Image URL rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Image URL\" .\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 474 prefix-match hit, remaining 1 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    16 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   14539.74 ms /    17 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar, http://example.org/Location'] | Relevant Properties: {'id': 'cmpl-19081435-32bf-457d-aed2-e139e732d9d7', 'object': 'text_completion', 'created': 1746210473, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\nPlease let me know if you need more information or clarification.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 475, 'completion_tokens': 15, 'total_tokens': 490}}\n"
          ]
        }
      ],
      "source": [
        "question_ = \"'What are the locations of the events happen on 2015-12-12\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6b895f-a4dc-49e4-8fc8-5c3de5585d1f",
      "metadata": {
        "id": "2c6b895f-a4dc-49e4-8fc8-5c3de5585d1f"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Calendar\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7add5d8d-c921-49e9-8bd9-775873c059ca",
      "metadata": {
        "id": "7add5d8d-c921-49e9-8bd9-775873c059ca"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5985b167-e27b-44d2-b7d8-5a82ea76d1ea",
      "metadata": {
        "id": "5985b167-e27b-44d2-b7d8-5a82ea76d1ea",
        "outputId": "0dfe707f-51eb-4c82-af7c-76a4e8a54808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 49 prefix-match hit, remaining 669 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:Event rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "\n",
            "ex:Calendar rdf:type owl:Class ;\n",
            "    rdfs:label \"Calendar\" .\n",
            "\n",
            "\n",
            "ex:Calendar Class ID rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Calendar Class ID\" .\n",
            "\n",
            "ex:Event Class ID rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Class ID\" .\n",
            "\n",
            "ex:EndTime rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"EndTime\" .\n",
            "\n",
            "ex:Event Name rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "\n",
            "ex:StartTime rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"StartTime\" .\n",
            "\n",
            "ex:State code rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:State ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"State code\" .\n",
            "\n",
            "ex:day rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"day\" .\n",
            "\n",
            "ex:Event On rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Calendar ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event On\" .\n",
            "\n",
            "ex:Event State rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "\n",
            "ex:State name rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:State ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"State name\" .\n",
            "\n",
            "ex:Event Description (IT) rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Description (IT)\" .\n",
            "\n",
            "ex:Event Image URL rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Image URL\" .\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   669 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    23 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   58633.53 ms /   692 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Calendar'] | Relevant Properties: {'id': 'cmpl-639eed19-a581-49a5-9450-91ff16e3d2fc', 'object': 'text_completion', 'created': 1746210487, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\n\\nEvent Name, StartTime, EndTime, Event On, Event State, State name, Event Image URL', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 718, 'completion_tokens': 23, 'total_tokens': 741}}\n"
          ]
        }
      ],
      "source": [
        "question_1 = \"What are the names of the events happening on 2015-12-12?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_1, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b90b8cc4-b870-407f-8f15-cb1fdb4e6c6c",
      "metadata": {
        "id": "b90b8cc4-b870-407f-8f15-cb1fdb4e6c6c"
      },
      "outputs": [],
      "source": [
        "relevant_classes = [\"http://example.org/Event\", \"http://example.org/Location\",\"http://example.org/EventCategory\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb54570b-8f22-4123-99bf-8db699a092dc",
      "metadata": {
        "id": "cb54570b-8f22-4123-99bf-8db699a092dc"
      },
      "outputs": [],
      "source": [
        "all_collected_props = set()\n",
        "\n",
        "for cls in relevant_classes:\n",
        "    props = dtt_traverse(G, cls)\n",
        "    for prop in props:\n",
        "        prop_tuple = (prop[\"from\"], prop[\"to\"], prop[\"label\"], prop[\"type\"])\n",
        "        all_collected_props.add(prop_tuple)\n",
        "\n",
        "all_collected_props = list(all_collected_props)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95fb5932-b40b-40f8-a339-77dad4d0d76f",
      "metadata": {
        "id": "95fb5932-b40b-40f8-a339-77dad4d0d76f",
        "outputId": "19ebf35f-ae88-4185-d0b4-ecb9edf4b194"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 49 prefix-match hit, remaining 747 prompt tokens to eval\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ex:Event rdf:type owl:Class ;\n",
            "    rdfs:label \"Event\" .\n",
            "\n",
            "ex:Location rdf:type owl:Class ;\n",
            "    rdfs:label \"Location\" .\n",
            "\n",
            "ex:EventCategory rdf:type owl:Class ;\n",
            "    rdfs:label \"EventCategory\" .\n",
            "\n",
            "\n",
            "ex:Event Class ID rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Class ID\" .\n",
            "\n",
            "ex:Eventcat Name rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:EventCategory ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Eventcat Name\" .\n",
            "\n",
            "ex:Event Name rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Name\" .\n",
            "\n",
            "ex:Address rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Address\" .\n",
            "\n",
            "ex:Eventcat Classid rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:EventCategory ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Eventcat Classid\" .\n",
            "\n",
            "ex:State code rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:State ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"State code\" .\n",
            "\n",
            "ex:Location Class ID rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Location Class ID\" .\n",
            "\n",
            "ex:Has Category rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:EventCategory ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Has Category\" .\n",
            "\n",
            "ex:Event At rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Location ;\n",
            "    rdfs:range ex:Event ;\n",
            "    rdfs:label \"Event At\" .\n",
            "\n",
            "ex:Event State rdf:type owl:ObjectProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range ex:State ;\n",
            "    rdfs:label \"Event State\" .\n",
            "\n",
            "ex:State name rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:State ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"State name\" .\n",
            "\n",
            "ex:Event Description (IT) rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Description (IT)\" .\n",
            "\n",
            "ex:Event Image URL rdf:type owl:DatatypeProperty ;\n",
            "    rdfs:domain ex:Event ;\n",
            "    rdfs:range xsd:string ;\n",
            "    rdfs:label \"Event Image URL\" .\n",
            "\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_perf_context_print:        load time =    7835.56 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   747 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /    18 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =   59777.92 ms /   765 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class: ['http://example.org/Event', 'http://example.org/Location', 'http://example.org/EventCategory'] | Relevant Properties: {'id': 'cmpl-a9275745-aedc-48cd-8928-b4d8de1e5ec1', 'object': 'text_completion', 'created': 1746210546, 'model': 'llama-2-7b-chat.Q8_0.gguf', 'choices': [{'text': '\\nEvent Class ID, Event Name, Eventcat Name, State name, Event At.', 'index': 0, 'logprobs': None, 'finish_reason': 'stop'}], 'usage': {'prompt_tokens': 796, 'completion_tokens': 18, 'total_tokens': 814}}\n"
          ]
        }
      ],
      "source": [
        "question_2 = \"What are the names and addresses of the events belong to 'Kids' category?\"\n",
        "\n",
        "\n",
        "prompt = prepare_property_prompt(question_2, relevant_classes, all_collected_props)\n",
        "response = llm(prompt, max_tokens=150, temperature=0.2)\n",
        "\n",
        "    #response_text = response['choices'][0]['text']\n",
        "    #relevant_props = [p.strip() for p in response_text.split(\",\") if p.strip()]\n",
        "\n",
        "print(f\"Class: {relevant_classes} | Relevant Properties: {response}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ed3509-5cff-4bf8-8525-44c0418c1711",
      "metadata": {
        "id": "b3ed3509-5cff-4bf8-8525-44c0418c1711"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "217847ef-e476-4340-8f04-4188291ce76c",
      "metadata": {
        "id": "217847ef-e476-4340-8f04-4188291ce76c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f8de62f-958d-490e-8079-d2f189d8d232",
      "metadata": {
        "id": "1f8de62f-958d-490e-8079-d2f189d8d232"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd72f2ff-bb1e-473d-b3b3-13c857f0cef5",
      "metadata": {
        "id": "dd72f2ff-bb1e-473d-b3b3-13c857f0cef5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6815f00-678a-4c0e-ab2a-3413517da273",
      "metadata": {
        "id": "d6815f00-678a-4c0e-ab2a-3413517da273"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07155b8f-d424-4d7d-8e3e-ead8d4c3acca",
      "metadata": {
        "id": "07155b8f-d424-4d7d-8e3e-ead8d4c3acca"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "895ef3a9-e13e-4453-96e6-f6f58ebbc2eb",
      "metadata": {
        "id": "895ef3a9-e13e-4453-96e6-f6f58ebbc2eb",
        "outputId": "8b5845e5-0d67-4ab8-a984-10f75e668b7c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: 499 prefix-match hit, remaining 34 prompt tokens to eval\n",
            "llama_perf_context_print:        load time =   22856.20 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /    34 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /   112 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =  115936.86 ms /   146 tokens\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT ?eventName ?eventAddress\n",
            "WHERE {\n",
            "  ?event a ex:Event ;\n",
            "         ex:EventName ?eventName ;\n",
            "         ex:eventon ?calendar ;\n",
            "         ?calendar ex:start_time ?startTime ;\n",
            "            ex:end_time ?endTime ;\n",
            "            ex:day ?eventDate .\n",
            "  FILTER(?eventDate = \"2015-12-12\")\n",
            "}\n",
            "\n",
            "Note: Please use the ontology provided to answer the user's question.\n"
          ]
        }
      ],
      "source": [
        "question = \"What are the names and addresses of the events happening on 2015-12-12?\"\n",
        "classes_involved = {\"ex:Event\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Event\" .''',\n",
        "\"ex:Calendar\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Calendar\" .''',\n",
        "\"ex:Location\": '''rdf:type owl:Class ;\n",
        "    rdfs:label \"Location\" .''',\n",
        "}\n",
        "relevant_properties = [\n",
        "    \"Event Name (DatatypeProperty)\",\n",
        "    \"Event On (DatatypeProperty)\",\n",
        "    \"Event At (ObjectProperty)\",\n",
        "    \"Address (DatatypeProperty)\",\n",
        "    \"StartTime (DatatypeProperty)\",\n",
        "    \"EndTime (DatatypeProperty)\"\n",
        "]\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are a semantic web expert. Your task is to write a SPARQL query that answers a user's question using the provided ontology.\n",
        "\n",
        "Classes involved:\n",
        "- {', '.join(classes_involved)}\n",
        "\n",
        "Relevant Properties:\n",
        "- {', '.join(relevant_properties)}\n",
        "\n",
        "Here are a few example SPARQL queries to help you understand the format:\n",
        "\n",
        "### EXAMPLE 1 ###\n",
        "Question: What are the names and locations of the events that occurred in 2015-10-01?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?eventLocation\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar ;\n",
        "         ex:eventat ?eventAt .\n",
        "  ?eventAt ex:address ?eventLocation .\n",
        "  ?calendar  ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "### EXAMPLE 2 ###\n",
        "Question: What are the start and end times of the events happening in 2015-12-03?\n",
        "SPARQL:\n",
        "PREFIX ex: <http://example.org/>\n",
        "\n",
        "SELECT ?eventName ?startTime ?endTime\n",
        "WHERE {{\n",
        "  ?event a ex:Event ;\n",
        "         ex:EventName ?eventName ;\n",
        "         ex:eventon ?calendar .\n",
        "  ?calendar ex:start_time ?startTime ;\n",
        "            ex:end_time ?endTime ;\n",
        "            ex:day ?eventDate .\n",
        "  FILTER(?eventDate = \"2015-12-03\")\n",
        "}}\n",
        "\n",
        "Now, please generate the SPARQL query for the user's question: \"{question}\"\n",
        "\n",
        "Output:\n",
        "Provide only the SPARQL query. Use PREFIX ex: <http://example.org/>.\n",
        "\n",
        "SPARQL:\n",
        "\"\"\"\n",
        "\n",
        "response = llm(prompt, max_tokens=150, temperature=0.1)\n",
        "print(response['choices'][0]['text'].strip())\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}